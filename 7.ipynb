{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "from common.util import im2col\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "# 引数（データ個数、1データのチャンネル数、1データの高さ、1データの幅）\n",
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "# im2colはフィルタの適用範囲ごとに、1行のデータに変換しそれを縦に並べた形にする。\n",
    "# 1行ごとにフィルタの適用処理が簡単にできる。\n",
    "# im2col(入力データ、フィルターの高さ、フィルターの横幅、ストライド、パディング)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "x2 = np.random.rand(10, 3, 7, 7)\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "\n",
    "    def forward(self, x):\n",
    "        # フィルターの個数、チャンネル数、フィルター高さ、フィルター幅\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        # 入力データの個数、チャンネル数、高さ、幅\n",
    "        N, C, H, W = x.shpae\n",
    "        # 出力サイズ高さ\n",
    "        out_h = int(1 + (H + 2 * self.pad - FH) / self.stride)\n",
    "        # 出力サイズ幅\n",
    "        out_w = int(1 + (W + 2 * self.pad - FW) / self.stride)\n",
    "\n",
    "        # 入力データをim2colで展開\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        # フィルターも展開\n",
    "        # reshapeで-1を指定すると、自動で要素数の辻褄が合うようにまとめてくれる\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        # 出力を元のサイズに戻す。\n",
    "        # transposeは多次元配列の軸の順番を入れ替える。\n",
    "        # transpose(0,3,1,2)は、元の多次元配列の軸(0,1,2,3)を(0,3,1,2)に入れ替える事を示す。\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=2, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        # 展開（1）\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w)\n",
    "\n",
    "        # 最大値（2）\n",
    "        out = np.max(col, axis=1)\n",
    "        # 整形（3）\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    def __init_(\n",
    "        self,\n",
    "        input_dim=(1, 28, 28),\n",
    "        conv_param={\"filter_num\": 30, \"filter_size\": 5, \"pad\": 0, \"stride\": 1},\n",
    "        hidden_size=100,\n",
    "        output_size=10,\n",
    "        weight_init_std=0.01,\n",
    "    ):\n",
    "        filter_num = conv_param[\"filter_num\"]\n",
    "        filter_size = conv_param[\"filter_size\"]\n",
    "        filter_pad = conv_param[\"pad\"]\n",
    "        filter_stride = conv_param[\"stride\"]\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (\n",
    "            input_size - filter_size + 2 * filter_pad\n",
    "        ) / filter_stride + 1\n",
    "        pool_outpu_size = int(\n",
    "            filter_num * (conv_output_size / 2) * (conv_output_size / 2)\n",
    "        )\n",
    "\n",
    "        self.params = {}\n",
    "        self.params[\"W1\"] = weight_init_std * np.random.randn(\n",
    "            filter_num, input_dim[0], filter_size, filter_size\n",
    "        )\n",
    "        self.params[\"b1\"] = np.zeros(filter_num)\n",
    "        self.params[\"W2\"] = weight_init_std * np.random.randn(\n",
    "            pool_outpu_size, hidden_size\n",
    "        )\n",
    "        self.params[\"b2\"] = np.zeros(hidden_size)\n",
    "        self.params[\"W3\"] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params[\"b3\"] = np.zeros(output_size)\n",
    "\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"Conv1\"] = Convolution(\n",
    "            self.params[\"W1\"],\n",
    "            self.params[\"b1\"],\n",
    "            conv_param[\"stride\"],\n",
    "            conv_param[\"pad\"],\n",
    "        )\n",
    "        self.layers[\"Relu1\"] = layers.Relu()\n",
    "        self.layers[\"Pool1\"] = layers.Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers[\"Relu2\"] = layers.Relu()\n",
    "        self.layers[\"Affine2\"] = layers.Affine(self.params[\"W3\"], self.params[\"b3\"])\n",
    "        self.last_layer = layers.SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads[\"W1\"] = self.layers[\"Conv1\"].dW\n",
    "        grads[\"b1\"] = self.layers[\"Conv1\"].db\n",
    "        grads[\"W2\"] = self.layers[\"Affine1\"].dW\n",
    "        grads[\"b2\"] = self.layers[\"Affine1\"].db\n",
    "        grads[\"W3\"] = self.layers[\"Affine2\"].dW\n",
    "        grads[\"b3\"] = self.layers[\"Affine2\"].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "from ch07.simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3000011078979186\n",
      "=== epoch:1, train acc:0.119, test acc:0.12 ===\n",
      "train loss:2.298152643089111\n",
      "train loss:2.2955666554498517\n",
      "train loss:2.2881633252232088\n",
      "train loss:2.280245211772289\n",
      "train loss:2.2695880770127657\n",
      "train loss:2.259504076409803\n",
      "train loss:2.249433952857369\n",
      "train loss:2.2368578529409926\n",
      "train loss:2.205682737759244\n",
      "train loss:2.1574144944706983\n",
      "train loss:2.1409400870836777\n",
      "train loss:2.0849170795983905\n",
      "train loss:2.075237386279413\n",
      "train loss:2.016049986883303\n",
      "train loss:1.9487132771178681\n",
      "train loss:1.8528623599211445\n",
      "train loss:1.8545486605518406\n",
      "train loss:1.8113750878614807\n",
      "train loss:1.7447347334696863\n",
      "train loss:1.7291916359626012\n",
      "train loss:1.5365602856274585\n",
      "train loss:1.4715239001823872\n",
      "train loss:1.3974739390866155\n",
      "train loss:1.3088157936839402\n",
      "train loss:1.2617177103139112\n",
      "train loss:1.0337879514472637\n",
      "train loss:1.0217196230079653\n",
      "train loss:1.0296731387861464\n",
      "train loss:0.9483515772656267\n",
      "train loss:0.9340655252789403\n",
      "train loss:0.908569036316296\n",
      "train loss:0.8733209531075994\n",
      "train loss:0.8218648785505153\n",
      "train loss:0.7738710052504361\n",
      "train loss:0.7880934374187692\n",
      "train loss:0.7743412843592143\n",
      "train loss:0.8574405917053545\n",
      "train loss:0.8124844920582003\n",
      "train loss:0.6294236622070848\n",
      "train loss:0.7197507698549498\n",
      "train loss:0.79301505784831\n",
      "train loss:0.9912053012046586\n",
      "train loss:0.5586198177897992\n",
      "train loss:0.6880160375120957\n",
      "train loss:0.5810373189502238\n",
      "train loss:0.5195515012530681\n",
      "train loss:0.7353603844496017\n",
      "train loss:0.6120740914944087\n",
      "train loss:0.48432331660679023\n",
      "train loss:0.4749771493823258\n",
      "train loss:0.5208593273554442\n",
      "train loss:0.4343099408391747\n",
      "train loss:0.4655699063675874\n",
      "train loss:0.42410299374615645\n",
      "train loss:0.4671921902014251\n",
      "train loss:0.6232294966911762\n",
      "train loss:0.5250664363322878\n",
      "train loss:0.5299426580283847\n",
      "train loss:0.5734140414540249\n",
      "train loss:0.48680918184889616\n",
      "train loss:0.45959581309669034\n",
      "train loss:0.3965713687254608\n",
      "train loss:0.4515345809582378\n",
      "train loss:0.5067311234941333\n",
      "train loss:0.5613439702324257\n",
      "train loss:0.5451639415527498\n",
      "train loss:0.49077763155200776\n",
      "train loss:0.38932734722861817\n",
      "train loss:0.36062312293006504\n",
      "train loss:0.5680723671540702\n",
      "train loss:0.4094659400349551\n",
      "train loss:0.45177353956335203\n",
      "train loss:0.3286289722229251\n",
      "train loss:0.4052228707178232\n",
      "train loss:0.5191708787218565\n",
      "train loss:0.5654127364479226\n",
      "train loss:0.39851382715031675\n",
      "train loss:0.3983771891479316\n",
      "train loss:0.29635430954117437\n",
      "train loss:0.444695777626114\n",
      "train loss:0.3020725707278475\n",
      "train loss:0.30009433108165307\n",
      "train loss:0.4362470583797273\n",
      "train loss:0.4800329434466666\n",
      "train loss:0.39596227152901475\n",
      "train loss:0.3533698503247419\n",
      "train loss:0.2626470094000403\n",
      "train loss:0.46517035954342423\n",
      "train loss:0.3836137098753236\n",
      "train loss:0.38700429359122945\n",
      "train loss:0.457419828918962\n",
      "train loss:0.31111445532152127\n",
      "train loss:0.21673765182517146\n",
      "train loss:0.4040156251971816\n",
      "train loss:0.3279119793993592\n",
      "train loss:0.31443117262880643\n",
      "train loss:0.23546590365683123\n",
      "train loss:0.30174326007712643\n",
      "train loss:0.3747156866359006\n",
      "train loss:0.2670505276647927\n",
      "train loss:0.33850872740923776\n",
      "train loss:0.4001024116132044\n",
      "train loss:0.40562931041455275\n",
      "train loss:0.387627313601293\n",
      "train loss:0.4964833747886125\n",
      "train loss:0.33170520578054125\n",
      "train loss:0.3793558323719736\n",
      "train loss:0.2554581273250095\n",
      "train loss:0.24581910028664666\n",
      "train loss:0.405946694327112\n",
      "train loss:0.2878730393770132\n",
      "train loss:0.3087268648037285\n",
      "train loss:0.3818044733320998\n",
      "train loss:0.45402612042109736\n",
      "train loss:0.5921995018583872\n",
      "train loss:0.3178607521860874\n",
      "train loss:0.2604765134091613\n",
      "train loss:0.33626840970016225\n",
      "train loss:0.3745162475633402\n",
      "train loss:0.41593235270541484\n",
      "train loss:0.27507526023465284\n",
      "train loss:0.3692880743242891\n",
      "train loss:0.28510412156992215\n",
      "train loss:0.2697188668950769\n",
      "train loss:0.3548619834139991\n",
      "train loss:0.391855581945743\n",
      "train loss:0.23010137087794333\n",
      "train loss:0.23462174485472972\n",
      "train loss:0.26594428702902584\n",
      "train loss:0.5891243134344859\n",
      "train loss:0.3080217465132685\n",
      "train loss:0.41068165779273874\n",
      "train loss:0.28310139127057193\n",
      "train loss:0.40118126312713703\n",
      "train loss:0.2253496891760467\n",
      "train loss:0.18257316378016863\n",
      "train loss:0.37326850847935433\n",
      "train loss:0.3836449193717177\n",
      "train loss:0.3379296167255874\n",
      "train loss:0.2919297484910816\n",
      "train loss:0.2756373128688705\n",
      "train loss:0.3385933871761157\n",
      "train loss:0.2677659301871558\n",
      "train loss:0.18007982694008096\n",
      "train loss:0.31913261677254723\n",
      "train loss:0.3106250253211045\n",
      "train loss:0.29182113126480014\n",
      "train loss:0.2048996314629778\n",
      "train loss:0.33486334169559195\n",
      "train loss:0.22649560414597233\n",
      "train loss:0.1774800424814844\n",
      "train loss:0.4085818847144966\n",
      "train loss:0.4166680067234839\n",
      "train loss:0.24659832166186998\n",
      "train loss:0.22316209488651229\n",
      "train loss:0.38263131443804327\n",
      "train loss:0.3176594674995146\n",
      "train loss:0.37931685042792473\n",
      "train loss:0.3449706385719405\n",
      "train loss:0.21326118374699057\n",
      "train loss:0.3549269685530231\n",
      "train loss:0.3089388006538959\n",
      "train loss:0.2965864731903452\n",
      "train loss:0.21312121697442568\n",
      "train loss:0.23480520152624174\n",
      "train loss:0.2531825118042498\n",
      "train loss:0.34913539360956203\n",
      "train loss:0.27383014337290257\n",
      "train loss:0.2334882134020215\n",
      "train loss:0.18577366765449196\n",
      "train loss:0.4070510228294154\n",
      "train loss:0.22087764831075588\n",
      "train loss:0.20656553118579207\n",
      "train loss:0.22346590539165276\n",
      "train loss:0.38687158635039587\n",
      "train loss:0.3165354306504261\n",
      "train loss:0.2005782052068726\n",
      "train loss:0.19846771835666335\n",
      "train loss:0.2918713810969882\n",
      "train loss:0.20586700949392273\n",
      "train loss:0.4989264059446459\n",
      "train loss:0.23484831931691696\n",
      "train loss:0.27734752488794123\n",
      "train loss:0.2223688701023057\n",
      "train loss:0.33820605827858835\n",
      "train loss:0.32064119342038355\n",
      "train loss:0.19287052778821956\n",
      "train loss:0.4199574731461852\n",
      "train loss:0.40739494892683487\n",
      "train loss:0.27287277792206394\n",
      "train loss:0.2438994938303799\n",
      "train loss:0.2841177646946205\n",
      "train loss:0.35861975723055667\n",
      "train loss:0.30578520500227635\n",
      "train loss:0.21318627339552637\n",
      "train loss:0.20258145873081115\n",
      "train loss:0.21497032647646586\n",
      "train loss:0.23193441022263073\n",
      "train loss:0.27164737436831693\n",
      "train loss:0.2824835386817243\n",
      "train loss:0.15446641342680073\n",
      "train loss:0.1799834596999067\n",
      "train loss:0.3012098617932346\n",
      "train loss:0.20971444790258334\n",
      "train loss:0.22003102530877391\n",
      "train loss:0.19073929757137503\n",
      "train loss:0.29195882564112113\n",
      "train loss:0.23468907703747985\n",
      "train loss:0.2474228890740105\n",
      "train loss:0.33642840931560214\n",
      "train loss:0.09377023493597633\n",
      "train loss:0.13146124799266767\n",
      "train loss:0.17319873125783505\n",
      "train loss:0.23290974079792945\n",
      "train loss:0.19421541885353832\n",
      "train loss:0.24531333632692698\n",
      "train loss:0.12984870628840262\n",
      "train loss:0.2579983592786099\n",
      "train loss:0.3362684246393605\n",
      "train loss:0.1213444242059813\n",
      "train loss:0.24415425111853523\n",
      "train loss:0.12431438740904373\n",
      "train loss:0.3057007574727973\n",
      "train loss:0.13140184245897055\n",
      "train loss:0.17390231709365778\n",
      "train loss:0.20868725277177397\n",
      "train loss:0.1435199903449538\n",
      "train loss:0.22273588270915293\n",
      "train loss:0.1800458196496609\n",
      "train loss:0.19609299924543896\n",
      "train loss:0.14225113210735377\n",
      "train loss:0.14908996950497794\n",
      "train loss:0.16340418773965104\n",
      "train loss:0.2495588956075616\n",
      "train loss:0.16174318965570125\n",
      "train loss:0.15864857305510993\n",
      "train loss:0.2569657161637597\n",
      "train loss:0.2072142371491833\n",
      "train loss:0.18265367239873775\n",
      "train loss:0.22103149327202953\n",
      "train loss:0.17583134977367199\n",
      "train loss:0.2814694829733339\n",
      "train loss:0.22640462713766912\n",
      "train loss:0.21451155702863628\n",
      "train loss:0.3621604268252964\n",
      "train loss:0.20613755705645867\n",
      "train loss:0.14992045644861912\n",
      "train loss:0.22291896357294116\n",
      "train loss:0.15517949096554823\n",
      "train loss:0.15524640212834448\n",
      "train loss:0.23109375475634844\n",
      "train loss:0.2501752448924115\n",
      "train loss:0.23689914283345595\n",
      "train loss:0.24129482616068793\n",
      "train loss:0.1884990049089471\n",
      "train loss:0.1675020706003506\n",
      "train loss:0.2115018292763176\n",
      "train loss:0.24589622255486498\n",
      "train loss:0.19951706202538882\n",
      "train loss:0.19503780603411205\n",
      "train loss:0.22917951674935533\n",
      "train loss:0.111202544106839\n",
      "train loss:0.22716520305181828\n",
      "train loss:0.20550103356896193\n",
      "train loss:0.14540919854504447\n",
      "train loss:0.17383346258770943\n",
      "train loss:0.18899640888185704\n",
      "train loss:0.17938035665647206\n",
      "train loss:0.09333143868861998\n",
      "train loss:0.15708647881806245\n",
      "train loss:0.19590614377037988\n",
      "train loss:0.18618025272279057\n",
      "train loss:0.17646696694207306\n",
      "train loss:0.1317861004872193\n",
      "train loss:0.12461735155609689\n",
      "train loss:0.2033823531799643\n",
      "train loss:0.2529861101116602\n",
      "train loss:0.11252753304976768\n",
      "train loss:0.2973147360638644\n",
      "train loss:0.33331127913436676\n",
      "train loss:0.17674705614782646\n",
      "train loss:0.18108877578930144\n",
      "train loss:0.21353760455179363\n",
      "train loss:0.18996117486296554\n",
      "train loss:0.30665062771654206\n",
      "train loss:0.2208772136219647\n",
      "train loss:0.23871060054601137\n",
      "train loss:0.195281779862037\n",
      "train loss:0.25312358079442243\n",
      "train loss:0.22946668747042942\n",
      "train loss:0.2656700077843408\n",
      "train loss:0.19438378056449662\n",
      "train loss:0.08933870230976897\n",
      "train loss:0.16665196328834483\n",
      "train loss:0.21789554382113302\n",
      "train loss:0.14047063667050838\n",
      "train loss:0.16648333669361687\n",
      "train loss:0.19261230178373015\n",
      "train loss:0.16320064392192102\n",
      "train loss:0.11877092438396492\n",
      "train loss:0.1482597299225933\n",
      "train loss:0.19549422896642912\n",
      "train loss:0.36064050207946424\n",
      "train loss:0.2608977595763607\n",
      "train loss:0.16874426254897665\n",
      "train loss:0.09540287739304139\n",
      "train loss:0.29101405969286726\n",
      "train loss:0.12541434912820393\n",
      "train loss:0.08533176473424771\n",
      "train loss:0.08785261305638152\n",
      "train loss:0.14217419337268206\n",
      "train loss:0.20757170029087604\n",
      "train loss:0.15051662598700874\n",
      "train loss:0.232725840107818\n",
      "train loss:0.20463748640067167\n",
      "train loss:0.14302114536345767\n",
      "train loss:0.1479605292883294\n",
      "train loss:0.23753972105783497\n",
      "train loss:0.14103124897865593\n",
      "train loss:0.16070854989993216\n",
      "train loss:0.15724422509382546\n",
      "train loss:0.11149291958660149\n",
      "train loss:0.15946481761039458\n",
      "train loss:0.19208577677245553\n",
      "train loss:0.19523807862176423\n",
      "train loss:0.17086171457049867\n",
      "train loss:0.15081925016299133\n",
      "train loss:0.15365346253293904\n",
      "train loss:0.15199985643987127\n",
      "train loss:0.20705755788199898\n",
      "train loss:0.1406710201328173\n",
      "train loss:0.19899886716257872\n",
      "train loss:0.13676692474373967\n",
      "train loss:0.23155539842554482\n",
      "train loss:0.1624558434330391\n",
      "train loss:0.17260561095104132\n",
      "train loss:0.19755168592097022\n",
      "train loss:0.1050716479767718\n",
      "train loss:0.15959261968982894\n",
      "train loss:0.15637716800922108\n",
      "train loss:0.13820089943698868\n",
      "train loss:0.10947392152541509\n",
      "train loss:0.168032389330303\n",
      "train loss:0.15393427778830554\n",
      "train loss:0.16357447894062627\n",
      "train loss:0.19659079419249156\n",
      "train loss:0.323553889211402\n",
      "train loss:0.0692183001111924\n",
      "train loss:0.09898056817969819\n",
      "train loss:0.14947509466557546\n",
      "train loss:0.1999362231209571\n",
      "train loss:0.1276483383882595\n",
      "train loss:0.11041425870361951\n",
      "train loss:0.198695302338611\n",
      "train loss:0.11288443806265587\n",
      "train loss:0.16710198723886424\n",
      "train loss:0.15018673210451344\n",
      "train loss:0.1006085227096506\n",
      "train loss:0.12576702926373193\n",
      "train loss:0.11903840313571103\n",
      "train loss:0.21841322327649382\n",
      "train loss:0.1555581730254444\n",
      "train loss:0.2173690553379417\n",
      "train loss:0.10638917645296773\n",
      "train loss:0.0816818609899982\n",
      "train loss:0.1574085590434632\n",
      "train loss:0.16868339082662165\n",
      "train loss:0.2233450755781335\n",
      "train loss:0.08123458094995975\n",
      "train loss:0.09556465818671013\n",
      "train loss:0.14985585203918358\n",
      "train loss:0.2113467496717853\n",
      "train loss:0.17065380169867775\n",
      "train loss:0.2683810673755862\n",
      "train loss:0.24299477469177547\n",
      "train loss:0.21887575652986288\n",
      "train loss:0.09987918525249566\n",
      "train loss:0.12868895014132614\n",
      "train loss:0.16192449789217583\n",
      "train loss:0.09164817440298156\n",
      "train loss:0.10316883747900168\n",
      "train loss:0.10700109353130388\n",
      "train loss:0.11123894105612166\n",
      "train loss:0.13404949773481378\n",
      "train loss:0.12629724665470995\n",
      "train loss:0.1383872726593915\n",
      "train loss:0.1940440996397337\n",
      "train loss:0.10960259292203635\n",
      "train loss:0.16643786422098628\n",
      "train loss:0.16595349075877552\n",
      "train loss:0.16681519321540894\n",
      "train loss:0.07917376348859166\n",
      "train loss:0.13485390032092512\n",
      "train loss:0.13498330876232528\n",
      "train loss:0.13880882072969278\n",
      "train loss:0.1450004382341027\n",
      "train loss:0.13255030077325286\n",
      "train loss:0.1325379678529287\n",
      "train loss:0.0759752126059948\n",
      "train loss:0.10017649002310483\n",
      "train loss:0.12778394033901985\n",
      "train loss:0.14928429579465508\n",
      "train loss:0.1308497446364334\n",
      "train loss:0.10042466795859464\n",
      "train loss:0.05482102428530327\n",
      "train loss:0.12238433610613124\n",
      "train loss:0.06802438987400125\n",
      "train loss:0.1523109109483223\n",
      "train loss:0.1828183550488195\n",
      "train loss:0.13870945085996747\n",
      "train loss:0.20213977747444456\n",
      "train loss:0.07452089664491247\n",
      "train loss:0.3050122396619226\n",
      "train loss:0.14890181087734983\n",
      "train loss:0.16659719440167747\n",
      "train loss:0.12469075129173257\n",
      "train loss:0.1711463860349321\n",
      "train loss:0.224837169029426\n",
      "train loss:0.1596316978445598\n",
      "train loss:0.1911196965730071\n",
      "train loss:0.17701250422602094\n",
      "train loss:0.1640776538338175\n",
      "train loss:0.06452241341862536\n",
      "train loss:0.1107219541765145\n",
      "train loss:0.16378497196985664\n",
      "train loss:0.10857615997147034\n",
      "train loss:0.10502934316403024\n",
      "train loss:0.19481996138499966\n",
      "train loss:0.1109805396186511\n",
      "train loss:0.16414032235330353\n",
      "train loss:0.13554810681185908\n",
      "train loss:0.16168201010544056\n",
      "train loss:0.1541078884550471\n",
      "train loss:0.08693736563737582\n",
      "train loss:0.07994673765806354\n",
      "train loss:0.0958298379115006\n",
      "train loss:0.1440477573301242\n",
      "train loss:0.06321995073313838\n",
      "train loss:0.09699937955840478\n",
      "train loss:0.1397908395783352\n",
      "train loss:0.18537001737769546\n",
      "train loss:0.07768472011883086\n",
      "train loss:0.13171528208558414\n",
      "train loss:0.17071725354257797\n",
      "train loss:0.13278658918569433\n",
      "train loss:0.11542250523859524\n",
      "train loss:0.12837423957736796\n",
      "train loss:0.1275735877068221\n",
      "train loss:0.14295822143909567\n",
      "train loss:0.07632108337700105\n",
      "train loss:0.13493234515771166\n",
      "train loss:0.19604085044436967\n",
      "train loss:0.0986619330121273\n",
      "train loss:0.11805289011621052\n",
      "train loss:0.18292322097762256\n",
      "train loss:0.06347073596540175\n",
      "train loss:0.0649585577727307\n",
      "train loss:0.08525078855507334\n",
      "train loss:0.15923750238839698\n",
      "train loss:0.0596096650892444\n",
      "train loss:0.11634158967092942\n",
      "train loss:0.056025918503599205\n",
      "train loss:0.13778466185819974\n",
      "train loss:0.0870359069450097\n",
      "train loss:0.08247310125666645\n",
      "train loss:0.16501631860066263\n",
      "train loss:0.17254458357902763\n",
      "train loss:0.14227097818042894\n",
      "train loss:0.17792419364320838\n",
      "train loss:0.1779200596993042\n",
      "train loss:0.11483951404730637\n",
      "train loss:0.09790741308737949\n",
      "train loss:0.1387387947089395\n",
      "train loss:0.1349675720947287\n",
      "train loss:0.07024580180904386\n",
      "train loss:0.07492262078530758\n",
      "train loss:0.10645839240754454\n",
      "train loss:0.13291151947654367\n",
      "train loss:0.1620574123026212\n",
      "train loss:0.15218083990904405\n",
      "train loss:0.08558720506339684\n",
      "train loss:0.19119279036773268\n",
      "train loss:0.21830846947881483\n",
      "train loss:0.24776209567935\n",
      "train loss:0.07875905949928834\n",
      "train loss:0.16060753652360713\n",
      "train loss:0.06974429312227652\n",
      "train loss:0.06254714615312043\n",
      "train loss:0.07443175998409825\n",
      "train loss:0.16612748579457148\n",
      "train loss:0.18281613629649218\n",
      "train loss:0.04871271381853324\n",
      "train loss:0.0997690823248114\n",
      "train loss:0.15247716232755965\n",
      "train loss:0.2105567684411633\n",
      "train loss:0.1069178876671454\n",
      "train loss:0.06829315936546866\n",
      "train loss:0.156389155368992\n",
      "train loss:0.10470460382326637\n",
      "train loss:0.10865949871884295\n",
      "train loss:0.15864327805713457\n",
      "train loss:0.3025821693072773\n",
      "train loss:0.16062076492007146\n",
      "train loss:0.09931372916522463\n",
      "train loss:0.08456365551204426\n",
      "train loss:0.08849001739599334\n",
      "train loss:0.15381885175212215\n",
      "train loss:0.11791686196170742\n",
      "train loss:0.09474129265655958\n",
      "train loss:0.17209846365310255\n",
      "train loss:0.05730209924364501\n",
      "train loss:0.06868095794282202\n",
      "train loss:0.22548952824773794\n",
      "train loss:0.1119228340602644\n",
      "train loss:0.17534325595665745\n",
      "train loss:0.08593141949027061\n",
      "train loss:0.09602050897108659\n",
      "train loss:0.04823965634338936\n",
      "train loss:0.10152426969395567\n",
      "train loss:0.11391251769854882\n",
      "train loss:0.07246820125183853\n",
      "train loss:0.0797015750267523\n",
      "train loss:0.09999725460920522\n",
      "train loss:0.13488121690813065\n",
      "train loss:0.07429458924335491\n",
      "train loss:0.11668318493930627\n",
      "train loss:0.13836248546642776\n",
      "train loss:0.1970368196292298\n",
      "train loss:0.06847082631246859\n",
      "train loss:0.06909551097049156\n",
      "train loss:0.13780595123992836\n",
      "train loss:0.12437688337389147\n",
      "train loss:0.27954212921501154\n",
      "train loss:0.12561888113398859\n",
      "train loss:0.15154798086927052\n",
      "train loss:0.062087298907375486\n",
      "train loss:0.15269352101648462\n",
      "train loss:0.08409337545603494\n",
      "train loss:0.17877211866217368\n",
      "train loss:0.16489220627886478\n",
      "train loss:0.05452007760507138\n",
      "train loss:0.16028000924594832\n",
      "train loss:0.13826577866110668\n",
      "train loss:0.11631348615056575\n",
      "train loss:0.1748280312708584\n",
      "train loss:0.09598813154344384\n",
      "train loss:0.07062989629218422\n",
      "train loss:0.09914004772462974\n",
      "train loss:0.12064713959960459\n",
      "train loss:0.06653885957882755\n",
      "train loss:0.15604839593926098\n",
      "train loss:0.1119107120527918\n",
      "train loss:0.1557290036214282\n",
      "train loss:0.1203376773104655\n",
      "train loss:0.0504355906845039\n",
      "train loss:0.06540892760953104\n",
      "train loss:0.07666807951612908\n",
      "train loss:0.12904417122874037\n",
      "train loss:0.10572401904490414\n",
      "train loss:0.0938525242432598\n",
      "train loss:0.15763246749644114\n",
      "train loss:0.13857176533368742\n",
      "train loss:0.15484881054982927\n",
      "train loss:0.18070346939221374\n",
      "train loss:0.11792122483085729\n",
      "train loss:0.12743310269297523\n",
      "train loss:0.13167035799730706\n",
      "train loss:0.10225926374909378\n",
      "train loss:0.14271110498271353\n",
      "train loss:0.08429841301129452\n",
      "train loss:0.10754834450166216\n",
      "train loss:0.05832169678293768\n",
      "train loss:0.09563147804061053\n",
      "train loss:0.14794107074805338\n",
      "train loss:0.13873551890080482\n",
      "train loss:0.15395809082596248\n",
      "train loss:0.1094604932762745\n",
      "train loss:0.06304828035808438\n",
      "train loss:0.09426725630925759\n",
      "train loss:0.046793508206042056\n",
      "train loss:0.16871965074946244\n",
      "train loss:0.08129909779838566\n",
      "train loss:0.11872440132904913\n",
      "train loss:0.07630577872617772\n",
      "train loss:0.14562469905898812\n",
      "train loss:0.14564010501620125\n",
      "train loss:0.12572603728040188\n",
      "train loss:0.17232335570360402\n",
      "train loss:0.13924869660595568\n",
      "train loss:0.12986903512014464\n",
      "train loss:0.15655035492433178\n",
      "train loss:0.037912219307615326\n",
      "train loss:0.04705932085314745\n",
      "train loss:0.11013187421315845\n",
      "train loss:0.14570898864361478\n",
      "train loss:0.12637034050393633\n",
      "train loss:0.091545913041308\n",
      "train loss:0.1056749948902942\n",
      "train loss:0.0731825032220763\n",
      "train loss:0.06080909072923389\n",
      "=== epoch:2, train acc:0.967, test acc:0.97 ===\n",
      "train loss:0.13644254344844448\n",
      "train loss:0.06221358665648442\n",
      "train loss:0.12266888455770611\n",
      "train loss:0.10016845316450354\n",
      "train loss:0.07811953894307959\n",
      "train loss:0.07955466457332984\n",
      "train loss:0.1042775622958042\n",
      "train loss:0.18574909094687617\n",
      "train loss:0.13119397725020904\n",
      "train loss:0.051001727640124714\n",
      "train loss:0.07882264371129889\n",
      "train loss:0.045092781237970184\n",
      "train loss:0.04490578056568374\n",
      "train loss:0.0869133093668606\n",
      "train loss:0.09245404818697171\n",
      "train loss:0.07013794120661122\n",
      "train loss:0.16733401644674906\n",
      "train loss:0.06010739372939341\n",
      "train loss:0.18675985966596836\n",
      "train loss:0.07735599017760349\n",
      "train loss:0.16704406066800967\n",
      "train loss:0.07833416075421168\n",
      "train loss:0.052894746997743367\n",
      "train loss:0.21861614240644278\n",
      "train loss:0.03471354832257003\n",
      "train loss:0.16361812968866452\n",
      "train loss:0.04223961610629716\n",
      "train loss:0.05217248119983494\n",
      "train loss:0.11163672631410339\n",
      "train loss:0.04099473806706912\n",
      "train loss:0.10313753331986505\n",
      "train loss:0.10313186520202645\n",
      "train loss:0.10921551753372377\n",
      "train loss:0.06886646723842851\n",
      "train loss:0.03509675277832913\n",
      "train loss:0.09595828614683528\n",
      "train loss:0.03616986082265259\n",
      "train loss:0.1906221404146275\n",
      "train loss:0.10142127341689605\n",
      "train loss:0.09944046091265285\n",
      "train loss:0.06640246535417711\n",
      "train loss:0.08495094684875787\n",
      "train loss:0.17312573443974255\n",
      "train loss:0.07452283876616575\n",
      "train loss:0.26869597404531836\n",
      "train loss:0.08165133638561624\n",
      "train loss:0.08681852367269256\n",
      "train loss:0.07571050093152429\n",
      "train loss:0.10607987648607238\n",
      "train loss:0.09253403117151907\n",
      "train loss:0.12649331268417624\n",
      "train loss:0.15992278938913373\n",
      "train loss:0.07141823249870977\n",
      "train loss:0.07507663395169364\n",
      "train loss:0.05553412832491927\n",
      "train loss:0.17829300594774025\n",
      "train loss:0.02803714308356214\n",
      "train loss:0.04122795060622362\n",
      "train loss:0.08148078695701562\n",
      "train loss:0.04833278825496188\n",
      "train loss:0.1071127656145619\n",
      "train loss:0.06883464850413135\n",
      "train loss:0.045757364262889295\n",
      "train loss:0.0802850202993251\n",
      "train loss:0.10887714833654588\n",
      "train loss:0.08391473482876513\n",
      "train loss:0.059897368194039846\n",
      "train loss:0.1256124760663565\n",
      "train loss:0.15623039651736415\n",
      "train loss:0.10483211045492588\n",
      "train loss:0.11183872898619258\n",
      "train loss:0.15301505724267211\n",
      "train loss:0.12395915182791681\n",
      "train loss:0.05142510636831087\n",
      "train loss:0.17078038842248017\n",
      "train loss:0.03217387311468058\n",
      "train loss:0.11862531862604131\n",
      "train loss:0.04963304817542863\n",
      "train loss:0.0840386638425234\n",
      "train loss:0.055279607197260036\n",
      "train loss:0.07397308445452415\n",
      "train loss:0.10160912813917199\n",
      "train loss:0.28706971669637693\n",
      "train loss:0.0467366986263163\n",
      "train loss:0.08407508717361799\n",
      "train loss:0.051622260299754356\n",
      "train loss:0.01953006261039439\n",
      "train loss:0.18207543237865711\n",
      "train loss:0.06759210272009707\n",
      "train loss:0.13083476241072423\n",
      "train loss:0.06253653367206174\n",
      "train loss:0.05375374321133795\n",
      "train loss:0.21855458215802565\n",
      "train loss:0.08843304790245396\n",
      "train loss:0.12664075357223448\n",
      "train loss:0.07049413109087319\n",
      "train loss:0.08672775294982163\n",
      "train loss:0.05381264248737787\n",
      "train loss:0.0856972004484758\n",
      "train loss:0.0802231108089534\n",
      "train loss:0.14351004963553915\n",
      "train loss:0.1486102151169378\n",
      "train loss:0.07870403774139084\n",
      "train loss:0.034519417129286134\n",
      "train loss:0.04685112125286195\n",
      "train loss:0.1735173043863808\n",
      "train loss:0.08066975509040875\n",
      "train loss:0.09748812815364312\n",
      "train loss:0.09818676769359444\n",
      "train loss:0.07450125708599699\n",
      "train loss:0.10591248584887403\n",
      "train loss:0.044690981460337606\n",
      "train loss:0.069597742118612\n",
      "train loss:0.07979909113488189\n",
      "train loss:0.04300307932597135\n",
      "train loss:0.057221146996245656\n",
      "train loss:0.06252952593018371\n",
      "train loss:0.2159893657497825\n",
      "train loss:0.04601044955781781\n",
      "train loss:0.09187991579718938\n",
      "train loss:0.05691781763375072\n",
      "train loss:0.08698933689222596\n",
      "train loss:0.03701366675108205\n",
      "train loss:0.0503753675514542\n",
      "train loss:0.18031600066734899\n",
      "train loss:0.10172285315650016\n",
      "train loss:0.09358860867077835\n",
      "train loss:0.0700910570514785\n",
      "train loss:0.0831845157328336\n",
      "train loss:0.0600969984968228\n",
      "train loss:0.15166652916535608\n",
      "train loss:0.044444688409522246\n",
      "train loss:0.15204445867652855\n",
      "train loss:0.12722294550199637\n",
      "train loss:0.025878803883333926\n",
      "train loss:0.09862155117803763\n",
      "train loss:0.0839900178440804\n",
      "train loss:0.11186241180200004\n",
      "train loss:0.09998049871534832\n",
      "train loss:0.08382082545616873\n",
      "train loss:0.11805411614078393\n",
      "train loss:0.12296609209081141\n",
      "train loss:0.07478911769623349\n",
      "train loss:0.09967022973202316\n",
      "train loss:0.040464619525163545\n",
      "train loss:0.06642105242121132\n",
      "train loss:0.11227194461506347\n",
      "train loss:0.06580955403731378\n",
      "train loss:0.13428784040330835\n",
      "train loss:0.15376134917169046\n",
      "train loss:0.11998701077480313\n",
      "train loss:0.0854758657300257\n",
      "train loss:0.09368718548061486\n",
      "train loss:0.09402414582808305\n",
      "train loss:0.09721525193991275\n",
      "train loss:0.042340754204431334\n",
      "train loss:0.13396069888406822\n",
      "train loss:0.08875837733296627\n",
      "train loss:0.1607115110726099\n",
      "train loss:0.049530912824343784\n",
      "train loss:0.11252448189377551\n",
      "train loss:0.043027443285737654\n",
      "train loss:0.02903679721957262\n",
      "train loss:0.054013743589424915\n",
      "train loss:0.1842923903664158\n",
      "train loss:0.07091553376006146\n",
      "train loss:0.0913062888030318\n",
      "train loss:0.1274680687580281\n",
      "train loss:0.0900170976676024\n",
      "train loss:0.05583846576147118\n",
      "train loss:0.09246669020810307\n",
      "train loss:0.13575330137417876\n",
      "train loss:0.09958833301887163\n",
      "train loss:0.08706400348193437\n",
      "train loss:0.05114032394894042\n",
      "train loss:0.16539495970018772\n",
      "train loss:0.14028251029761052\n",
      "train loss:0.07322952564433849\n",
      "train loss:0.054097761148401834\n",
      "train loss:0.10676571136363033\n",
      "train loss:0.22162741659705604\n",
      "train loss:0.06140657404223802\n",
      "train loss:0.08874145992786396\n",
      "train loss:0.09332167656096668\n",
      "train loss:0.13639156886586598\n",
      "train loss:0.05568257170060107\n",
      "train loss:0.033218028157362654\n",
      "train loss:0.11649362650670195\n",
      "train loss:0.05413322795821543\n",
      "train loss:0.08324497829542107\n",
      "train loss:0.062442274092436884\n",
      "train loss:0.12500633022554458\n",
      "train loss:0.0352071806123669\n",
      "train loss:0.09898484859198994\n",
      "train loss:0.04659143048067852\n",
      "train loss:0.10129023326199879\n",
      "train loss:0.08756655876861225\n",
      "train loss:0.05079316770595311\n",
      "train loss:0.06754825358467748\n",
      "train loss:0.13084724989363378\n",
      "train loss:0.06385562746511166\n",
      "train loss:0.06253387339386011\n",
      "train loss:0.14569161231093442\n",
      "train loss:0.04132042744278066\n",
      "train loss:0.10184972989136265\n",
      "train loss:0.09817951163772884\n",
      "train loss:0.0493317876098589\n",
      "train loss:0.1117502784569744\n",
      "train loss:0.11767514117000452\n",
      "train loss:0.08999023747354533\n",
      "train loss:0.03934974779281239\n",
      "train loss:0.11994630200200614\n",
      "train loss:0.056725952844578806\n",
      "train loss:0.05012350790675753\n",
      "train loss:0.1502510577611828\n",
      "train loss:0.03071243881843696\n",
      "train loss:0.09049211498142667\n",
      "train loss:0.05511273504485134\n",
      "train loss:0.10037093098155278\n",
      "train loss:0.07686033777298182\n",
      "train loss:0.049211176179704316\n",
      "train loss:0.09045813780243099\n",
      "train loss:0.12779704354329616\n",
      "train loss:0.06962789662068618\n",
      "train loss:0.07763153947100843\n",
      "train loss:0.1576434920108235\n",
      "train loss:0.06437436278142279\n",
      "train loss:0.0856711201918113\n",
      "train loss:0.048540278540346635\n",
      "train loss:0.06637592320303547\n",
      "train loss:0.10240212276183211\n",
      "train loss:0.12715420678839898\n",
      "train loss:0.058234425195031365\n",
      "train loss:0.08708028613978457\n",
      "train loss:0.1282745421361316\n",
      "train loss:0.07646315177728484\n",
      "train loss:0.07779461846021092\n",
      "train loss:0.041313375804322906\n",
      "train loss:0.04876921891265353\n",
      "train loss:0.06408621476518941\n",
      "train loss:0.08824980208032081\n",
      "train loss:0.04854155847667983\n",
      "train loss:0.04613848405575406\n",
      "train loss:0.09945579395974635\n",
      "train loss:0.09935138232067058\n",
      "train loss:0.03575811483290201\n",
      "train loss:0.0543188106813685\n",
      "train loss:0.07709091790754025\n",
      "train loss:0.08723978380610092\n",
      "train loss:0.08118389058638958\n",
      "train loss:0.04813740911752947\n",
      "train loss:0.11198883974368722\n",
      "train loss:0.05091889368926061\n",
      "train loss:0.07174853084970081\n",
      "train loss:0.06881627782024545\n",
      "train loss:0.11614069599954151\n",
      "train loss:0.022760578156316248\n",
      "train loss:0.04962757845153232\n",
      "train loss:0.09973883636691248\n",
      "train loss:0.0560122872575462\n",
      "train loss:0.09624850629161927\n",
      "train loss:0.06658085311537824\n",
      "train loss:0.04383618872517468\n",
      "train loss:0.04353637541102217\n",
      "train loss:0.026133931454266856\n",
      "train loss:0.07000729930185264\n",
      "train loss:0.07453783335628632\n",
      "train loss:0.11764800317471065\n",
      "train loss:0.1155027316457386\n",
      "train loss:0.06107639047783894\n",
      "train loss:0.13596854567804884\n",
      "train loss:0.027494836591515175\n",
      "train loss:0.08224543902434607\n",
      "train loss:0.1488306824060471\n",
      "train loss:0.014309569599953149\n",
      "train loss:0.05152493131872487\n",
      "train loss:0.04676252737250695\n",
      "train loss:0.09588437331668782\n",
      "train loss:0.09013095705953961\n",
      "train loss:0.04281037720908562\n",
      "train loss:0.05655421231873313\n",
      "train loss:0.027157041381442454\n",
      "train loss:0.05444648182824191\n",
      "train loss:0.13763446962246859\n",
      "train loss:0.11428774520362213\n",
      "train loss:0.11980161047544938\n",
      "train loss:0.05603215830149889\n",
      "train loss:0.09244483596097113\n",
      "train loss:0.12630035687052438\n",
      "train loss:0.09199072062846893\n",
      "train loss:0.10976382864585123\n",
      "train loss:0.032752298466183015\n",
      "train loss:0.056040943039799146\n",
      "train loss:0.05824186932683099\n",
      "train loss:0.07071733411752877\n",
      "train loss:0.0423187834339066\n",
      "train loss:0.10426434521880724\n",
      "train loss:0.04284954255600124\n",
      "train loss:0.033015394366942674\n",
      "train loss:0.0862001192289315\n",
      "train loss:0.09584108469533723\n",
      "train loss:0.15409979014122185\n",
      "train loss:0.04107469626368749\n",
      "train loss:0.04531662158063053\n",
      "train loss:0.06071365289766246\n",
      "train loss:0.09447120146739606\n",
      "train loss:0.07422561160761673\n",
      "train loss:0.2555542144837256\n",
      "train loss:0.0334017188291359\n",
      "train loss:0.04227844216345167\n",
      "train loss:0.04580925700232632\n",
      "train loss:0.08900597806825696\n",
      "train loss:0.07719167739368431\n",
      "train loss:0.08909888798044072\n",
      "train loss:0.0450856063965041\n",
      "train loss:0.09010085000265516\n",
      "train loss:0.11433376172896013\n",
      "train loss:0.07619484396993453\n",
      "train loss:0.04691841595780797\n",
      "train loss:0.1382254001434778\n",
      "train loss:0.08468487991888259\n",
      "train loss:0.1279211397017733\n",
      "train loss:0.12541787635177654\n",
      "train loss:0.08499558622659825\n",
      "train loss:0.04407011327160025\n",
      "train loss:0.04561149377387182\n",
      "train loss:0.06496973452541804\n",
      "train loss:0.0875272543096253\n",
      "train loss:0.08776526746278356\n",
      "train loss:0.03187224045576334\n",
      "train loss:0.10510253551282579\n",
      "train loss:0.0428932278860293\n",
      "train loss:0.12356776163277186\n",
      "train loss:0.1298298531330823\n",
      "train loss:0.08727670011291325\n",
      "train loss:0.08949602481506494\n",
      "train loss:0.048943257184457696\n",
      "train loss:0.1439053807429044\n",
      "train loss:0.06234227225463076\n",
      "train loss:0.024189346670459244\n",
      "train loss:0.1398739745420157\n",
      "train loss:0.05209948233469138\n",
      "train loss:0.06989220745920269\n",
      "train loss:0.061980501314841244\n",
      "train loss:0.05685887802548214\n",
      "train loss:0.08551129289352795\n",
      "train loss:0.10702376607538962\n",
      "train loss:0.10449941465826168\n",
      "train loss:0.06792134428565777\n",
      "train loss:0.03696751921667824\n",
      "train loss:0.052852182348788884\n",
      "train loss:0.04936758144990508\n",
      "train loss:0.021228279410862406\n",
      "train loss:0.11321081275188312\n",
      "train loss:0.05086837273214125\n",
      "train loss:0.035555485612449395\n",
      "train loss:0.0693475370802876\n",
      "train loss:0.05055488085687238\n",
      "train loss:0.010410348729661192\n",
      "train loss:0.05438454695624038\n",
      "train loss:0.016408235350428263\n",
      "train loss:0.03175022788759492\n",
      "train loss:0.03330321848721397\n",
      "train loss:0.0849664645310125\n",
      "train loss:0.18826111072970966\n",
      "train loss:0.038807766994631274\n",
      "train loss:0.059334224719759965\n",
      "train loss:0.06228956851790149\n",
      "train loss:0.06760943640836584\n",
      "train loss:0.11089740287861122\n",
      "train loss:0.06142605329290084\n",
      "train loss:0.06161754676986412\n",
      "train loss:0.0886106018762208\n",
      "train loss:0.17914509047945834\n",
      "train loss:0.03787839922327921\n",
      "train loss:0.07690276994505353\n",
      "train loss:0.032952822281736974\n",
      "train loss:0.1255437934097004\n",
      "train loss:0.04802220512735122\n",
      "train loss:0.0879505902163495\n",
      "train loss:0.023155692689437356\n",
      "train loss:0.04760863387339257\n",
      "train loss:0.05097336586743161\n",
      "train loss:0.032794909606663536\n",
      "train loss:0.07041393339355265\n",
      "train loss:0.04390099108628312\n",
      "train loss:0.027359063452196093\n",
      "train loss:0.12030134317332208\n",
      "train loss:0.09918681408296727\n",
      "train loss:0.1256235180196388\n",
      "train loss:0.028541413081869194\n",
      "train loss:0.20347589214167527\n",
      "train loss:0.02317609178245531\n",
      "train loss:0.025060897764917187\n",
      "train loss:0.06133781814090472\n",
      "train loss:0.0688750368793788\n",
      "train loss:0.06672519587201359\n",
      "train loss:0.021208302693101967\n",
      "train loss:0.08165865880959551\n",
      "train loss:0.08394967331614397\n",
      "train loss:0.02298848322317962\n",
      "train loss:0.025955385352758736\n",
      "train loss:0.09965572279111244\n",
      "train loss:0.037443965128799\n",
      "train loss:0.0730952000610234\n",
      "train loss:0.024208356058691486\n",
      "train loss:0.03546645563850598\n",
      "train loss:0.12534589277238609\n",
      "train loss:0.055682465629023375\n",
      "train loss:0.025752548140081225\n",
      "train loss:0.027145734322485137\n",
      "train loss:0.08627480748014113\n",
      "train loss:0.04499154030788417\n",
      "train loss:0.09996666993016261\n",
      "train loss:0.03930815307740181\n",
      "train loss:0.05049244200749087\n",
      "train loss:0.054079742449541425\n",
      "train loss:0.04501816895564342\n",
      "train loss:0.08891615298799767\n",
      "train loss:0.07645872475525996\n",
      "train loss:0.10474349290464785\n",
      "train loss:0.07072031390675165\n",
      "train loss:0.05187187411612655\n",
      "train loss:0.05771611908848697\n",
      "train loss:0.04192737562165326\n",
      "train loss:0.069270989557024\n",
      "train loss:0.13200128372244196\n",
      "train loss:0.04485196309178113\n",
      "train loss:0.07354406568611462\n",
      "train loss:0.09269436602615057\n",
      "train loss:0.11323203730636877\n",
      "train loss:0.06531711431105917\n",
      "train loss:0.1608758299884022\n",
      "train loss:0.042431211304033815\n",
      "train loss:0.021926344361371686\n",
      "train loss:0.07827306971431083\n",
      "train loss:0.058830330373595856\n",
      "train loss:0.02917349431802706\n",
      "train loss:0.023280888518828587\n",
      "train loss:0.01248854275402888\n",
      "train loss:0.051859694918086306\n",
      "train loss:0.04142996535108673\n",
      "train loss:0.15355929310601243\n",
      "train loss:0.019285238506158514\n",
      "train loss:0.05097003268328844\n",
      "train loss:0.08045830202838417\n",
      "train loss:0.04527535045148725\n",
      "train loss:0.1046577744763084\n",
      "train loss:0.06936822908292391\n",
      "train loss:0.040586843543257096\n",
      "train loss:0.05640661542951974\n",
      "train loss:0.029331829305960747\n",
      "train loss:0.02939358148277435\n",
      "train loss:0.03753671392919207\n",
      "train loss:0.053944066337537074\n",
      "train loss:0.037634526269556566\n",
      "train loss:0.11613841089547096\n",
      "train loss:0.11442324127103723\n",
      "train loss:0.018055100935698145\n",
      "train loss:0.11249048605218956\n",
      "train loss:0.11824607086994554\n",
      "train loss:0.05881461431109905\n",
      "train loss:0.010961062230039807\n",
      "train loss:0.018138397230863836\n",
      "train loss:0.11670489093352358\n",
      "train loss:0.06163910700099511\n",
      "train loss:0.018504018860144363\n",
      "train loss:0.028640377472146476\n",
      "train loss:0.025270828610342397\n",
      "train loss:0.029127087674925715\n",
      "train loss:0.07626333521100458\n",
      "train loss:0.04792180151610991\n",
      "train loss:0.04605559856247522\n",
      "train loss:0.10420653355487401\n",
      "train loss:0.060962243681959925\n",
      "train loss:0.01573017903412686\n",
      "train loss:0.0907651633442082\n",
      "train loss:0.04469923684359485\n",
      "train loss:0.04781943580358417\n",
      "train loss:0.06180353637492392\n",
      "train loss:0.0406942281888665\n",
      "train loss:0.041456642036268795\n",
      "train loss:0.08703114884450563\n",
      "train loss:0.05733027642391247\n",
      "train loss:0.026533705970662912\n",
      "train loss:0.06309650019139791\n",
      "train loss:0.11945592306565159\n",
      "train loss:0.11408498174452543\n",
      "train loss:0.05079565344287942\n",
      "train loss:0.10282932064392147\n",
      "train loss:0.08952886787028089\n",
      "train loss:0.05771140117330195\n",
      "train loss:0.04439522072446265\n",
      "train loss:0.052670829594197374\n",
      "train loss:0.04793176308898283\n",
      "train loss:0.028437374367221678\n",
      "train loss:0.03645091460694966\n",
      "train loss:0.07002516024451613\n",
      "train loss:0.03871306929374567\n",
      "train loss:0.029993940938766096\n",
      "train loss:0.05732823557645353\n",
      "train loss:0.03125179581740394\n",
      "train loss:0.06181172075786511\n",
      "train loss:0.07269508856825985\n",
      "train loss:0.13870544096788007\n",
      "train loss:0.0400834086459106\n",
      "train loss:0.1344845331494067\n",
      "train loss:0.03029755115360536\n",
      "train loss:0.1199799769049031\n",
      "train loss:0.04786038385693003\n",
      "train loss:0.04317371517035781\n",
      "train loss:0.04410124342896516\n",
      "train loss:0.04914544929075988\n",
      "train loss:0.0680116170832719\n",
      "train loss:0.0923981386319305\n",
      "train loss:0.037787780851589084\n",
      "train loss:0.07693100686532593\n",
      "train loss:0.06047075349150335\n",
      "train loss:0.09681435777360456\n",
      "train loss:0.10832076324425159\n",
      "train loss:0.113362430950641\n",
      "train loss:0.10289968757027988\n",
      "train loss:0.09843762945020408\n",
      "train loss:0.01944038842080069\n",
      "train loss:0.048042028333219376\n",
      "train loss:0.05324942975098313\n",
      "train loss:0.03533823902568336\n",
      "train loss:0.09175802197941355\n",
      "train loss:0.039619283076134125\n",
      "train loss:0.09592430552998424\n",
      "train loss:0.05531291769865773\n",
      "train loss:0.15238848550382206\n",
      "train loss:0.06356227318924389\n",
      "train loss:0.07706592909111501\n",
      "train loss:0.03815262601496095\n",
      "train loss:0.04508022675284709\n",
      "train loss:0.053082476587367255\n",
      "train loss:0.03898564581659928\n",
      "train loss:0.0787660898354182\n",
      "train loss:0.07099732916619783\n",
      "train loss:0.05810549265966683\n",
      "train loss:0.07614170793830553\n",
      "train loss:0.09158679041929674\n",
      "train loss:0.05072659898321391\n",
      "train loss:0.05771205903201962\n",
      "train loss:0.09700426455792269\n",
      "train loss:0.04371778921724152\n",
      "train loss:0.024003697797154003\n",
      "train loss:0.060708407904333093\n",
      "train loss:0.12499317358492298\n",
      "train loss:0.08575605502469395\n",
      "train loss:0.07689788550973271\n",
      "train loss:0.02054519136125846\n",
      "train loss:0.07473421323144053\n",
      "train loss:0.042320222045795344\n",
      "train loss:0.07196773991240049\n",
      "train loss:0.04509897008587437\n",
      "train loss:0.08829752673051093\n",
      "train loss:0.10529755311092664\n",
      "train loss:0.08947191814106188\n",
      "train loss:0.08289579701557911\n",
      "train loss:0.06854391262535228\n",
      "train loss:0.04943610082768852\n",
      "train loss:0.06368866280291606\n",
      "train loss:0.06257550365024687\n",
      "train loss:0.08228680308322317\n",
      "train loss:0.014780586423202046\n",
      "train loss:0.032096171509882844\n",
      "train loss:0.037485937029208286\n",
      "train loss:0.019147031038529525\n",
      "train loss:0.0636977024190871\n",
      "train loss:0.08189685074404165\n",
      "train loss:0.058649374801430225\n",
      "train loss:0.057734576494786784\n",
      "train loss:0.037162219286050485\n",
      "train loss:0.16520310912235314\n",
      "train loss:0.038747771881294794\n",
      "train loss:0.07247546154755728\n",
      "train loss:0.043360642657917066\n",
      "train loss:0.05547587463432713\n",
      "train loss:0.09740582263203802\n",
      "train loss:0.04419999393441041\n",
      "train loss:0.02395027568588329\n",
      "train loss:0.03103309170738032\n",
      "train loss:0.15750728985210313\n",
      "train loss:0.06626820207053016\n",
      "train loss:0.016857147996137994\n",
      "train loss:0.039908566074543364\n",
      "train loss:0.13191947249786706\n",
      "train loss:0.02239072612917784\n",
      "train loss:0.05835331149329538\n",
      "train loss:0.0667426377438529\n",
      "train loss:0.06610051678557793\n",
      "train loss:0.04876416215278093\n",
      "train loss:0.05575101031295441\n",
      "train loss:0.053686052948366765\n",
      "train loss:0.13208298349175257\n",
      "train loss:0.028030168931454953\n",
      "train loss:0.08802284037438342\n",
      "train loss:0.02466858764606851\n",
      "=== epoch:3, train acc:0.975, test acc:0.981 ===\n",
      "train loss:0.03237386841262877\n",
      "train loss:0.03217867895943943\n",
      "train loss:0.041146018255647156\n",
      "train loss:0.026442382747829122\n",
      "train loss:0.07353715103460282\n",
      "train loss:0.017059502774245075\n",
      "train loss:0.11134750912523046\n",
      "train loss:0.017857269230353596\n",
      "train loss:0.032449731487555866\n",
      "train loss:0.03154781108874085\n",
      "train loss:0.023737930140425183\n",
      "train loss:0.04118785022640044\n",
      "train loss:0.029889218566067584\n",
      "train loss:0.03957736770034821\n",
      "train loss:0.058499412078146\n",
      "train loss:0.05177488269061897\n",
      "train loss:0.03217746777361385\n",
      "train loss:0.036079572276442054\n",
      "train loss:0.015184474562908935\n",
      "train loss:0.11066618429815543\n",
      "train loss:0.05518507457264093\n",
      "train loss:0.07615362258007125\n",
      "train loss:0.062379250457307106\n",
      "train loss:0.024556434060129088\n",
      "train loss:0.0310262680539724\n",
      "train loss:0.08393892022615652\n",
      "train loss:0.03955023445265105\n",
      "train loss:0.04712131685026521\n",
      "train loss:0.053746807399422225\n",
      "train loss:0.010140006180570713\n",
      "train loss:0.05987185193598436\n",
      "train loss:0.03167780559614468\n",
      "train loss:0.03586807302493531\n",
      "train loss:0.01697039420654005\n",
      "train loss:0.025088721686541384\n",
      "train loss:0.04929330057609599\n",
      "train loss:0.09853005711775284\n",
      "train loss:0.06167148781856216\n",
      "train loss:0.02364828924620775\n",
      "train loss:0.054236171489401824\n",
      "train loss:0.05574444876708849\n",
      "train loss:0.050108341644816166\n",
      "train loss:0.06102277848489627\n",
      "train loss:0.07001045495360084\n",
      "train loss:0.02474810030795485\n",
      "train loss:0.11208871259638356\n",
      "train loss:0.0927276082112852\n",
      "train loss:0.042781058890337606\n",
      "train loss:0.056081290756912774\n",
      "train loss:0.03823054602606192\n",
      "train loss:0.037118379309396175\n",
      "train loss:0.07870852860957034\n",
      "train loss:0.03369474340455175\n",
      "train loss:0.03819522274635622\n",
      "train loss:0.06660476211265468\n",
      "train loss:0.015430681328748102\n",
      "train loss:0.05490839049872151\n",
      "train loss:0.04523265674299701\n",
      "train loss:0.13710273446854596\n",
      "train loss:0.08464541228590758\n",
      "train loss:0.03181216663060919\n",
      "train loss:0.06329187163535126\n",
      "train loss:0.008959239258269568\n",
      "train loss:0.04165634965099153\n",
      "train loss:0.02550906610416031\n",
      "train loss:0.019771370049121294\n",
      "train loss:0.055552087101112174\n",
      "train loss:0.10055056956551796\n",
      "train loss:0.06571968155931748\n",
      "train loss:0.23389520483653076\n",
      "train loss:0.033154109936386636\n",
      "train loss:0.046863962066016916\n",
      "train loss:0.031083943701408465\n",
      "train loss:0.011669850286042983\n",
      "train loss:0.10218150147452659\n",
      "train loss:0.027008863704484073\n",
      "train loss:0.016055952776766046\n",
      "train loss:0.06307300294432673\n",
      "train loss:0.027504509221620854\n",
      "train loss:0.18664680597438082\n",
      "train loss:0.041466985883849096\n",
      "train loss:0.10714565929238389\n",
      "train loss:0.06737529301724582\n",
      "train loss:0.04046015717241\n",
      "train loss:0.03667833557713098\n",
      "train loss:0.05521453755186097\n",
      "train loss:0.04856859868705763\n",
      "train loss:0.055851899468064764\n",
      "train loss:0.0424804307525673\n",
      "train loss:0.03392471373289918\n",
      "train loss:0.07428769201149167\n",
      "train loss:0.05383833262465161\n",
      "train loss:0.05802046782236906\n",
      "train loss:0.08690435978407114\n",
      "train loss:0.03216696060299224\n",
      "train loss:0.04936349308941617\n",
      "train loss:0.11463274688972133\n",
      "train loss:0.030619403398820643\n",
      "train loss:0.030309096582116633\n",
      "train loss:0.025678581424095452\n",
      "train loss:0.03214917225256387\n",
      "train loss:0.08882180377020983\n",
      "train loss:0.04028170560049259\n",
      "train loss:0.1451099840820079\n",
      "train loss:0.03393423025628981\n",
      "train loss:0.07256770214346492\n",
      "train loss:0.04596780233259265\n",
      "train loss:0.014576264072587074\n",
      "train loss:0.031981410377222505\n",
      "train loss:0.027922893112596426\n",
      "train loss:0.11358000600889057\n",
      "train loss:0.02338066626442584\n",
      "train loss:0.046834130356320995\n",
      "train loss:0.13324449990117454\n",
      "train loss:0.09165837244050654\n",
      "train loss:0.04459281955889466\n",
      "train loss:0.06583161904964913\n",
      "train loss:0.11459229563050226\n",
      "train loss:0.09731023850447945\n",
      "train loss:0.0505479636995958\n",
      "train loss:0.033821048871456885\n",
      "train loss:0.018371943076446892\n",
      "train loss:0.06479970399075484\n",
      "train loss:0.013151231127688717\n",
      "train loss:0.019421581386321697\n",
      "train loss:0.03141496734461236\n",
      "train loss:0.07239409016139806\n",
      "train loss:0.014995856762193907\n",
      "train loss:0.027619903289253386\n",
      "train loss:0.035873178248284086\n",
      "train loss:0.029613381069086345\n",
      "train loss:0.0770461898336644\n",
      "train loss:0.033186289977239394\n",
      "train loss:0.13158380690501126\n",
      "train loss:0.049230993474184206\n",
      "train loss:0.1256885648067711\n",
      "train loss:0.07401011618012918\n",
      "train loss:0.04616209560347441\n",
      "train loss:0.09876560464869538\n",
      "train loss:0.05983467738903373\n",
      "train loss:0.03055814686835751\n",
      "train loss:0.05684898053024479\n",
      "train loss:0.07834640085612611\n",
      "train loss:0.08010582689931577\n",
      "train loss:0.10862558689924975\n",
      "train loss:0.03651785515871678\n",
      "train loss:0.01708728222257974\n",
      "train loss:0.01584940658274776\n",
      "train loss:0.04397297842497999\n",
      "train loss:0.04217155811161983\n",
      "train loss:0.12338727230264097\n",
      "train loss:0.04900442384307807\n",
      "train loss:0.03371554861775183\n",
      "train loss:0.11183748121560312\n",
      "train loss:0.055060181984826234\n",
      "train loss:0.06499222562098014\n",
      "train loss:0.08273198605402811\n",
      "train loss:0.12724930819495006\n",
      "train loss:0.11373017266104402\n",
      "train loss:0.008783934130723517\n",
      "train loss:0.05668312431603344\n",
      "train loss:0.03233359127996973\n",
      "train loss:0.0210709714057066\n",
      "train loss:0.17422296213993232\n",
      "train loss:0.04717586761203376\n",
      "train loss:0.04504927341419527\n",
      "train loss:0.03820532365502424\n",
      "train loss:0.05466357759653709\n",
      "train loss:0.09126768931940527\n",
      "train loss:0.10486943362015481\n",
      "train loss:0.11139465130246798\n",
      "train loss:0.054114269202493945\n",
      "train loss:0.06050780283074857\n",
      "train loss:0.044020588497741944\n",
      "train loss:0.04005116877841712\n",
      "train loss:0.04670409613390427\n",
      "train loss:0.027207069724608533\n",
      "train loss:0.0661887529593395\n",
      "train loss:0.022309824657205025\n",
      "train loss:0.03823208782591706\n",
      "train loss:0.021885413457944213\n",
      "train loss:0.06382231627351398\n",
      "train loss:0.060066678387525475\n",
      "train loss:0.11186395762552563\n",
      "train loss:0.04456244692533432\n",
      "train loss:0.07935968335017195\n",
      "train loss:0.05688765917080062\n",
      "train loss:0.04886466887023148\n",
      "train loss:0.0922184372333085\n",
      "train loss:0.13381522773932578\n",
      "train loss:0.04512298635676469\n",
      "train loss:0.08481038984788615\n",
      "train loss:0.023152497856630715\n",
      "train loss:0.08161918763027005\n",
      "train loss:0.02523751072064365\n",
      "train loss:0.06528125926316145\n",
      "train loss:0.013022230390365697\n",
      "train loss:0.0551147916034949\n",
      "train loss:0.039416767955281255\n",
      "train loss:0.03119978302369716\n",
      "train loss:0.06814047318697092\n",
      "train loss:0.030810994574397396\n",
      "train loss:0.03822382797813075\n",
      "train loss:0.05236066438439655\n",
      "train loss:0.07180715516219173\n",
      "train loss:0.03557012688866319\n",
      "train loss:0.05347036056364491\n",
      "train loss:0.04994872643231505\n",
      "train loss:0.05027484766736608\n",
      "train loss:0.012072858342606983\n",
      "train loss:0.07492101794435704\n",
      "train loss:0.0405415470301938\n",
      "train loss:0.06754148270295589\n",
      "train loss:0.03086599097425363\n",
      "train loss:0.015919812382326783\n",
      "train loss:0.042009042469263604\n",
      "train loss:0.0721037769640962\n",
      "train loss:0.0464315793312351\n",
      "train loss:0.07689338065091819\n",
      "train loss:0.07301424465008587\n",
      "train loss:0.026331015362626817\n",
      "train loss:0.039671720917234796\n",
      "train loss:0.07527620508518296\n",
      "train loss:0.06846112999083384\n",
      "train loss:0.017413419816659958\n",
      "train loss:0.022261519039689613\n",
      "train loss:0.017081216849988833\n",
      "train loss:0.03411425380344306\n",
      "train loss:0.049011607407762454\n",
      "train loss:0.05625379392365372\n",
      "train loss:0.022306705307495466\n",
      "train loss:0.025483891623354356\n",
      "train loss:0.13277763013104898\n",
      "train loss:0.08888120842107662\n",
      "train loss:0.021882464960039916\n",
      "train loss:0.11263683371906424\n",
      "train loss:0.03763136026922992\n",
      "train loss:0.0915715188595044\n",
      "train loss:0.07753147269377275\n",
      "train loss:0.08702365178697356\n",
      "train loss:0.010786728822875687\n",
      "train loss:0.0441894317787584\n",
      "train loss:0.02275866215045999\n",
      "train loss:0.10646231516338965\n",
      "train loss:0.12174805451408358\n",
      "train loss:0.08814095198153375\n",
      "train loss:0.07114391902086178\n",
      "train loss:0.03807814895346263\n",
      "train loss:0.022324146266705758\n",
      "train loss:0.02088654434006136\n",
      "train loss:0.06758039646378722\n",
      "train loss:0.04175255257884221\n",
      "train loss:0.029104239020431626\n",
      "train loss:0.06121684526835632\n",
      "train loss:0.09125256895134325\n",
      "train loss:0.02960466874213025\n",
      "train loss:0.04929938214020157\n",
      "train loss:0.05529290714836687\n",
      "train loss:0.023052012217070348\n",
      "train loss:0.025475889616424916\n",
      "train loss:0.01586765531817884\n",
      "train loss:0.047243827219583784\n",
      "train loss:0.03232694678980945\n",
      "train loss:0.03236178349673858\n",
      "train loss:0.09159192198478065\n",
      "train loss:0.04240909451028026\n",
      "train loss:0.027070282860893635\n",
      "train loss:0.11853133851495694\n",
      "train loss:0.04439079443932314\n",
      "train loss:0.044796969633093424\n",
      "train loss:0.053420778422610234\n",
      "train loss:0.04267293372834923\n",
      "train loss:0.009619787560784234\n",
      "train loss:0.01759141247598106\n",
      "train loss:0.09668376263038134\n",
      "train loss:0.05749492616263556\n",
      "train loss:0.09552042654016848\n",
      "train loss:0.09142190688343607\n",
      "train loss:0.01628333458649265\n",
      "train loss:0.0378492098462115\n",
      "train loss:0.10648380237895783\n",
      "train loss:0.014166947308906788\n",
      "train loss:0.09995342387090775\n",
      "train loss:0.08936940292831143\n",
      "train loss:0.025644283380999094\n",
      "train loss:0.06050823869802108\n",
      "train loss:0.029698797614747283\n",
      "train loss:0.1021028135442489\n",
      "train loss:0.028984893975871655\n",
      "train loss:0.028011800087581702\n",
      "train loss:0.05972229728807906\n",
      "train loss:0.018340588089971577\n",
      "train loss:0.051574144388760325\n",
      "train loss:0.053416750737327996\n",
      "train loss:0.0844903871051275\n",
      "train loss:0.025777586929940952\n",
      "train loss:0.08303427219125757\n",
      "train loss:0.02026691212004219\n",
      "train loss:0.02179717027480884\n",
      "train loss:0.024384762673869697\n",
      "train loss:0.04737686957582333\n",
      "train loss:0.06466376394002926\n",
      "train loss:0.06196925891945896\n",
      "train loss:0.08720850644570767\n",
      "train loss:0.06839559668322436\n",
      "train loss:0.04900516177349444\n",
      "train loss:0.08325134667794185\n",
      "train loss:0.013630711213611006\n",
      "train loss:0.018431280099043303\n",
      "train loss:0.021241592812412325\n",
      "train loss:0.03460098599258176\n",
      "train loss:0.07101816603923487\n",
      "train loss:0.018806044162866763\n",
      "train loss:0.057858108185863316\n",
      "train loss:0.008191709485036947\n",
      "train loss:0.12033897252234967\n",
      "train loss:0.028012236209177498\n",
      "train loss:0.0963244680799691\n",
      "train loss:0.05504738540681827\n",
      "train loss:0.06920739211602836\n",
      "train loss:0.04629169595647073\n",
      "train loss:0.11087267406650908\n",
      "train loss:0.03859914451603296\n",
      "train loss:0.009416470855181077\n",
      "train loss:0.06722134771360712\n",
      "train loss:0.042481420998960795\n",
      "train loss:0.04709798685051005\n",
      "train loss:0.03522898017668719\n",
      "train loss:0.01808696344361527\n",
      "train loss:0.04075679279515621\n",
      "train loss:0.018694556591221167\n",
      "train loss:0.03918499413319862\n",
      "train loss:0.1876612936203324\n",
      "train loss:0.024033001929011727\n",
      "train loss:0.07582803826091611\n",
      "train loss:0.053832028097278724\n",
      "train loss:0.01428437628760485\n",
      "train loss:0.09427929753241455\n",
      "train loss:0.02256542690819021\n",
      "train loss:0.08005340157419401\n",
      "train loss:0.09193790017021784\n",
      "train loss:0.0395611803843915\n",
      "train loss:0.05799644307535935\n",
      "train loss:0.029011932015703117\n",
      "train loss:0.0214067973171499\n",
      "train loss:0.019349047172070234\n",
      "train loss:0.0332794144899156\n",
      "train loss:0.017263724278459052\n",
      "train loss:0.03130047615217982\n",
      "train loss:0.12507419971700184\n",
      "train loss:0.0743343942318699\n",
      "train loss:0.02629736806446157\n",
      "train loss:0.035766156363899786\n",
      "train loss:0.032133773843904805\n",
      "train loss:0.08508931495570994\n",
      "train loss:0.010384416930790894\n",
      "train loss:0.07530077875884998\n",
      "train loss:0.016487394873899868\n",
      "train loss:0.12401954306770957\n",
      "train loss:0.0207281360270318\n",
      "train loss:0.05479439433335624\n",
      "train loss:0.06724050205404193\n",
      "train loss:0.023880656014777436\n",
      "train loss:0.019362833425104833\n",
      "train loss:0.07728292709933696\n",
      "train loss:0.07928757231557915\n",
      "train loss:0.0069467481890568335\n",
      "train loss:0.08404371683444331\n",
      "train loss:0.06602003313099723\n",
      "train loss:0.08134602245270918\n",
      "train loss:0.03348910494955492\n",
      "train loss:0.024283543009258654\n",
      "train loss:0.07883121556470062\n",
      "train loss:0.15551898452725335\n",
      "train loss:0.020533798207001054\n",
      "train loss:0.025791937892202587\n",
      "train loss:0.02595220508840518\n",
      "train loss:0.013750528112770343\n",
      "train loss:0.015254500805157313\n",
      "train loss:0.04541018285482006\n",
      "train loss:0.013081041793224231\n",
      "train loss:0.01219495072071969\n",
      "train loss:0.060220010902615126\n",
      "train loss:0.016071978724896137\n",
      "train loss:0.06072952159358423\n",
      "train loss:0.03020324759547742\n",
      "train loss:0.029020295482583763\n",
      "train loss:0.06430674444774422\n",
      "train loss:0.02536140743636472\n",
      "train loss:0.01647246004385319\n",
      "train loss:0.009623964050727386\n",
      "train loss:0.012288622580289264\n",
      "train loss:0.067128519988395\n",
      "train loss:0.025136345204048754\n",
      "train loss:0.054973839102924735\n",
      "train loss:0.04094709056068305\n",
      "train loss:0.030068238930479517\n",
      "train loss:0.012067154343731658\n",
      "train loss:0.05319744019296548\n",
      "train loss:0.06423308867677863\n",
      "train loss:0.050451945639127534\n",
      "train loss:0.0881929836300484\n",
      "train loss:0.04048362962872502\n",
      "train loss:0.11315789852977336\n",
      "train loss:0.06927123941802943\n",
      "train loss:0.05655676345480056\n",
      "train loss:0.016389628063782496\n",
      "train loss:0.029252728376283545\n",
      "train loss:0.05326724939721919\n",
      "train loss:0.03415276227663999\n",
      "train loss:0.04729051069015031\n",
      "train loss:0.04914962932036748\n",
      "train loss:0.030324748103577395\n",
      "train loss:0.05101529248999779\n",
      "train loss:0.02084170844071327\n",
      "train loss:0.047631710463591694\n",
      "train loss:0.01694340207317787\n",
      "train loss:0.0356254322547485\n",
      "train loss:0.00823100069982181\n",
      "train loss:0.046535982941774065\n",
      "train loss:0.01725884709243443\n",
      "train loss:0.04706404250046578\n",
      "train loss:0.06110508478832264\n",
      "train loss:0.017596261179776945\n",
      "train loss:0.020201568304352747\n",
      "train loss:0.11244421219173689\n",
      "train loss:0.02683861903653837\n",
      "train loss:0.010305724345474483\n",
      "train loss:0.014944158603185063\n",
      "train loss:0.012669453850649721\n",
      "train loss:0.0395020457404885\n",
      "train loss:0.02650377109441568\n",
      "train loss:0.02982698785624014\n",
      "train loss:0.01399453048899383\n",
      "train loss:0.04526260237414399\n",
      "train loss:0.014346112198747178\n",
      "train loss:0.005364861631018482\n",
      "train loss:0.029739468304389748\n",
      "train loss:0.12632916223218404\n",
      "train loss:0.008459995464609708\n",
      "train loss:0.05578075295151839\n",
      "train loss:0.0578923293102587\n",
      "train loss:0.014768836929693972\n",
      "train loss:0.0234216269579183\n",
      "train loss:0.049673331908375126\n",
      "train loss:0.010556912455007806\n",
      "train loss:0.05509197858617748\n",
      "train loss:0.02455443427907269\n",
      "train loss:0.09410570932697027\n",
      "train loss:0.0961702681389518\n",
      "train loss:0.28589878084827375\n",
      "train loss:0.020743278875494018\n",
      "train loss:0.025427953407398826\n",
      "train loss:0.13332537856005242\n",
      "train loss:0.01985777660327171\n",
      "train loss:0.07556703220999766\n",
      "train loss:0.007179319905237212\n",
      "train loss:0.0668440788669035\n",
      "train loss:0.022369790359152753\n",
      "train loss:0.03701453686870257\n",
      "train loss:0.024560250232873133\n",
      "train loss:0.01936843514982254\n",
      "train loss:0.02539750774638224\n",
      "train loss:0.054631543226491955\n",
      "train loss:0.03461394267727003\n",
      "train loss:0.024745979247232253\n",
      "train loss:0.06346790798529506\n",
      "train loss:0.038891490181375915\n",
      "train loss:0.0176674130025461\n",
      "train loss:0.005530519743756948\n",
      "train loss:0.035094673487721335\n",
      "train loss:0.02342177158103835\n",
      "train loss:0.015674952980648273\n",
      "train loss:0.10868177748219768\n",
      "train loss:0.07658174750276164\n",
      "train loss:0.01549235615373102\n",
      "train loss:0.020959283898549366\n",
      "train loss:0.017855464362295893\n",
      "train loss:0.01562398405840802\n",
      "train loss:0.019472827834208072\n",
      "train loss:0.025184921202510292\n",
      "train loss:0.010164181361130129\n",
      "train loss:0.018705563017274975\n",
      "train loss:0.034332237661964735\n",
      "train loss:0.07578786040472019\n",
      "train loss:0.04293130659991779\n",
      "train loss:0.021338046489439617\n",
      "train loss:0.013800599788153088\n",
      "train loss:0.034702200453334164\n",
      "train loss:0.026144829638622004\n",
      "train loss:0.02260490022207058\n",
      "train loss:0.016551918415845277\n",
      "train loss:0.09937204750420552\n",
      "train loss:0.009771190390055327\n",
      "train loss:0.04671210083828765\n",
      "train loss:0.055798001913614594\n",
      "train loss:0.19031862687367365\n",
      "train loss:0.044933114417545016\n",
      "train loss:0.052348555285697235\n",
      "train loss:0.04737105893273168\n",
      "train loss:0.05573303022541947\n",
      "train loss:0.019809754980390722\n",
      "train loss:0.04573113200335904\n",
      "train loss:0.10874329975599578\n",
      "train loss:0.025494639573455526\n",
      "train loss:0.04659889441254711\n",
      "train loss:0.04557067929281325\n",
      "train loss:0.04241279043948905\n",
      "train loss:0.06340365602577057\n",
      "train loss:0.03787962301392766\n",
      "train loss:0.014068538474714256\n",
      "train loss:0.024206541785840887\n",
      "train loss:0.022901092289103833\n",
      "train loss:0.014313146499061867\n",
      "train loss:0.016470477964640816\n",
      "train loss:0.013867741165242255\n",
      "train loss:0.04181398257902311\n",
      "train loss:0.0497653753326229\n",
      "train loss:0.03269108213389546\n",
      "train loss:0.03432046460827856\n",
      "train loss:0.02845237363569815\n",
      "train loss:0.0451236756546375\n",
      "train loss:0.017696174880823475\n",
      "train loss:0.027326754255230217\n",
      "train loss:0.05823074721300678\n",
      "train loss:0.0419147796526017\n",
      "train loss:0.04599496621638691\n",
      "train loss:0.043622016030378276\n",
      "train loss:0.03725589346634834\n",
      "train loss:0.08197529905418845\n",
      "train loss:0.03325506532000767\n",
      "train loss:0.014161801530841558\n",
      "train loss:0.0195541899648505\n",
      "train loss:0.02802621475974911\n",
      "train loss:0.03244867750904389\n",
      "train loss:0.05136683406476673\n",
      "train loss:0.06614286672471409\n",
      "train loss:0.09104047367362417\n",
      "train loss:0.006943591135345468\n",
      "train loss:0.05111849444164098\n",
      "train loss:0.11290287610624274\n",
      "train loss:0.025305292899791474\n",
      "train loss:0.016304578569895523\n",
      "train loss:0.024577342904618053\n",
      "train loss:0.03974022608766174\n",
      "train loss:0.004951332638773635\n",
      "train loss:0.011674484376175269\n",
      "train loss:0.018576691237997572\n",
      "train loss:0.057028285409608165\n",
      "train loss:0.015641590601274374\n",
      "train loss:0.036184341509091174\n",
      "train loss:0.05176146014132946\n",
      "train loss:0.023028710682463146\n",
      "train loss:0.09709697921093353\n",
      "train loss:0.054946451315308925\n",
      "train loss:0.033468149028759116\n",
      "train loss:0.011194492241795782\n",
      "train loss:0.010205361160172663\n",
      "train loss:0.0536425344688465\n",
      "train loss:0.020464231589692603\n",
      "train loss:0.052418428607973536\n",
      "train loss:0.061265463490407616\n",
      "train loss:0.025715809456375183\n",
      "train loss:0.014749798059939905\n",
      "train loss:0.053179616450944635\n",
      "train loss:0.0633849313414308\n",
      "train loss:0.018796982152528497\n",
      "train loss:0.005969021617103878\n",
      "train loss:0.030572062342987892\n",
      "train loss:0.02686548321386608\n",
      "train loss:0.033644868310963125\n",
      "train loss:0.011477087468464991\n",
      "train loss:0.018081564071927014\n",
      "train loss:0.05531387959971286\n",
      "train loss:0.010028223905213678\n",
      "train loss:0.048134277479557494\n",
      "train loss:0.03362127978492907\n",
      "train loss:0.08309986741642872\n",
      "train loss:0.040547031157386657\n",
      "train loss:0.022179563090209235\n",
      "train loss:0.014121097436452165\n",
      "train loss:0.02258575825304491\n",
      "train loss:0.03174863085365891\n",
      "train loss:0.01238104490710616\n",
      "train loss:0.02783676796573561\n",
      "train loss:0.040060930535952236\n",
      "train loss:0.009302029059845956\n",
      "train loss:0.05908311227356375\n",
      "train loss:0.05839930837609681\n",
      "train loss:0.01967409328165003\n",
      "train loss:0.04307587413962111\n",
      "train loss:0.05413431511351943\n",
      "train loss:0.01409093351574715\n",
      "train loss:0.058844447388456296\n",
      "train loss:0.020933928987478718\n",
      "train loss:0.033158973285292326\n",
      "train loss:0.07494376305768075\n",
      "train loss:0.10738432839653447\n",
      "train loss:0.05275519448805215\n",
      "train loss:0.05028942960578948\n",
      "=== epoch:4, train acc:0.983, test acc:0.984 ===\n",
      "train loss:0.08066541959394939\n",
      "train loss:0.01429384372010788\n",
      "train loss:0.0487806296146666\n",
      "train loss:0.020988417806286307\n",
      "train loss:0.023411419359274897\n",
      "train loss:0.025413730757877735\n",
      "train loss:0.054436748389953965\n",
      "train loss:0.015026509936121589\n",
      "train loss:0.023660210377092004\n",
      "train loss:0.06277672733495523\n",
      "train loss:0.030365326582898512\n",
      "train loss:0.05323115375933501\n",
      "train loss:0.0219985711127859\n",
      "train loss:0.02881880278116679\n",
      "train loss:0.032974372858974796\n",
      "train loss:0.026042427707563754\n",
      "train loss:0.06375330897466318\n",
      "train loss:0.01834604502244854\n",
      "train loss:0.07060883152829721\n",
      "train loss:0.03548322016896167\n",
      "train loss:0.08284006563037487\n",
      "train loss:0.00766524113978457\n",
      "train loss:0.035322646187552854\n",
      "train loss:0.10036486320217397\n",
      "train loss:0.11441071573022944\n",
      "train loss:0.04516032351766865\n",
      "train loss:0.014935664860078296\n",
      "train loss:0.04236125901454845\n",
      "train loss:0.03894083420681189\n",
      "train loss:0.0828664224619669\n",
      "train loss:0.04861636263437053\n",
      "train loss:0.02215899285910953\n",
      "train loss:0.059243359697768255\n",
      "train loss:0.052043589528095104\n",
      "train loss:0.019923316108975242\n",
      "train loss:0.06137890727542759\n",
      "train loss:0.022557959405586026\n",
      "train loss:0.05629177761866223\n",
      "train loss:0.07833351944670222\n",
      "train loss:0.0825565360106311\n",
      "train loss:0.07360244839540178\n",
      "train loss:0.060435125291157625\n",
      "train loss:0.019685550467659785\n",
      "train loss:0.012129724314441639\n",
      "train loss:0.04260869277555142\n",
      "train loss:0.03819821309943623\n",
      "train loss:0.11097238140410409\n",
      "train loss:0.0539284524354702\n",
      "train loss:0.08523463004870942\n",
      "train loss:0.019020671177942105\n",
      "train loss:0.029216902450506357\n",
      "train loss:0.011524074684724278\n",
      "train loss:0.013968435494820717\n",
      "train loss:0.01925188071503043\n",
      "train loss:0.03608061608785712\n",
      "train loss:0.01600824584032251\n",
      "train loss:0.06590663845362861\n",
      "train loss:0.057553402664133495\n",
      "train loss:0.046182822900036925\n",
      "train loss:0.017235151312383016\n",
      "train loss:0.03535170702045035\n",
      "train loss:0.05617706190136596\n",
      "train loss:0.05189300730138263\n",
      "train loss:0.05454202006381806\n",
      "train loss:0.03084531216271956\n",
      "train loss:0.026649746995844742\n",
      "train loss:0.035250697107578756\n",
      "train loss:0.035470589777024684\n",
      "train loss:0.06621709927684821\n",
      "train loss:0.059634225837883754\n",
      "train loss:0.03184963713826098\n",
      "train loss:0.04999494069387925\n",
      "train loss:0.048603864036652136\n",
      "train loss:0.08977809884807163\n",
      "train loss:0.021163293984776805\n",
      "train loss:0.024160537436742416\n",
      "train loss:0.021688038036991607\n",
      "train loss:0.023940067824664464\n",
      "train loss:0.019341765472861906\n",
      "train loss:0.044455727650159364\n",
      "train loss:0.08466457534761318\n",
      "train loss:0.07339509597924948\n",
      "train loss:0.03186070338419143\n",
      "train loss:0.02489570772004254\n",
      "train loss:0.05469369788405151\n",
      "train loss:0.037713118853826465\n",
      "train loss:0.028850158054778707\n",
      "train loss:0.025480236777436917\n",
      "train loss:0.04993280185649937\n",
      "train loss:0.10706221271625198\n",
      "train loss:0.10557657510236823\n",
      "train loss:0.018330994927959275\n",
      "train loss:0.020868001164430005\n",
      "train loss:0.032958180652422085\n",
      "train loss:0.08324973955049407\n",
      "train loss:0.004339043513375454\n",
      "train loss:0.029942293501766266\n",
      "train loss:0.11692014207674134\n",
      "train loss:0.024102195795466623\n",
      "train loss:0.007845469432326026\n",
      "train loss:0.025135860426882713\n",
      "train loss:0.0377325357230345\n",
      "train loss:0.03303844768103408\n",
      "train loss:0.035180429276145196\n",
      "train loss:0.0748555131437699\n",
      "train loss:0.0050150914192735084\n",
      "train loss:0.03473832875780701\n",
      "train loss:0.012873207832468547\n",
      "train loss:0.024447708611825852\n",
      "train loss:0.03142485643796618\n",
      "train loss:0.014614378841905555\n",
      "train loss:0.0707033227652287\n",
      "train loss:0.03001683670394623\n",
      "train loss:0.013583341331043396\n",
      "train loss:0.02643808003718643\n",
      "train loss:0.029163496300706474\n",
      "train loss:0.03648868302008003\n",
      "train loss:0.013540168253708464\n",
      "train loss:0.01720164695006698\n",
      "train loss:0.03192578856892035\n",
      "train loss:0.03167304660310927\n",
      "train loss:0.023216728259584016\n",
      "train loss:0.023700759363874623\n",
      "train loss:0.02906077958328263\n",
      "train loss:0.04392183152914455\n",
      "train loss:0.011335214179239678\n",
      "train loss:0.029264108697480903\n",
      "train loss:0.0620487721651746\n",
      "train loss:0.04826568193114017\n",
      "train loss:0.044885052447424724\n",
      "train loss:0.06478903675741655\n",
      "train loss:0.009072951642844135\n",
      "train loss:0.08458365402659104\n",
      "train loss:0.021444665782537828\n",
      "train loss:0.024006572004459152\n",
      "train loss:0.008906089274460165\n",
      "train loss:0.008850052301401335\n",
      "train loss:0.028064284202016142\n",
      "train loss:0.040087023942845794\n",
      "train loss:0.007962777724020417\n",
      "train loss:0.03719395386489245\n",
      "train loss:0.02807334360608041\n",
      "train loss:0.015521039026503161\n",
      "train loss:0.08179216713699469\n",
      "train loss:0.046310371756863276\n",
      "train loss:0.04287818745591177\n",
      "train loss:0.02243248973777068\n",
      "train loss:0.029144382886741295\n",
      "train loss:0.014364053555163158\n",
      "train loss:0.03463388122598631\n",
      "train loss:0.05317723424936724\n",
      "train loss:0.054588339667775675\n",
      "train loss:0.03783045751664432\n",
      "train loss:0.06015215542965958\n",
      "train loss:0.11457181900114188\n",
      "train loss:0.02098947421235675\n",
      "train loss:0.023631373539228884\n",
      "train loss:0.028700117266369868\n",
      "train loss:0.09983130360359117\n",
      "train loss:0.0326092614597115\n",
      "train loss:0.044163704992418784\n",
      "train loss:0.07901328227887\n",
      "train loss:0.026814343303439448\n",
      "train loss:0.012366294090181591\n",
      "train loss:0.12613674390464724\n",
      "train loss:0.03351787674325824\n",
      "train loss:0.022817246324064126\n",
      "train loss:0.1252570991520125\n",
      "train loss:0.03135326300534744\n",
      "train loss:0.0580353773459278\n",
      "train loss:0.008901213192127926\n",
      "train loss:0.02474476630286766\n",
      "train loss:0.01846183540241579\n",
      "train loss:0.06442277820413407\n",
      "train loss:0.015751570001979423\n",
      "train loss:0.049106614321034005\n",
      "train loss:0.03236335434732084\n",
      "train loss:0.04412402541198263\n",
      "train loss:0.03457985001327808\n",
      "train loss:0.08180357114160396\n",
      "train loss:0.021383097322490507\n",
      "train loss:0.04603167271917227\n",
      "train loss:0.011107498429685054\n",
      "train loss:0.05625579694483077\n",
      "train loss:0.06626584497658064\n",
      "train loss:0.00941686016097728\n",
      "train loss:0.014722787130536824\n",
      "train loss:0.013707592917688211\n",
      "train loss:0.036597585555428545\n",
      "train loss:0.006686715186291064\n",
      "train loss:0.06224996374219988\n",
      "train loss:0.02743112902043968\n",
      "train loss:0.037844449776829846\n",
      "train loss:0.06549845637206275\n",
      "train loss:0.04952035584753565\n",
      "train loss:0.09746304234619155\n",
      "train loss:0.02794997180821481\n",
      "train loss:0.018300838454945394\n",
      "train loss:0.03209084509818307\n",
      "train loss:0.0432922555916919\n",
      "train loss:0.026992738033526694\n",
      "train loss:0.07932112485767381\n",
      "train loss:0.03893968307210028\n",
      "train loss:0.0397609610127277\n",
      "train loss:0.003673573594875065\n",
      "train loss:0.019954031720820407\n",
      "train loss:0.0322160218833039\n",
      "train loss:0.017388118984577927\n",
      "train loss:0.06620986752677852\n",
      "train loss:0.04220756309886213\n",
      "train loss:0.0668013581419268\n",
      "train loss:0.047379288198060504\n",
      "train loss:0.03922794015298339\n",
      "train loss:0.025726673921580474\n",
      "train loss:0.021284092777456343\n",
      "train loss:0.005205868231036779\n",
      "train loss:0.006554229690728763\n",
      "train loss:0.026396461977076763\n",
      "train loss:0.020213955483224168\n",
      "train loss:0.01372411597130769\n",
      "train loss:0.04370722661267578\n",
      "train loss:0.014817988374222477\n",
      "train loss:0.038397081310780144\n",
      "train loss:0.03603663063796217\n",
      "train loss:0.021308819307935222\n",
      "train loss:0.04464188665732123\n",
      "train loss:0.008648151390022068\n",
      "train loss:0.08970973334522013\n",
      "train loss:0.18346049708982468\n",
      "train loss:0.03354457640022688\n",
      "train loss:0.02619513400856475\n",
      "train loss:0.01457967225462771\n",
      "train loss:0.02335964772279787\n",
      "train loss:0.013183003816604194\n",
      "train loss:0.012798948548277494\n",
      "train loss:0.037284472561026016\n",
      "train loss:0.08463600378548712\n",
      "train loss:0.04927859111645877\n",
      "train loss:0.06212518337584174\n",
      "train loss:0.030768621265985292\n",
      "train loss:0.08710422095931865\n",
      "train loss:0.034133593333584206\n",
      "train loss:0.03494950800094044\n",
      "train loss:0.01506030807978804\n",
      "train loss:0.04098090946846372\n",
      "train loss:0.015346408397081783\n",
      "train loss:0.028899639747642966\n",
      "train loss:0.04552088545118099\n",
      "train loss:0.05279642487485612\n",
      "train loss:0.07467250293394262\n",
      "train loss:0.020723131733326104\n",
      "train loss:0.01203915994235578\n",
      "train loss:0.052675860160989484\n",
      "train loss:0.043405148042234894\n",
      "train loss:0.08152672140585741\n",
      "train loss:0.01910009498791538\n",
      "train loss:0.11451605147433261\n",
      "train loss:0.00957084680677132\n",
      "train loss:0.022284126816219104\n",
      "train loss:0.06340749646055154\n",
      "train loss:0.028846137595897044\n",
      "train loss:0.01306289270335394\n",
      "train loss:0.06137412868294729\n",
      "train loss:0.023004737063622507\n",
      "train loss:0.019048846729216192\n",
      "train loss:0.01644909671023207\n",
      "train loss:0.033795664693415196\n",
      "train loss:0.0294932868828534\n",
      "train loss:0.06871284798746566\n",
      "train loss:0.025623337950853756\n",
      "train loss:0.02129314621998228\n",
      "train loss:0.05042500416253096\n",
      "train loss:0.11893748746365881\n",
      "train loss:0.018363956445345313\n",
      "train loss:0.038603321003829856\n",
      "train loss:0.04342418478809286\n",
      "train loss:0.0067473172392839235\n",
      "train loss:0.04452782203324691\n",
      "train loss:0.11374000642142597\n",
      "train loss:0.02310487578382245\n",
      "train loss:0.03789644295257119\n",
      "train loss:0.01284934670425526\n",
      "train loss:0.029299861594574993\n",
      "train loss:0.026269203349058533\n",
      "train loss:0.02246714684211745\n",
      "train loss:0.030327416241986312\n",
      "train loss:0.042808770703519156\n",
      "train loss:0.019096562303269792\n",
      "train loss:0.013414318308995614\n",
      "train loss:0.014688839674940364\n",
      "train loss:0.030892990202794013\n",
      "train loss:0.014828286917312566\n",
      "train loss:0.031800633592814466\n",
      "train loss:0.022272783462323066\n",
      "train loss:0.052839859186713856\n",
      "train loss:0.028259547113830653\n",
      "train loss:0.021474964548993933\n",
      "train loss:0.010488973531083736\n",
      "train loss:0.03478789184076778\n",
      "train loss:0.021542400088441042\n",
      "train loss:0.04028172003241877\n",
      "train loss:0.014179200366228672\n",
      "train loss:0.05615523364630359\n",
      "train loss:0.007961453147184959\n",
      "train loss:0.04928402907862852\n",
      "train loss:0.005334532613034103\n",
      "train loss:0.015347931030722186\n",
      "train loss:0.04012577812553214\n",
      "train loss:0.05091956159875312\n",
      "train loss:0.0207931721358\n",
      "train loss:0.019394167814477805\n",
      "train loss:0.024839941723822707\n",
      "train loss:0.059561174224089165\n",
      "train loss:0.020781243992110378\n",
      "train loss:0.007189759081808008\n",
      "train loss:0.04761477284364119\n",
      "train loss:0.02373459993533979\n",
      "train loss:0.03169652556866522\n",
      "train loss:0.024561211628799873\n",
      "train loss:0.04572316156794298\n",
      "train loss:0.013193699464333486\n",
      "train loss:0.003666812213273749\n",
      "train loss:0.03374462776345359\n",
      "train loss:0.010046592070922865\n",
      "train loss:0.023973883306914027\n",
      "train loss:0.011715408315303363\n",
      "train loss:0.022668555146526798\n",
      "train loss:0.021455497315770886\n",
      "train loss:0.019658414598066228\n",
      "train loss:0.019725242799686654\n",
      "train loss:0.03607228835068307\n",
      "train loss:0.014708573181773323\n",
      "train loss:0.013310597599227744\n",
      "train loss:0.10898108194884422\n",
      "train loss:0.06291490190165293\n",
      "train loss:0.02591292608249356\n",
      "train loss:0.015751849765534853\n",
      "train loss:0.025567390575876377\n",
      "train loss:0.016168485958946658\n",
      "train loss:0.030490320777677982\n",
      "train loss:0.03077407170633893\n",
      "train loss:0.025479612366164455\n",
      "train loss:0.010320620744246514\n",
      "train loss:0.04019481700943132\n",
      "train loss:0.013114482144509833\n",
      "train loss:0.04477738370498598\n",
      "train loss:0.025368640768937984\n",
      "train loss:0.10463870645062165\n",
      "train loss:0.050650754265267856\n",
      "train loss:0.022474217593055457\n",
      "train loss:0.0701473063427172\n",
      "train loss:0.020801505537633925\n",
      "train loss:0.01648729054662016\n",
      "train loss:0.02010650897085494\n",
      "train loss:0.09223125910679726\n",
      "train loss:0.03950526330877526\n",
      "train loss:0.007284337938459006\n",
      "train loss:0.028746996857981988\n",
      "train loss:0.012010086337471979\n",
      "train loss:0.012051567235478415\n",
      "train loss:0.01407748093056488\n",
      "train loss:0.05209437224405301\n",
      "train loss:0.02610299401991117\n",
      "train loss:0.050602789425591224\n",
      "train loss:0.03802940225206062\n",
      "train loss:0.05655541797484759\n",
      "train loss:0.009330957070715554\n",
      "train loss:0.015704550488855933\n",
      "train loss:0.03814065104403386\n",
      "train loss:0.0268407506148244\n",
      "train loss:0.012681863128328924\n",
      "train loss:0.038013503775425866\n",
      "train loss:0.06626158809850889\n",
      "train loss:0.021594743292480637\n",
      "train loss:0.01793246948442905\n",
      "train loss:0.05414258195442521\n",
      "train loss:0.051428320733526635\n",
      "train loss:0.07589597666735268\n",
      "train loss:0.058006522840589485\n",
      "train loss:0.008246554256245077\n",
      "train loss:0.04537573282316657\n",
      "train loss:0.03479430625531196\n",
      "train loss:0.049392903644417466\n",
      "train loss:0.03228983957547278\n",
      "train loss:0.015495534087693169\n",
      "train loss:0.041284117018553064\n",
      "train loss:0.020172400636881464\n",
      "train loss:0.013817304688988945\n",
      "train loss:0.025047535967862383\n",
      "train loss:0.06064749058180336\n",
      "train loss:0.01657633492440736\n",
      "train loss:0.041842329234253774\n",
      "train loss:0.04618894021333135\n",
      "train loss:0.008795073704474752\n",
      "train loss:0.03714339630965935\n",
      "train loss:0.026426257053379018\n",
      "train loss:0.011372519190044162\n",
      "train loss:0.013917475774238929\n",
      "train loss:0.035659573856131194\n",
      "train loss:0.02780686582505838\n",
      "train loss:0.011726358275451336\n",
      "train loss:0.009990306890329174\n",
      "train loss:0.016657759745818138\n",
      "train loss:0.03844402400153223\n",
      "train loss:0.003362965894390428\n",
      "train loss:0.016240544724921764\n",
      "train loss:0.017943358728837032\n",
      "train loss:0.029797408451737048\n",
      "train loss:0.060626254730460634\n",
      "train loss:0.03258076989493283\n",
      "train loss:0.011671522171513779\n",
      "train loss:0.14685767744263123\n",
      "train loss:0.02489634280295237\n",
      "train loss:0.022981535430797607\n",
      "train loss:0.03818791331773375\n",
      "train loss:0.023753907075493158\n",
      "train loss:0.00736629958294996\n",
      "train loss:0.06353756730128449\n",
      "train loss:0.04119164274687393\n",
      "train loss:0.04518607539180858\n",
      "train loss:0.032657566386487966\n",
      "train loss:0.052363875633663605\n",
      "train loss:0.02020869164231098\n",
      "train loss:0.010972879564502597\n",
      "train loss:0.014903021275276422\n",
      "train loss:0.008080300654531393\n",
      "train loss:0.015493930481124582\n",
      "train loss:0.03636766050261377\n",
      "train loss:0.052078298093620044\n",
      "train loss:0.03781557850248606\n",
      "train loss:0.02620742105897885\n",
      "train loss:0.031667817720890945\n",
      "train loss:0.038617703894845624\n",
      "train loss:0.0237627348645132\n",
      "train loss:0.009424027783887918\n",
      "train loss:0.02327052457778867\n",
      "train loss:0.07463592145871217\n",
      "train loss:0.013014388665849254\n",
      "train loss:0.022741839392872373\n",
      "train loss:0.010810674921116464\n",
      "train loss:0.1374970169070727\n",
      "train loss:0.06541126968107326\n",
      "train loss:0.005942188763047929\n",
      "train loss:0.028062036603798735\n",
      "train loss:0.01592509396319548\n",
      "train loss:0.021560114546209735\n",
      "train loss:0.030510586201429723\n",
      "train loss:0.03260310472415009\n",
      "train loss:0.05548217838883158\n",
      "train loss:0.03941843180439225\n",
      "train loss:0.021861070907642374\n",
      "train loss:0.02960281135354083\n",
      "train loss:0.18186231787683943\n",
      "train loss:0.01157887069234486\n",
      "train loss:0.023052493553358398\n",
      "train loss:0.06137499104228833\n",
      "train loss:0.015675426933653595\n",
      "train loss:0.06363497658862943\n",
      "train loss:0.008553782384435979\n",
      "train loss:0.010715314028237945\n",
      "train loss:0.006353017443632493\n",
      "train loss:0.020573248648200964\n",
      "train loss:0.026243982022800368\n",
      "train loss:0.017358754712340045\n",
      "train loss:0.015440478184659807\n",
      "train loss:0.008027593088641299\n",
      "train loss:0.02738940407027983\n",
      "train loss:0.01948285551071539\n",
      "train loss:0.01668097282863937\n",
      "train loss:0.007447069470852975\n",
      "train loss:0.03115799612304571\n",
      "train loss:0.07467686583015479\n",
      "train loss:0.011508270716638154\n",
      "train loss:0.014126004002846203\n",
      "train loss:0.02305764743054799\n",
      "train loss:0.009739273967329673\n",
      "train loss:0.03202146119932832\n",
      "train loss:0.08098430141449552\n",
      "train loss:0.0226800271241383\n",
      "train loss:0.01893617143715278\n",
      "train loss:0.06089922464915166\n",
      "train loss:0.024546283064540958\n",
      "train loss:0.011807867093661826\n",
      "train loss:0.008551495845494906\n",
      "train loss:0.031217989466746497\n",
      "train loss:0.02686106427156386\n",
      "train loss:0.02839669068975166\n",
      "train loss:0.01785974935279524\n",
      "train loss:0.013171098860517176\n",
      "train loss:0.037949335833495475\n",
      "train loss:0.011270534400130343\n",
      "train loss:0.018519037982625258\n",
      "train loss:0.011920677431496529\n",
      "train loss:0.06916604078210463\n",
      "train loss:0.11797983697918457\n",
      "train loss:0.036757410050233016\n",
      "train loss:0.015365916149108965\n",
      "train loss:0.02829636289093987\n",
      "train loss:0.007772635251018999\n",
      "train loss:0.006586767565771329\n",
      "train loss:0.048553218144817174\n",
      "train loss:0.030496484595714638\n",
      "train loss:0.03137820079792028\n",
      "train loss:0.015190175293184678\n",
      "train loss:0.02590667205200449\n",
      "train loss:0.012009701662611293\n",
      "train loss:0.017432774497394287\n",
      "train loss:0.016459618078112685\n",
      "train loss:0.020708353430047736\n",
      "train loss:0.03883875391352631\n",
      "train loss:0.033482026187481154\n",
      "train loss:0.06069614685783356\n",
      "train loss:0.03469729644737282\n",
      "train loss:0.06051397800031557\n",
      "train loss:0.016437017881704635\n",
      "train loss:0.011789259120375569\n",
      "train loss:0.013572779792720585\n",
      "train loss:0.014532884159672006\n",
      "train loss:0.02545580029497468\n",
      "train loss:0.014790911363147799\n",
      "train loss:0.01097671762895411\n",
      "train loss:0.03604370183521957\n",
      "train loss:0.01709286590080923\n",
      "train loss:0.02495162578056688\n",
      "train loss:0.021026359894887395\n",
      "train loss:0.006792136205828993\n",
      "train loss:0.029941475365773348\n",
      "train loss:0.07098455945903753\n",
      "train loss:0.018082176973515413\n",
      "train loss:0.02248178658897298\n",
      "train loss:0.009311036544878823\n",
      "train loss:0.0514355121482958\n",
      "train loss:0.011568995325095073\n",
      "train loss:0.045085230590336846\n",
      "train loss:0.032121921404688177\n",
      "train loss:0.03466851908941373\n",
      "train loss:0.025769787202242454\n",
      "train loss:0.003207947241114173\n",
      "train loss:0.011477844742583423\n",
      "train loss:0.020074625179907272\n",
      "train loss:0.04081280740416889\n",
      "train loss:0.008555624598663903\n",
      "train loss:0.018263028267495887\n",
      "train loss:0.020351149951797397\n",
      "train loss:0.01804430901035902\n",
      "train loss:0.03239233862568653\n",
      "train loss:0.07722495618703823\n",
      "train loss:0.04407194616395642\n",
      "train loss:0.010066577687091174\n",
      "train loss:0.017190314038405086\n",
      "train loss:0.032849057691416494\n",
      "train loss:0.042869940163729116\n",
      "train loss:0.06440469390366668\n",
      "train loss:0.017912820992352273\n",
      "train loss:0.044932659505107775\n",
      "train loss:0.020116854691355823\n",
      "train loss:0.018326242538388673\n",
      "train loss:0.011721446796951758\n",
      "train loss:0.029951084092929313\n",
      "train loss:0.014685998787228434\n",
      "train loss:0.01240545330948242\n",
      "train loss:0.09816463268328172\n",
      "train loss:0.05155742472419647\n",
      "train loss:0.031503841095840784\n",
      "train loss:0.007025048361814005\n",
      "train loss:0.17640738636644668\n",
      "train loss:0.022759752350951307\n",
      "train loss:0.019565377015952488\n",
      "train loss:0.0661151486366184\n",
      "train loss:0.019803020117602738\n",
      "train loss:0.04055260465892957\n",
      "train loss:0.02981583774514109\n",
      "train loss:0.05040724737270699\n",
      "train loss:0.013015419430101163\n",
      "train loss:0.02051880243523074\n",
      "train loss:0.010877635925131962\n",
      "train loss:0.022442052119930236\n",
      "train loss:0.06799442689527863\n",
      "train loss:0.029516009023244756\n",
      "train loss:0.02744620202066923\n",
      "train loss:0.03481019835048479\n",
      "train loss:0.08616504486098236\n",
      "train loss:0.005737153053480801\n",
      "train loss:0.01932327771854468\n",
      "train loss:0.02413513672724171\n",
      "train loss:0.018910222606276915\n",
      "train loss:0.022536268979397426\n",
      "train loss:0.030245216101272187\n",
      "train loss:0.007328921446721184\n",
      "train loss:0.005558352372526872\n",
      "train loss:0.008693595282234458\n",
      "train loss:0.02103044746365372\n",
      "train loss:0.020433913349744058\n",
      "train loss:0.08040441157490337\n",
      "train loss:0.03752963145608082\n",
      "train loss:0.032688537662868784\n",
      "train loss:0.03348417854677225\n",
      "train loss:0.07832311491973243\n",
      "train loss:0.006626108566203157\n",
      "train loss:0.023400981329853174\n",
      "=== epoch:5, train acc:0.989, test acc:0.988 ===\n",
      "train loss:0.028648232465302334\n",
      "train loss:0.07486200756359168\n",
      "train loss:0.014838460643212724\n",
      "train loss:0.029238928149013674\n",
      "train loss:0.04498884426155976\n",
      "train loss:0.02669948202713818\n",
      "train loss:0.1242483719025715\n",
      "train loss:0.00803380090717542\n",
      "train loss:0.01340700295396154\n",
      "train loss:0.020760357819469076\n",
      "train loss:0.021570838923110472\n",
      "train loss:0.042645290041363325\n",
      "train loss:0.04302539955387304\n",
      "train loss:0.04243104494948695\n",
      "train loss:0.018500111943681098\n",
      "train loss:0.011711970245752436\n",
      "train loss:0.02188930312488806\n",
      "train loss:0.014309762702060011\n",
      "train loss:0.01805595095045034\n",
      "train loss:0.05068736339335473\n",
      "train loss:0.004455929770842839\n",
      "train loss:0.019542126720589553\n",
      "train loss:0.027075765862125317\n",
      "train loss:0.02859100770221374\n",
      "train loss:0.010541414333083374\n",
      "train loss:0.011402156651038386\n",
      "train loss:0.04966238720016533\n",
      "train loss:0.034703402796707895\n",
      "train loss:0.014350841673394971\n",
      "train loss:0.008997141097436554\n",
      "train loss:0.021946255369449708\n",
      "train loss:0.031812464686954874\n",
      "train loss:0.017912188787870032\n",
      "train loss:0.04322977193022615\n",
      "train loss:0.0074627565479709005\n",
      "train loss:0.021985259407128244\n",
      "train loss:0.03736645922587232\n",
      "train loss:0.0078012806831242966\n",
      "train loss:0.004538237682030828\n",
      "train loss:0.02069237067288598\n",
      "train loss:0.023079812953507594\n",
      "train loss:0.01529008949376777\n",
      "train loss:0.015575468466182548\n",
      "train loss:0.02833913611403593\n",
      "train loss:0.006038467157859728\n",
      "train loss:0.007666054312630102\n",
      "train loss:0.04538863470827031\n",
      "train loss:0.0028770429742298142\n",
      "train loss:0.03237656125238097\n",
      "train loss:0.022493328060454593\n",
      "train loss:0.0161349918919414\n",
      "train loss:0.03298064365179837\n",
      "train loss:0.004380038776011121\n",
      "train loss:0.057251214110643635\n",
      "train loss:0.011297882080113923\n",
      "train loss:0.019228022399452056\n",
      "train loss:0.032084659135208415\n",
      "train loss:0.018694377067921212\n",
      "train loss:0.008918023159992268\n",
      "train loss:0.031542350043420125\n",
      "train loss:0.026935646672112682\n",
      "train loss:0.005989725673805714\n",
      "train loss:0.025002186366917138\n",
      "train loss:0.03663720466965808\n",
      "train loss:0.06383196652948707\n",
      "train loss:0.05870253880597679\n",
      "train loss:0.11565982002533655\n",
      "train loss:0.007486725228582414\n",
      "train loss:0.023356968308538638\n",
      "train loss:0.06635551720779513\n",
      "train loss:0.026969982112199288\n",
      "train loss:0.0074062637977347166\n",
      "train loss:0.026241723252034662\n",
      "train loss:0.011032153873048914\n",
      "train loss:0.01102751119604257\n",
      "train loss:0.06714289443616198\n",
      "train loss:0.01926574997050832\n",
      "train loss:0.02416506359412182\n",
      "train loss:0.008794781125509245\n",
      "train loss:0.05104519487732504\n",
      "train loss:0.028504212478825845\n",
      "train loss:0.043979041410658004\n",
      "train loss:0.0123896251959518\n",
      "train loss:0.026791855797045575\n",
      "train loss:0.014949648448495913\n",
      "train loss:0.010557607015777853\n",
      "train loss:0.01921665162389792\n",
      "train loss:0.021020822484338092\n",
      "train loss:0.05632851960924132\n",
      "train loss:0.010615502611345919\n",
      "train loss:0.008228615659798079\n",
      "train loss:0.014675551763276388\n",
      "train loss:0.02339443007049001\n",
      "train loss:0.025561844760187313\n",
      "train loss:0.0457993379381267\n",
      "train loss:0.06080020453941883\n",
      "train loss:0.0071442481879145335\n",
      "train loss:0.003191457625698865\n",
      "train loss:0.009384175621293818\n",
      "train loss:0.04204896012715411\n",
      "train loss:0.006998649533631965\n",
      "train loss:0.06285374181793248\n",
      "train loss:0.07671571974631722\n",
      "train loss:0.008475969276990014\n",
      "train loss:0.03979067229151647\n",
      "train loss:0.01295633589152343\n",
      "train loss:0.04028400635962009\n",
      "train loss:0.03850816210948882\n",
      "train loss:0.006563927705325505\n",
      "train loss:0.038805259151114\n",
      "train loss:0.016123475963404688\n",
      "train loss:0.1463503923689675\n",
      "train loss:0.009366838709478662\n",
      "train loss:0.023534294461234576\n",
      "train loss:0.03243201054176455\n",
      "train loss:0.00902934407497053\n",
      "train loss:0.05450319311674878\n",
      "train loss:0.03830411506739518\n",
      "train loss:0.010790861304394259\n",
      "train loss:0.06957670403679866\n",
      "train loss:0.022206956135395303\n",
      "train loss:0.005744492698502717\n",
      "train loss:0.019564590193467582\n",
      "train loss:0.05676403568042652\n",
      "train loss:0.01364995375983341\n",
      "train loss:0.018543570047731314\n",
      "train loss:0.010054821754787677\n",
      "train loss:0.011157346979689333\n",
      "train loss:0.053337998596358245\n",
      "train loss:0.012227795297502448\n",
      "train loss:0.014599766262503136\n",
      "train loss:0.04866771345094725\n",
      "train loss:0.020412979905752176\n",
      "train loss:0.009302891393258426\n",
      "train loss:0.030392749815152154\n",
      "train loss:0.014711658792667153\n",
      "train loss:0.019341163114058375\n",
      "train loss:0.0700633339821711\n",
      "train loss:0.030698456006829414\n",
      "train loss:0.007326683811330203\n",
      "train loss:0.036266771242702826\n",
      "train loss:0.01789978330909317\n",
      "train loss:0.02836555353100004\n",
      "train loss:0.02259868623281591\n",
      "train loss:0.02900927380393636\n",
      "train loss:0.014551962809196642\n",
      "train loss:0.030622347551336967\n",
      "train loss:0.0067122810425027666\n",
      "train loss:0.014148253056994202\n",
      "train loss:0.03067251196422595\n",
      "train loss:0.08361879704490763\n",
      "train loss:0.005287347792133698\n",
      "train loss:0.011079810602043928\n",
      "train loss:0.02245476788426822\n",
      "train loss:0.015560395487553875\n",
      "train loss:0.00605186831348168\n",
      "train loss:0.05857194561573829\n",
      "train loss:0.0413210657006153\n",
      "train loss:0.005236125470929033\n",
      "train loss:0.02243574938847172\n",
      "train loss:0.0607391834730421\n",
      "train loss:0.009487932358806595\n",
      "train loss:0.05261829653383762\n",
      "train loss:0.01502597814429292\n",
      "train loss:0.020656911179211635\n",
      "train loss:0.04054286950869464\n",
      "train loss:0.04055874979357478\n",
      "train loss:0.007747338695319389\n",
      "train loss:0.007395090316089309\n",
      "train loss:0.037586142230321716\n",
      "train loss:0.038180760348211204\n",
      "train loss:0.011645251799903207\n",
      "train loss:0.07222886770521898\n",
      "train loss:0.01510411723904632\n",
      "train loss:0.040752259306384674\n",
      "train loss:0.024808364297311952\n",
      "train loss:0.06214488258186255\n",
      "train loss:0.16551068249160916\n",
      "train loss:0.02088345953175474\n",
      "train loss:0.012067656310038238\n",
      "train loss:0.012811479718255327\n",
      "train loss:0.03375379169921628\n",
      "train loss:0.023867939667868824\n",
      "train loss:0.060068420542496954\n",
      "train loss:0.01155793600438386\n",
      "train loss:0.030310681366981153\n",
      "train loss:0.02025808868317217\n",
      "train loss:0.016394815404024078\n",
      "train loss:0.05629195487729329\n",
      "train loss:0.02278182800816209\n",
      "train loss:0.02999221287027811\n",
      "train loss:0.027385826125386554\n",
      "train loss:0.01882098928984561\n",
      "train loss:0.024808314566089593\n",
      "train loss:0.014037142586093792\n",
      "train loss:0.00779939194584258\n",
      "train loss:0.038902856179969386\n",
      "train loss:0.010082485128621348\n",
      "train loss:0.024581074809407695\n",
      "train loss:0.06353924657935525\n",
      "train loss:0.010374148396875593\n",
      "train loss:0.1689838662826789\n",
      "train loss:0.03597463356748009\n",
      "train loss:0.05133415409034572\n",
      "train loss:0.02040259099425067\n",
      "train loss:0.013459585517977752\n",
      "train loss:0.031370290849266895\n",
      "train loss:0.007910582944348704\n",
      "train loss:0.06655088959900456\n",
      "train loss:0.020290415085620347\n",
      "train loss:0.009085920187179707\n",
      "train loss:0.02149334888960712\n",
      "train loss:0.004440535552610836\n",
      "train loss:0.009514990012567196\n",
      "train loss:0.0752110693842471\n",
      "train loss:0.011006265900311436\n",
      "train loss:0.022404047308147587\n",
      "train loss:0.02388135507916646\n",
      "train loss:0.057346415300717976\n",
      "train loss:0.10563901064904074\n",
      "train loss:0.052171758188800946\n",
      "train loss:0.03723588638918147\n",
      "train loss:0.008956946975353175\n",
      "train loss:0.02240400542595766\n",
      "train loss:0.16258002194440643\n",
      "train loss:0.02001523516759161\n",
      "train loss:0.057353068844791875\n",
      "train loss:0.012453618905415645\n",
      "train loss:0.00663150095300525\n",
      "train loss:0.07254533539936188\n",
      "train loss:0.020281851045645567\n",
      "train loss:0.045028500973102306\n",
      "train loss:0.052314379049052\n",
      "train loss:0.02236841810410405\n",
      "train loss:0.010375279871333591\n",
      "train loss:0.02132832923161259\n",
      "train loss:0.007359670172032059\n",
      "train loss:0.036314069734383864\n",
      "train loss:0.0024143972967211095\n",
      "train loss:0.02665537524049964\n",
      "train loss:0.012561956441198405\n",
      "train loss:0.011727694752175919\n",
      "train loss:0.025399593817205995\n",
      "train loss:0.02530603532758061\n",
      "train loss:0.015010880693603911\n",
      "train loss:0.047180185619913495\n",
      "train loss:0.005476961392053479\n",
      "train loss:0.04585724110521543\n",
      "train loss:0.011129194719646405\n",
      "train loss:0.011535844461110669\n",
      "train loss:0.032391111381064354\n",
      "train loss:0.03362982812146029\n",
      "train loss:0.004748573552212334\n",
      "train loss:0.036503395483606246\n",
      "train loss:0.11846595053444385\n",
      "train loss:0.10700672426652\n",
      "train loss:0.040379529003166395\n",
      "train loss:0.012078207011142685\n",
      "train loss:0.020313872333626595\n",
      "train loss:0.031841047739626656\n",
      "train loss:0.03298456553091846\n",
      "train loss:0.027236266159462313\n",
      "train loss:0.00531091813078793\n",
      "train loss:0.008768476398775286\n",
      "train loss:0.019439690911825066\n",
      "train loss:0.0053793918400581505\n",
      "train loss:0.040740917291180116\n",
      "train loss:0.017097555850215183\n",
      "train loss:0.020363430859166844\n",
      "train loss:0.027571919797696645\n",
      "train loss:0.03060255783160304\n",
      "train loss:0.029195145171935798\n",
      "train loss:0.007676161696433027\n",
      "train loss:0.014326543276209039\n",
      "train loss:0.012755717964378275\n",
      "train loss:0.026564509993714798\n",
      "train loss:0.03595420274645841\n",
      "train loss:0.0028428266371190135\n",
      "train loss:0.003317675224509244\n",
      "train loss:0.04282814316469553\n",
      "train loss:0.0013568366533131412\n",
      "train loss:0.10971090377900751\n",
      "train loss:0.031026977113939112\n",
      "train loss:0.02798575858247453\n",
      "train loss:0.01062329379375784\n",
      "train loss:0.018325860091540035\n",
      "train loss:0.003578094366123778\n",
      "train loss:0.07173377819111168\n",
      "train loss:0.06971799693766528\n",
      "train loss:0.04432134322821873\n",
      "train loss:0.022599870244520516\n",
      "train loss:0.01286705703281942\n",
      "train loss:0.05591591348211507\n",
      "train loss:0.005256910643569004\n",
      "train loss:0.014814635969691514\n",
      "train loss:0.028110267170096716\n",
      "train loss:0.004003954059467395\n",
      "train loss:0.014903098484897147\n",
      "train loss:0.014957764857687114\n",
      "train loss:0.05831440211580631\n",
      "train loss:0.004097587136964643\n",
      "train loss:0.06882387692004681\n",
      "train loss:0.012691350931040018\n",
      "train loss:0.036282197857503196\n",
      "train loss:0.006507169263326662\n",
      "train loss:0.10318809998494469\n",
      "train loss:0.01548023599297344\n",
      "train loss:0.03914027977349834\n",
      "train loss:0.00790430431343725\n",
      "train loss:0.05066372842615917\n",
      "train loss:0.004481558243680156\n",
      "train loss:0.014272155310225161\n",
      "train loss:0.01749338514776449\n",
      "train loss:0.030678662681818607\n",
      "train loss:0.025908438051552442\n",
      "train loss:0.0141282712400911\n",
      "train loss:0.017988987102935904\n",
      "train loss:0.04305591195399648\n",
      "train loss:0.054871690850240705\n",
      "train loss:0.020174854816471674\n",
      "train loss:0.004163381101700659\n",
      "train loss:0.03817870300246115\n",
      "train loss:0.019156193831685497\n",
      "train loss:0.03971941035282103\n",
      "train loss:0.035144218274428776\n",
      "train loss:0.004948957480980075\n",
      "train loss:0.009203258075726117\n",
      "train loss:0.03343283181997135\n",
      "train loss:0.021615260753511823\n",
      "train loss:0.0026618619433982135\n",
      "train loss:0.012646855249240758\n",
      "train loss:0.022769428691984183\n",
      "train loss:0.037102847617364654\n",
      "train loss:0.007490489349560204\n",
      "train loss:0.027894468617431434\n",
      "train loss:0.004003163884962522\n",
      "train loss:0.012590936269518467\n",
      "train loss:0.19483440007053743\n",
      "train loss:0.01702208032538487\n",
      "train loss:0.014533049434009175\n",
      "train loss:0.00724113333807712\n",
      "train loss:0.014531054799772378\n",
      "train loss:0.09358250751050642\n",
      "train loss:0.02893908460647441\n",
      "train loss:0.013379135592559844\n",
      "train loss:0.01729922274496396\n",
      "train loss:0.04226422267132832\n",
      "train loss:0.05527401594491498\n",
      "train loss:0.02576131260166416\n",
      "train loss:0.019584051019481942\n",
      "train loss:0.04947496032703222\n",
      "train loss:0.00600850387474727\n",
      "train loss:0.028892730542222488\n",
      "train loss:0.042484188485267624\n",
      "train loss:0.006052416807086913\n",
      "train loss:0.02727404835402211\n",
      "train loss:0.0113487171380524\n",
      "train loss:0.016668379488494964\n",
      "train loss:0.0302363785749188\n",
      "train loss:0.03769291951283902\n",
      "train loss:0.014441266569821467\n",
      "train loss:0.04369846184479795\n",
      "train loss:0.007159213099145377\n",
      "train loss:0.01352503380014602\n",
      "train loss:0.010253667888881523\n",
      "train loss:0.02389311116123327\n",
      "train loss:0.04892435690929783\n",
      "train loss:0.032758845277244694\n",
      "train loss:0.03513079549662082\n",
      "train loss:0.021639363172935574\n",
      "train loss:0.07244325015331339\n",
      "train loss:0.02994280397561587\n",
      "train loss:0.010026122770210462\n",
      "train loss:0.08450129631085058\n",
      "train loss:0.009154337701047446\n",
      "train loss:0.013097382363061872\n",
      "train loss:0.011055787322678843\n",
      "train loss:0.02869708726017632\n",
      "train loss:0.034308157537437475\n",
      "train loss:0.019696526200432676\n",
      "train loss:0.03557730089367436\n",
      "train loss:0.018307160184224677\n",
      "train loss:0.012685724787845994\n",
      "train loss:0.04769015831464547\n",
      "train loss:0.007086861420306075\n",
      "train loss:0.015279964683176484\n",
      "train loss:0.025668906293060675\n",
      "train loss:0.0035657537666821774\n",
      "train loss:0.028374239781548894\n",
      "train loss:0.0344757885271295\n",
      "train loss:0.023293789917462063\n",
      "train loss:0.014398067820677506\n",
      "train loss:0.006420652942493322\n",
      "train loss:0.023679827384613633\n",
      "train loss:0.03603697159004751\n",
      "train loss:0.009825172343959448\n",
      "train loss:0.018915557443533366\n",
      "train loss:0.0018895973162923352\n",
      "train loss:0.02108425002529546\n",
      "train loss:0.03541355374760038\n",
      "train loss:0.0023653795331073347\n",
      "train loss:0.00878133154961497\n",
      "train loss:0.00882291258727295\n",
      "train loss:0.020710263947914757\n",
      "train loss:0.032293588303971214\n",
      "train loss:0.008959220600263136\n",
      "train loss:0.05228842075575171\n",
      "train loss:0.019961385853105303\n",
      "train loss:0.009146414183858177\n",
      "train loss:0.009005709254132396\n",
      "train loss:0.018218885679211486\n",
      "train loss:0.022215547546951347\n",
      "train loss:0.012415711951337463\n",
      "train loss:0.004279876275955181\n",
      "train loss:0.05290093696144748\n",
      "train loss:0.005614243878875853\n",
      "train loss:0.024664682736361434\n",
      "train loss:0.00896636800556084\n",
      "train loss:0.011821990514581205\n",
      "train loss:0.012471184709462369\n",
      "train loss:0.0062992992584624775\n",
      "train loss:0.02362001359526595\n",
      "train loss:0.013977380536840778\n",
      "train loss:0.012549562051970798\n",
      "train loss:0.007681184224021768\n",
      "train loss:0.006927725034209448\n",
      "train loss:0.025449252354554076\n",
      "train loss:0.014592065661551907\n",
      "train loss:0.04411421657142571\n",
      "train loss:0.04517420697412275\n",
      "train loss:0.006355324055448881\n",
      "train loss:0.07086708090356976\n",
      "train loss:0.03065102289567908\n",
      "train loss:0.0038434084854728602\n",
      "train loss:0.007543561341695858\n",
      "train loss:0.004922526526713947\n",
      "train loss:0.05956275308817496\n",
      "train loss:0.07252444425285072\n",
      "train loss:0.029406737658969947\n",
      "train loss:0.07969876544111575\n",
      "train loss:0.018745412314518463\n",
      "train loss:0.04116034995670069\n",
      "train loss:0.01438126131911585\n",
      "train loss:0.015138856718992328\n",
      "train loss:0.015515224932206853\n",
      "train loss:0.007598721255781593\n",
      "train loss:0.016028423670846056\n",
      "train loss:0.017939640213567004\n",
      "train loss:0.037171343672082496\n",
      "train loss:0.016005842947293805\n",
      "train loss:0.009815338851820772\n",
      "train loss:0.011440011137482069\n",
      "train loss:0.023300381761238043\n",
      "train loss:0.02243528805075642\n",
      "train loss:0.046233222586270155\n",
      "train loss:0.015328586931225612\n",
      "train loss:0.0036023763315110864\n",
      "train loss:0.01623821156321757\n",
      "train loss:0.009997350884440053\n",
      "train loss:0.015334642271443898\n",
      "train loss:0.0067279929956609915\n",
      "train loss:0.01753300196444104\n",
      "train loss:0.06045447190344346\n",
      "train loss:0.015666639377162502\n",
      "train loss:0.016111440050086738\n",
      "train loss:0.0028116716426114198\n",
      "train loss:0.010759953707641556\n",
      "train loss:0.009134578979765995\n",
      "train loss:0.006624590018140416\n",
      "train loss:0.04122547997144923\n",
      "train loss:0.0045102544868517586\n",
      "train loss:0.0848024635746399\n",
      "train loss:0.10007712990485411\n",
      "train loss:0.009109565818950135\n",
      "train loss:0.0024163217632085657\n",
      "train loss:0.026880910899974103\n",
      "train loss:0.030577048242850638\n",
      "train loss:0.009306062154091896\n",
      "train loss:0.02687824487690955\n",
      "train loss:0.06774207978788456\n",
      "train loss:0.01246692046374587\n",
      "train loss:0.0032239454615509366\n",
      "train loss:0.01044519771677904\n",
      "train loss:0.033962166071632875\n",
      "train loss:0.010174900521129465\n",
      "train loss:0.04852384260516072\n",
      "train loss:0.03334127534643788\n",
      "train loss:0.024742185779145585\n",
      "train loss:0.022323392746430158\n",
      "train loss:0.02530602893987141\n",
      "train loss:0.0027317906552233404\n",
      "train loss:0.02192866387647225\n",
      "train loss:0.010605192903478227\n",
      "train loss:0.0273179250677844\n",
      "train loss:0.005353672101528806\n",
      "train loss:0.04068278940568673\n",
      "train loss:0.007290358804066456\n",
      "train loss:0.005777902706368571\n",
      "train loss:0.015129704778812827\n",
      "train loss:0.04107856232073666\n",
      "train loss:0.023448844599319684\n",
      "train loss:0.01856404735494179\n",
      "train loss:0.02023463502898797\n",
      "train loss:0.006120782304435196\n",
      "train loss:0.03286957581822946\n",
      "train loss:0.07999990637953043\n",
      "train loss:0.034549774522751826\n",
      "train loss:0.020635082626329165\n",
      "train loss:0.11787218713695542\n",
      "train loss:0.06480112562632445\n",
      "train loss:0.07882380971891219\n",
      "train loss:0.015189705933133832\n",
      "train loss:0.007872734724783845\n",
      "train loss:0.004782992033410372\n",
      "train loss:0.007505861067295722\n",
      "train loss:0.06865973354623119\n",
      "train loss:0.053314576683781416\n",
      "train loss:0.012290649632872122\n",
      "train loss:0.012730238641375725\n",
      "train loss:0.009768361801918533\n",
      "train loss:0.030839610322925523\n",
      "train loss:0.017750130481244207\n",
      "train loss:0.09531060968108349\n",
      "train loss:0.15956773288620132\n",
      "train loss:0.013860965182439969\n",
      "train loss:0.0162057471657676\n",
      "train loss:0.03403794807600125\n",
      "train loss:0.07058782684024277\n",
      "train loss:0.03523521983485822\n",
      "train loss:0.026390207728773363\n",
      "train loss:0.006876948352018486\n",
      "train loss:0.012390021529689443\n",
      "train loss:0.029731023504955646\n",
      "train loss:0.034095040398667294\n",
      "train loss:0.009967960959753167\n",
      "train loss:0.004954827501539262\n",
      "train loss:0.015794350264534015\n",
      "train loss:0.0117887680304517\n",
      "train loss:0.0040172971885206335\n",
      "train loss:0.035324274431476434\n",
      "train loss:0.03641161764964641\n",
      "train loss:0.011492121595653985\n",
      "train loss:0.005673144323922327\n",
      "train loss:0.03137862315042633\n",
      "train loss:0.02364151339596551\n",
      "train loss:0.021385626732202095\n",
      "train loss:0.014631766724074563\n",
      "train loss:0.03280006454077755\n",
      "train loss:0.027448405274262087\n",
      "train loss:0.01749435499437005\n",
      "train loss:0.026659774724945233\n",
      "train loss:0.0212803032990513\n",
      "train loss:0.009890945554390743\n",
      "train loss:0.014748099858274416\n",
      "train loss:0.010732700239249797\n",
      "train loss:0.010572984252682832\n",
      "train loss:0.0019908302646538434\n",
      "train loss:0.08931669963531849\n",
      "train loss:0.019474069824184335\n",
      "train loss:0.02462909760497451\n",
      "train loss:0.02755226031951186\n",
      "train loss:0.030012021416003728\n",
      "train loss:0.005611358156972366\n",
      "train loss:0.04516591412832156\n",
      "train loss:0.0857359387306778\n",
      "train loss:0.011595091401707945\n",
      "train loss:0.01399149896198232\n",
      "train loss:0.00711336957193328\n",
      "train loss:0.013931341891182532\n",
      "train loss:0.004630786731636041\n",
      "train loss:0.018259246858268977\n",
      "train loss:0.03232213181980736\n",
      "train loss:0.051264541772828076\n",
      "train loss:0.010641424516031997\n",
      "train loss:0.020348097480626045\n",
      "train loss:0.005005101000224341\n",
      "train loss:0.019124302009400827\n",
      "train loss:0.028274992465723917\n",
      "train loss:0.007017789828520928\n",
      "train loss:0.0040523614703245085\n",
      "train loss:0.008442163634040812\n",
      "train loss:0.020798184728008425\n",
      "train loss:0.027217239823803956\n",
      "train loss:0.056830585780040924\n",
      "train loss:0.03537778622162398\n",
      "train loss:0.04220879659162442\n",
      "train loss:0.04092728895271014\n",
      "train loss:0.008203019525641923\n",
      "train loss:0.04886126212620982\n",
      "train loss:0.011613981793831303\n",
      "train loss:0.0593806889080104\n",
      "train loss:0.01618381628779511\n",
      "train loss:0.013704896606231386\n",
      "train loss:0.05946342364672764\n",
      "train loss:0.012429396423300225\n",
      "train loss:0.035041924208184076\n",
      "train loss:0.0033549687421384816\n",
      "train loss:0.06577362107282758\n",
      "train loss:0.01674571309979504\n",
      "train loss:0.03111548553148853\n",
      "=== epoch:6, train acc:0.983, test acc:0.988 ===\n",
      "train loss:0.060038812669578834\n",
      "train loss:0.020580153547605257\n",
      "train loss:0.008667822741979126\n",
      "train loss:0.009342027612579636\n",
      "train loss:0.04453966531553715\n",
      "train loss:0.04505420155681662\n",
      "train loss:0.016757700305218136\n",
      "train loss:0.028240948158669014\n",
      "train loss:0.020301420115120775\n",
      "train loss:0.008342827912487093\n",
      "train loss:0.012807997163444962\n",
      "train loss:0.0025792944123694365\n",
      "train loss:0.031046074997846458\n",
      "train loss:0.002805601636363012\n",
      "train loss:0.010079135546247344\n",
      "train loss:0.013172220053661325\n",
      "train loss:0.016327922572418635\n",
      "train loss:0.013879124176470326\n",
      "train loss:0.02060678810304005\n",
      "train loss:0.026169020129228154\n",
      "train loss:0.0017677051897622093\n",
      "train loss:0.0010693665478591606\n",
      "train loss:0.006152998114066128\n",
      "train loss:0.0051773770222526775\n",
      "train loss:0.043178697147701596\n",
      "train loss:0.02055812350406476\n",
      "train loss:0.028026832510105727\n",
      "train loss:0.03664000610622118\n",
      "train loss:0.015256635470148758\n",
      "train loss:0.010039320350108676\n",
      "train loss:0.00872037980432216\n",
      "train loss:0.008093456866687653\n",
      "train loss:0.011093185176827234\n",
      "train loss:0.011135929521844296\n",
      "train loss:0.012206832873483857\n",
      "train loss:0.08822898773146985\n",
      "train loss:0.04633018683522466\n",
      "train loss:0.0684124055811795\n",
      "train loss:0.04936650384632383\n",
      "train loss:0.051804355342992416\n",
      "train loss:0.022402069937922424\n",
      "train loss:0.0067425561017862845\n",
      "train loss:0.011093733046832371\n",
      "train loss:0.018523068580195284\n",
      "train loss:0.012121551058407757\n",
      "train loss:0.03031805369848255\n",
      "train loss:0.03209452284791664\n",
      "train loss:0.009183227499646278\n",
      "train loss:0.024630033117459548\n",
      "train loss:0.009864686716423193\n",
      "train loss:0.04373996116654721\n",
      "train loss:0.03225390788865581\n",
      "train loss:0.11967328243793586\n",
      "train loss:0.08816189366975699\n",
      "train loss:0.017739778479805922\n",
      "train loss:0.006849621634261165\n",
      "train loss:0.012842124307921114\n",
      "train loss:0.0066513530204867655\n",
      "train loss:0.02136961043682958\n",
      "train loss:0.0049444618635919\n",
      "train loss:0.005467827181641667\n",
      "train loss:0.04525905724156183\n",
      "train loss:0.020187058732070728\n",
      "train loss:0.03964071522444521\n",
      "train loss:0.0038831174322468587\n",
      "train loss:0.044723573111742285\n",
      "train loss:0.025352972704864096\n",
      "train loss:0.0395798960402409\n",
      "train loss:0.003611720570001592\n",
      "train loss:0.022129364106930904\n",
      "train loss:0.007975424376857509\n",
      "train loss:0.03340035936074723\n",
      "train loss:0.02845729387951783\n",
      "train loss:0.01483019407220212\n",
      "train loss:0.010707603976803608\n",
      "train loss:0.01211520485176961\n",
      "train loss:0.08864031738628332\n",
      "train loss:0.07200471780196685\n",
      "train loss:0.02272523534030828\n",
      "train loss:0.02716500110499725\n",
      "train loss:0.037888818633789054\n",
      "train loss:0.02978519008672869\n",
      "train loss:0.004282309467944252\n",
      "train loss:0.015388328658246502\n",
      "train loss:0.01800752134768304\n",
      "train loss:0.03913871763808789\n",
      "train loss:0.005105641448242478\n",
      "train loss:0.012560454334143666\n",
      "train loss:0.00986365811411091\n",
      "train loss:0.03232305248840978\n",
      "train loss:0.024198233239612614\n",
      "train loss:0.0536645880558904\n",
      "train loss:0.019697807654527433\n",
      "train loss:0.004763070429722435\n",
      "train loss:0.007458504921507897\n",
      "train loss:0.05211845043200821\n",
      "train loss:0.03687808336469557\n",
      "train loss:0.015428038495653511\n",
      "train loss:0.007307265099473754\n",
      "train loss:0.0075563866999563516\n",
      "train loss:0.0030825640899232254\n",
      "train loss:0.02014642458428193\n",
      "train loss:0.004081273933887186\n",
      "train loss:0.04903975872519551\n",
      "train loss:0.010995118055856186\n",
      "train loss:0.03226630538391929\n",
      "train loss:0.007943475489808931\n",
      "train loss:0.026292896455711444\n",
      "train loss:0.0034961122021534468\n",
      "train loss:0.016909539391239296\n",
      "train loss:0.016297312555422983\n",
      "train loss:0.00789878204413272\n",
      "train loss:0.019115610521953624\n",
      "train loss:0.00913984191605278\n",
      "train loss:0.019923173600434954\n",
      "train loss:0.017588011917908753\n",
      "train loss:0.008651888742243468\n",
      "train loss:0.009231246478130953\n",
      "train loss:0.03315114031124542\n",
      "train loss:0.039018620020178536\n",
      "train loss:0.0063849888025270096\n",
      "train loss:0.03111405449788737\n",
      "train loss:0.008604236170000397\n",
      "train loss:0.0080264528110264\n",
      "train loss:0.017262369213161682\n",
      "train loss:0.02337404225423886\n",
      "train loss:0.018691724484402913\n",
      "train loss:0.00894279783784209\n",
      "train loss:0.00584593954069563\n",
      "train loss:0.019951607577782568\n",
      "train loss:0.0181475638060095\n",
      "train loss:0.010631699279352848\n",
      "train loss:0.017800469862363916\n",
      "train loss:0.04192976249263977\n",
      "train loss:0.0536005154542817\n",
      "train loss:0.010341420044177435\n",
      "train loss:0.015997462743429846\n",
      "train loss:0.023891774086452558\n",
      "train loss:0.015549292982150227\n",
      "train loss:0.011846947336217389\n",
      "train loss:0.04338963844389286\n",
      "train loss:0.014017313422405642\n",
      "train loss:0.023696434932058478\n",
      "train loss:0.0061899788722961065\n",
      "train loss:0.018674470373814443\n",
      "train loss:0.03555703121370919\n",
      "train loss:0.020334686726386542\n",
      "train loss:0.028301776443271826\n",
      "train loss:0.015487853060501227\n",
      "train loss:0.021450339103265742\n",
      "train loss:0.017527916855479005\n",
      "train loss:0.08807437747675859\n",
      "train loss:0.03559417738507609\n",
      "train loss:0.0083810574504942\n",
      "train loss:0.01965259537783429\n",
      "train loss:0.012946819889626409\n",
      "train loss:0.04443094978864151\n",
      "train loss:0.01363037833575593\n",
      "train loss:0.06074509980886509\n",
      "train loss:0.11768176928724122\n",
      "train loss:0.017621441520903048\n",
      "train loss:0.010184863811765225\n",
      "train loss:0.06114355521379236\n",
      "train loss:0.014144283606210072\n",
      "train loss:0.0510432665554913\n",
      "train loss:0.03571088239333945\n",
      "train loss:0.012266096959260502\n",
      "train loss:0.051080211534617545\n",
      "train loss:0.06744065573235086\n",
      "train loss:0.017426386114458684\n",
      "train loss:0.01809306091337065\n",
      "train loss:0.0496624292759273\n",
      "train loss:0.023050598630758156\n",
      "train loss:0.007151761881222455\n",
      "train loss:0.01238306902626454\n",
      "train loss:0.025220848282050387\n",
      "train loss:0.024840306519375667\n",
      "train loss:0.025467062581183537\n",
      "train loss:0.024257756229331493\n",
      "train loss:0.013558007636922713\n",
      "train loss:0.012026179722370285\n",
      "train loss:0.021069781179080708\n",
      "train loss:0.06576130243944055\n",
      "train loss:0.002939145184207601\n",
      "train loss:0.006199603157317305\n",
      "train loss:0.012412527360363941\n",
      "train loss:0.02161485613329186\n",
      "train loss:0.021256095192258576\n",
      "train loss:0.006263264134168566\n",
      "train loss:0.009541868987823703\n",
      "train loss:0.011779755001994761\n",
      "train loss:0.015071464955431914\n",
      "train loss:0.01119831855681068\n",
      "train loss:0.0061116444104644665\n",
      "train loss:0.0037979106755354776\n",
      "train loss:0.020403910309194462\n",
      "train loss:0.005407081298402367\n",
      "train loss:0.052428931812141685\n",
      "train loss:0.006773217129096061\n",
      "train loss:0.013512974447806041\n",
      "train loss:0.015822745989329628\n",
      "train loss:0.061889524700025296\n",
      "train loss:0.017384359504151257\n",
      "train loss:0.004298458323712694\n",
      "train loss:0.014448413422184852\n",
      "train loss:0.007892542244405621\n",
      "train loss:0.009255625286475572\n",
      "train loss:0.010731757970645024\n",
      "train loss:0.03798981386959924\n",
      "train loss:0.013120311134073425\n",
      "train loss:0.002331459598166966\n",
      "train loss:0.012580306398258315\n",
      "train loss:0.007164572523190413\n",
      "train loss:0.009648400399407765\n",
      "train loss:0.025791383501217357\n",
      "train loss:0.02790997252665396\n",
      "train loss:0.01739313134381878\n",
      "train loss:0.005435996274550389\n",
      "train loss:0.026509699833695603\n",
      "train loss:0.031767680874995194\n",
      "train loss:0.001010328804238661\n",
      "train loss:0.025120820405772622\n",
      "train loss:0.006069461358318119\n",
      "train loss:0.010236580502647865\n",
      "train loss:0.01487399921907636\n",
      "train loss:0.027016286553863803\n",
      "train loss:0.007907297326371491\n",
      "train loss:0.016974978305405942\n",
      "train loss:0.004710236759801168\n",
      "train loss:0.00972438716312917\n",
      "train loss:0.004671430262234585\n",
      "train loss:0.03227372250296957\n",
      "train loss:0.006856784720227347\n",
      "train loss:0.011775667892151287\n",
      "train loss:0.014299002358079243\n",
      "train loss:0.007322649175162987\n",
      "train loss:0.010400748875432748\n",
      "train loss:0.0009638821324667379\n",
      "train loss:0.003987148220515428\n",
      "train loss:0.02338647336176685\n",
      "train loss:0.006170132823918966\n",
      "train loss:0.006807797895307074\n",
      "train loss:0.01142578513898622\n",
      "train loss:0.012278101824313069\n",
      "train loss:0.0022599576346173816\n",
      "train loss:0.018094375041976415\n",
      "train loss:0.017537845806956887\n",
      "train loss:0.027067514453063074\n",
      "train loss:0.04935391361381529\n",
      "train loss:0.03594727091814873\n",
      "train loss:0.03787773057605577\n",
      "train loss:0.0023467019907829198\n",
      "train loss:0.012104059701700762\n",
      "train loss:0.019886538361435113\n",
      "train loss:0.005000803720663088\n",
      "train loss:0.026179343259114623\n",
      "train loss:0.004434368228153345\n",
      "train loss:0.02617283352157561\n",
      "train loss:0.014848500061976664\n",
      "train loss:0.01658990797986323\n",
      "train loss:0.03132796010846727\n",
      "train loss:0.01250458302915557\n",
      "train loss:0.027197972101325497\n",
      "train loss:0.010971905453638613\n",
      "train loss:0.008824087112922145\n",
      "train loss:0.008283210204405742\n",
      "train loss:0.009384244338479062\n",
      "train loss:0.01960318280563683\n",
      "train loss:0.012937193125646817\n",
      "train loss:0.07081041815862936\n",
      "train loss:0.036337104027209015\n",
      "train loss:0.021879548689858308\n",
      "train loss:0.005812941378717909\n",
      "train loss:0.011805741000721078\n",
      "train loss:0.010773491698771509\n",
      "train loss:0.0015616264792371805\n",
      "train loss:0.022461151195657055\n",
      "train loss:0.006611926913898306\n",
      "train loss:0.006119386060096223\n",
      "train loss:0.06585275464634033\n",
      "train loss:0.016237642496340864\n",
      "train loss:0.02183898547526908\n",
      "train loss:0.01683495866969083\n",
      "train loss:0.008198798723004958\n",
      "train loss:0.0044999084700815565\n",
      "train loss:0.012936163219273157\n",
      "train loss:0.009876764434625505\n",
      "train loss:0.012658040769227741\n",
      "train loss:0.0029331999595735908\n",
      "train loss:0.016289924201406406\n",
      "train loss:0.023891765321662043\n",
      "train loss:0.012917938469800603\n",
      "train loss:0.026478836103608815\n",
      "train loss:0.007710196384957502\n",
      "train loss:0.009067504730392051\n",
      "train loss:0.0030878798342049035\n",
      "train loss:0.010377894029882389\n",
      "train loss:0.0272784001591368\n",
      "train loss:0.0394450196621453\n",
      "train loss:0.007830774513150026\n",
      "train loss:0.007170175617010888\n",
      "train loss:0.018250958639109645\n",
      "train loss:0.01930932530379641\n",
      "train loss:0.027616476818714705\n",
      "train loss:0.01119470486760723\n",
      "train loss:0.005743727495155721\n",
      "train loss:0.008113557396502791\n",
      "train loss:0.004488274313079578\n",
      "train loss:0.011072947992102676\n",
      "train loss:0.026190635027129386\n",
      "train loss:0.010950963536318763\n",
      "train loss:0.011444049598447642\n",
      "train loss:0.00846969340460841\n",
      "train loss:0.002576618703825096\n",
      "train loss:0.02022205552408153\n",
      "train loss:0.0028960500816048573\n",
      "train loss:0.019917986801343112\n",
      "train loss:0.007251801564040191\n",
      "train loss:0.009128726763579504\n",
      "train loss:0.010101452172500908\n",
      "train loss:0.00941996322758374\n",
      "train loss:0.06654574182085544\n",
      "train loss:0.06632031298424304\n",
      "train loss:0.008041832235286676\n",
      "train loss:0.01881230102345984\n",
      "train loss:0.004167063401033642\n",
      "train loss:0.06110867240939646\n",
      "train loss:0.042946338517353216\n",
      "train loss:0.012892951425033584\n",
      "train loss:0.02730984662126117\n",
      "train loss:0.00208303412886702\n",
      "train loss:0.004732206504701343\n",
      "train loss:0.06324545440457001\n",
      "train loss:0.06991392893816689\n",
      "train loss:0.02436233378088808\n",
      "train loss:0.00585063486817235\n",
      "train loss:0.006319884814503443\n",
      "train loss:0.044130615746532376\n",
      "train loss:0.015016380642880791\n",
      "train loss:0.0321727119125054\n",
      "train loss:0.003993699742862125\n",
      "train loss:0.013795946069972894\n",
      "train loss:0.01270232401313482\n",
      "train loss:0.0072248022704692995\n",
      "train loss:0.010753893631216475\n",
      "train loss:0.004818820011435638\n",
      "train loss:0.05894438965310514\n",
      "train loss:0.005416078347916162\n",
      "train loss:0.011770768385042768\n",
      "train loss:0.004727204545815362\n",
      "train loss:0.012820718350639337\n",
      "train loss:0.06085273955183736\n",
      "train loss:0.007299721479098265\n",
      "train loss:0.04068128300604796\n",
      "train loss:0.048539377873127273\n",
      "train loss:0.027506799763587567\n",
      "train loss:0.006801668470765409\n",
      "train loss:0.04241796213111969\n",
      "train loss:0.022039173203090207\n",
      "train loss:0.006958047081231033\n",
      "train loss:0.01243592983013951\n",
      "train loss:0.007649972772091224\n",
      "train loss:0.012858391200101542\n",
      "train loss:0.0033333023168993486\n",
      "train loss:0.0376008055235792\n",
      "train loss:0.037685233769286695\n",
      "train loss:0.015340034179746751\n",
      "train loss:0.011024716101053655\n",
      "train loss:0.021446781841587204\n",
      "train loss:0.0045394938401304725\n",
      "train loss:0.024683093882558217\n",
      "train loss:0.035158620429186375\n",
      "train loss:0.0294639994745671\n",
      "train loss:0.032708394572480655\n",
      "train loss:0.018817390207837154\n",
      "train loss:0.03713472462421288\n",
      "train loss:0.020048668236587193\n",
      "train loss:0.011683317489718186\n",
      "train loss:0.02469294749311167\n",
      "train loss:0.005541539171626693\n",
      "train loss:0.07634243647717594\n",
      "train loss:0.01794138860311243\n",
      "train loss:0.012524012704727517\n",
      "train loss:0.012470427437249599\n",
      "train loss:0.020597814990167378\n",
      "train loss:0.0194014580330799\n",
      "train loss:0.021305338953936666\n",
      "train loss:0.01934381273520096\n",
      "train loss:0.0357462159730687\n",
      "train loss:0.01659162918195194\n",
      "train loss:0.015036864088743716\n",
      "train loss:0.062653154754847\n",
      "train loss:0.009749455425964018\n",
      "train loss:0.011566769848263093\n",
      "train loss:0.0627980811460222\n",
      "train loss:0.11907294134695984\n",
      "train loss:0.002685834769589895\n",
      "train loss:0.020038608060370517\n",
      "train loss:0.018371374160144255\n",
      "train loss:0.00539325696900925\n",
      "train loss:0.00720120638263055\n",
      "train loss:0.006905080686761204\n",
      "train loss:0.019222396216971457\n",
      "train loss:0.00593702823855186\n",
      "train loss:0.011459949925027881\n",
      "train loss:0.08072768501360417\n",
      "train loss:0.01827983782973511\n",
      "train loss:0.002864982871472577\n",
      "train loss:0.004610343723537283\n",
      "train loss:0.019269084950213695\n",
      "train loss:0.016731062213385293\n",
      "train loss:0.01546283526284459\n",
      "train loss:0.013784843092329403\n",
      "train loss:0.006654346884506656\n",
      "train loss:0.021817246770902483\n",
      "train loss:0.010449976799115135\n",
      "train loss:0.006047447276337698\n",
      "train loss:0.006232370466106436\n",
      "train loss:0.03321878202192618\n",
      "train loss:0.013304946110190634\n",
      "train loss:0.0029261891870882234\n",
      "train loss:0.012064175469543718\n",
      "train loss:0.009396963668186743\n",
      "train loss:0.00442740953951738\n",
      "train loss:0.0074198064783309115\n",
      "train loss:0.0016145454223269273\n",
      "train loss:0.029883082622000855\n",
      "train loss:0.026504404857656906\n",
      "train loss:0.008440185590624004\n",
      "train loss:0.006270545408031509\n",
      "train loss:0.03526962186947728\n",
      "train loss:0.03890632292806985\n",
      "train loss:0.010133402474641144\n",
      "train loss:0.015395369579067739\n",
      "train loss:0.03695795617149265\n",
      "train loss:0.005894442744428793\n",
      "train loss:0.02601247793539929\n",
      "train loss:0.0018547880765958757\n",
      "train loss:0.002234076530596932\n",
      "train loss:0.0009166665984180355\n",
      "train loss:0.006397757962182929\n",
      "train loss:0.021170090936108506\n",
      "train loss:0.009927946253772735\n",
      "train loss:0.012605454317372826\n",
      "train loss:0.03156703646948758\n",
      "train loss:0.02723687258328221\n",
      "train loss:0.05986167475580641\n",
      "train loss:0.022235665760112787\n",
      "train loss:0.0029513453124706424\n",
      "train loss:0.01084072925916408\n",
      "train loss:0.005791402391544231\n",
      "train loss:0.03250393194273842\n",
      "train loss:0.01794200676737048\n",
      "train loss:0.03193281468726751\n",
      "train loss:0.006854961775674438\n",
      "train loss:0.04036428834279539\n",
      "train loss:0.018392185866319084\n",
      "train loss:0.0068183160156039665\n",
      "train loss:0.015795440126370398\n",
      "train loss:0.035759772088492875\n",
      "train loss:0.00864278094161438\n",
      "train loss:0.006774760293215596\n",
      "train loss:0.01477919957344042\n",
      "train loss:0.0030756250037623158\n",
      "train loss:0.004101745415104994\n",
      "train loss:0.02678013586265081\n",
      "train loss:0.002866646165761274\n",
      "train loss:0.005131020086633599\n",
      "train loss:0.005763782641120279\n",
      "train loss:0.010726423919574724\n",
      "train loss:0.005984837928732401\n",
      "train loss:0.003122079199804706\n",
      "train loss:0.02713504811394689\n",
      "train loss:0.047631928755833226\n",
      "train loss:0.005238097525217756\n",
      "train loss:0.025720676572946286\n",
      "train loss:0.01716679144897507\n",
      "train loss:0.019306978097067697\n",
      "train loss:0.00385846462023098\n",
      "train loss:0.013166147961948068\n",
      "train loss:0.015628466963788838\n",
      "train loss:0.029485036656377552\n",
      "train loss:0.0158616907398114\n",
      "train loss:0.014497706016734368\n",
      "train loss:0.018268985177982363\n",
      "train loss:0.014237182925205078\n",
      "train loss:0.0923517316289786\n",
      "train loss:0.02843343683201164\n",
      "train loss:0.005623696309606751\n",
      "train loss:0.024165402041542237\n",
      "train loss:0.012151621827348958\n",
      "train loss:0.032593954189345846\n",
      "train loss:0.01923100833853548\n",
      "train loss:0.024876935480009542\n",
      "train loss:0.004812449171803551\n",
      "train loss:0.0019930594492336712\n",
      "train loss:0.009301665514425761\n",
      "train loss:0.02787098698424714\n",
      "train loss:0.025109882635134285\n",
      "train loss:0.04427948452683363\n",
      "train loss:0.011990194888834104\n",
      "train loss:0.011068031687620187\n",
      "train loss:0.00730357536481261\n",
      "train loss:0.14052825975671795\n",
      "train loss:0.004593637160012122\n",
      "train loss:0.09922095304699972\n",
      "train loss:0.02231212193413753\n",
      "train loss:0.018396147476221834\n",
      "train loss:0.011924065084743024\n",
      "train loss:0.018519357263735676\n",
      "train loss:0.008953652001550273\n",
      "train loss:0.006757710649270689\n",
      "train loss:0.01030835119891635\n",
      "train loss:0.042982128402514946\n",
      "train loss:0.02908768067286889\n",
      "train loss:0.035784802443390384\n",
      "train loss:0.05186954129761693\n",
      "train loss:0.014819631052149064\n",
      "train loss:0.01518963901863686\n",
      "train loss:0.054254582068505995\n",
      "train loss:0.008627069333805528\n",
      "train loss:0.012233667989842862\n",
      "train loss:0.034112235834980326\n",
      "train loss:0.0022008152167289075\n",
      "train loss:0.037670890467298414\n",
      "train loss:0.002588273102847749\n",
      "train loss:0.006419752392006336\n",
      "train loss:0.021075603638010133\n",
      "train loss:0.020025196097163803\n",
      "train loss:0.003601226965467419\n",
      "train loss:0.009236980730417569\n",
      "train loss:0.00626409640821116\n",
      "train loss:0.00278524137918923\n",
      "train loss:0.007000467044439947\n",
      "train loss:0.016979218672582033\n",
      "train loss:0.008697277405922887\n",
      "train loss:0.022222252466940096\n",
      "train loss:0.017355874915016282\n",
      "train loss:0.01623832200390923\n",
      "train loss:0.01763064236812062\n",
      "train loss:0.0040832921236812385\n",
      "train loss:0.016728295340514857\n",
      "train loss:0.0073910583686787375\n",
      "train loss:0.013100937166153544\n",
      "train loss:0.0014213561306670828\n",
      "train loss:0.022056163156879072\n",
      "train loss:0.044820313795674284\n",
      "train loss:0.03566225038772625\n",
      "train loss:0.0008806534822438085\n",
      "train loss:0.0046076597980276865\n",
      "train loss:0.027865035998693565\n",
      "train loss:0.003166192426849163\n",
      "train loss:0.0063592768669239975\n",
      "train loss:0.05342610634164433\n",
      "train loss:0.015018573789302405\n",
      "train loss:0.022048809175830738\n",
      "train loss:0.01139411671647842\n",
      "train loss:0.011298781753438528\n",
      "train loss:0.008064739762626864\n",
      "train loss:0.06655951615859543\n",
      "train loss:0.01626331835596759\n",
      "train loss:0.013329519778235726\n",
      "train loss:0.016191778005493943\n",
      "train loss:0.018808224680003212\n",
      "train loss:0.021177774722441433\n",
      "train loss:0.041563993982053356\n",
      "train loss:0.0071632567407594215\n",
      "train loss:0.011445476499848468\n",
      "train loss:0.00674429168481575\n",
      "train loss:0.011423946456482204\n",
      "train loss:0.01529865135961495\n",
      "train loss:0.002071493440206281\n",
      "train loss:0.01244043159104931\n",
      "train loss:0.008342127824500193\n",
      "train loss:0.01796051598864497\n",
      "train loss:0.05367478141609419\n",
      "train loss:0.0011111936785382177\n",
      "train loss:0.007654544719423684\n",
      "train loss:0.004442374883545084\n",
      "train loss:0.0060922885486009385\n",
      "train loss:0.0186293599468208\n",
      "train loss:0.04335892074706965\n",
      "train loss:0.012830865689882976\n",
      "train loss:0.040351808455210095\n",
      "train loss:0.005203233438570182\n",
      "train loss:0.019215407790160562\n",
      "train loss:0.05793086441593924\n",
      "train loss:0.0036255484201041088\n",
      "train loss:0.0031433362372861955\n",
      "train loss:0.04338089523360884\n",
      "train loss:0.029791652987742667\n",
      "train loss:0.012942530519454407\n",
      "train loss:0.011497649802262502\n",
      "train loss:0.006079220013500795\n",
      "train loss:0.012550301078939927\n",
      "train loss:0.02112795826858456\n",
      "train loss:0.004946112062951682\n",
      "train loss:0.031684931409258474\n",
      "train loss:0.018016520984145336\n",
      "train loss:0.006904418982450904\n",
      "=== epoch:7, train acc:0.986, test acc:0.987 ===\n",
      "train loss:0.0036807350735999877\n",
      "train loss:0.052451813047544905\n",
      "train loss:0.005359036009109045\n",
      "train loss:0.005631104643271899\n",
      "train loss:0.00926098776553122\n",
      "train loss:0.022930812148462112\n",
      "train loss:0.02086278269299063\n",
      "train loss:0.022503991875547497\n",
      "train loss:0.024443813005018963\n",
      "train loss:0.012801999398189805\n",
      "train loss:0.01806337389344523\n",
      "train loss:0.00532351286565187\n",
      "train loss:0.012290438313456562\n",
      "train loss:0.044030236043410526\n",
      "train loss:0.011986289520509327\n",
      "train loss:0.04675363361327214\n",
      "train loss:0.049550289362128144\n",
      "train loss:0.008300120762937862\n",
      "train loss:0.00917268571579377\n",
      "train loss:0.003199283810045224\n",
      "train loss:0.0063249276968677945\n",
      "train loss:0.006252577714614151\n",
      "train loss:0.016538151292805493\n",
      "train loss:0.022587469324135946\n",
      "train loss:0.011364342598356846\n",
      "train loss:0.0050301625464439954\n",
      "train loss:0.015064702786284809\n",
      "train loss:0.026925314525864268\n",
      "train loss:0.011302870204784947\n",
      "train loss:0.008623693174566831\n",
      "train loss:0.012298074752797445\n",
      "train loss:0.009305541331063608\n",
      "train loss:0.007756045042638585\n",
      "train loss:0.02435720824944363\n",
      "train loss:0.001537815788460758\n",
      "train loss:0.00920669161465017\n",
      "train loss:0.0023588757347720434\n",
      "train loss:0.01209510540545115\n",
      "train loss:0.008634770494645228\n",
      "train loss:0.041919191725491016\n",
      "train loss:0.03427302941476987\n",
      "train loss:0.007450897801676464\n",
      "train loss:0.03304901440929662\n",
      "train loss:0.006815993299771937\n",
      "train loss:0.0204890496439777\n",
      "train loss:0.004600805476783625\n",
      "train loss:0.004441993158220913\n",
      "train loss:0.007083515209463349\n",
      "train loss:0.01253719912560911\n",
      "train loss:0.0025095708438890143\n",
      "train loss:0.005120897235121956\n",
      "train loss:0.02831677820461777\n",
      "train loss:0.06195462022488742\n",
      "train loss:0.011054512677983042\n",
      "train loss:0.008601426442455389\n",
      "train loss:0.04477775067316456\n",
      "train loss:0.013560763277595658\n",
      "train loss:0.017169816497754366\n",
      "train loss:0.00685348378574627\n",
      "train loss:0.02001368361952118\n",
      "train loss:0.00799673455101075\n",
      "train loss:0.026775257754315166\n",
      "train loss:0.01782989249275209\n",
      "train loss:0.007415925754447904\n",
      "train loss:0.02344494487107868\n",
      "train loss:0.011432836587382563\n",
      "train loss:0.0055951139845664966\n",
      "train loss:0.012295210022574332\n",
      "train loss:0.023468542418953017\n",
      "train loss:0.010807713500695846\n",
      "train loss:0.01393934859356078\n",
      "train loss:0.011617245697493197\n",
      "train loss:0.011332157438626802\n",
      "train loss:0.031179114493879504\n",
      "train loss:0.026549013755544252\n",
      "train loss:0.0024782087087729574\n",
      "train loss:0.010125238871662197\n",
      "train loss:0.05693395392525351\n",
      "train loss:0.03737038307501131\n",
      "train loss:0.025277654970106086\n",
      "train loss:0.013696257943897325\n",
      "train loss:0.006264644995668134\n",
      "train loss:0.0346632357430152\n",
      "train loss:0.004955554593287976\n",
      "train loss:0.011029787790610266\n",
      "train loss:0.03357003575761055\n",
      "train loss:0.010244269327726348\n",
      "train loss:0.003805121090963856\n",
      "train loss:0.035336578330471505\n",
      "train loss:0.008118663141305714\n",
      "train loss:0.008435404321910187\n",
      "train loss:0.03702933726548865\n",
      "train loss:0.006475770711764636\n",
      "train loss:0.05005230806774496\n",
      "train loss:0.009754857748763373\n",
      "train loss:0.002118849766652861\n",
      "train loss:0.007733316929534154\n",
      "train loss:0.026040912533867693\n",
      "train loss:0.00892378472353604\n",
      "train loss:0.007268240778338158\n",
      "train loss:0.022097980707113662\n",
      "train loss:0.04484847614690093\n",
      "train loss:0.017009522003725082\n",
      "train loss:0.013840418303619375\n",
      "train loss:0.024232495534985837\n",
      "train loss:0.02006559823746436\n",
      "train loss:0.01712294482483433\n",
      "train loss:0.04965908205089448\n",
      "train loss:0.025243617771456107\n",
      "train loss:0.03125535375213766\n",
      "train loss:0.03326531460200852\n",
      "train loss:0.0034708315780716107\n",
      "train loss:0.02588561002132433\n",
      "train loss:0.012346246988820834\n",
      "train loss:0.016245143871384548\n",
      "train loss:0.17239678215394708\n",
      "train loss:0.004963948937868731\n",
      "train loss:0.004082201932266939\n",
      "train loss:0.04934190801970659\n",
      "train loss:0.03027205475864404\n",
      "train loss:0.016523353783777124\n",
      "train loss:0.019680330171151336\n",
      "train loss:0.009581722575060224\n",
      "train loss:0.02025728931460596\n",
      "train loss:0.010960369101434672\n",
      "train loss:0.06550827899493487\n",
      "train loss:0.005564937420896116\n",
      "train loss:0.008659124494564957\n",
      "train loss:0.04982036714218773\n",
      "train loss:0.01869974441781292\n",
      "train loss:0.011812512971131261\n",
      "train loss:0.020724695869392434\n",
      "train loss:0.012930901279296754\n",
      "train loss:0.011924519098819744\n",
      "train loss:0.01795040154899505\n",
      "train loss:0.015551174537178226\n",
      "train loss:0.01262879557630871\n",
      "train loss:0.024913837134943703\n",
      "train loss:0.021870818244640135\n",
      "train loss:0.018706266679211214\n",
      "train loss:0.01868867446397538\n",
      "train loss:0.013206307852771635\n",
      "train loss:0.004294487530774837\n",
      "train loss:0.018793751739299466\n",
      "train loss:0.008098213311967285\n",
      "train loss:0.051567659453737945\n",
      "train loss:0.0022340174788122173\n",
      "train loss:0.0035467749061268896\n",
      "train loss:0.008820620128357892\n",
      "train loss:0.010451239270487802\n",
      "train loss:0.020657455239873786\n",
      "train loss:0.004282632557073176\n",
      "train loss:0.01697157536243353\n",
      "train loss:0.027443064622948102\n",
      "train loss:0.005538211134712625\n",
      "train loss:0.012935065292669492\n",
      "train loss:0.005070780999484471\n",
      "train loss:0.00559365022672444\n",
      "train loss:0.0073527716290102685\n",
      "train loss:0.023435487280292926\n",
      "train loss:0.004164990803413455\n",
      "train loss:0.014682462279965001\n",
      "train loss:0.02298033103661929\n",
      "train loss:0.006772933229922989\n",
      "train loss:0.01671290879800312\n",
      "train loss:0.005762469908838313\n",
      "train loss:0.010958752414746037\n",
      "train loss:0.04603673673047397\n",
      "train loss:0.006285655491094909\n",
      "train loss:0.009585726254134059\n",
      "train loss:0.011976102728348698\n",
      "train loss:0.014532074886475961\n",
      "train loss:0.028522700079765654\n",
      "train loss:0.0035278613199197467\n",
      "train loss:0.023904623410428413\n",
      "train loss:0.0034953771743449612\n",
      "train loss:0.007874485681175061\n",
      "train loss:0.00449660213942123\n",
      "train loss:0.05326861344769187\n",
      "train loss:0.00632004230394258\n",
      "train loss:0.025174761350932787\n",
      "train loss:0.013098870264480741\n",
      "train loss:0.009674208680804946\n",
      "train loss:0.00463235872272769\n",
      "train loss:0.005375883415970261\n",
      "train loss:0.007738437390209808\n",
      "train loss:0.06219902392059049\n",
      "train loss:0.007875715237805246\n",
      "train loss:0.005949133927743619\n",
      "train loss:0.008720213260750655\n",
      "train loss:0.007491809928262007\n",
      "train loss:0.058123795651272264\n",
      "train loss:0.012201334788571066\n",
      "train loss:0.03162794112724006\n",
      "train loss:0.01718508055681807\n",
      "train loss:0.001696221150300055\n",
      "train loss:0.006821469068864213\n",
      "train loss:0.0060272644739851585\n",
      "train loss:0.011530939545367188\n",
      "train loss:0.019466544293990157\n",
      "train loss:0.01330860658023095\n",
      "train loss:0.03127144206117555\n",
      "train loss:0.00426589293164356\n",
      "train loss:0.020653935612196986\n",
      "train loss:0.02199205087885506\n",
      "train loss:0.013864920088466081\n",
      "train loss:0.02026119650484586\n",
      "train loss:0.009636351504830457\n",
      "train loss:0.009297593784265862\n",
      "train loss:0.004695424829468692\n",
      "train loss:0.0034356888310554134\n",
      "train loss:0.012212033316676134\n",
      "train loss:0.0055629685589614385\n",
      "train loss:0.01441543390895877\n",
      "train loss:0.00542230818084404\n",
      "train loss:0.0059694290164138235\n",
      "train loss:0.06689064122678894\n",
      "train loss:0.0545325438981398\n",
      "train loss:0.014206328040349336\n",
      "train loss:0.005256771467160715\n",
      "train loss:0.03765496826303774\n",
      "train loss:0.022473286344262853\n",
      "train loss:0.017783626885377043\n",
      "train loss:0.0051893450691086985\n",
      "train loss:0.0045237958585962615\n",
      "train loss:0.0034190184352659754\n",
      "train loss:0.003094612700944616\n",
      "train loss:0.01223732072738858\n",
      "train loss:0.00607983184583681\n",
      "train loss:0.019665540860866953\n",
      "train loss:0.0017873242188198638\n",
      "train loss:0.05255739034333556\n",
      "train loss:0.0028393497666449746\n",
      "train loss:0.06038228746398139\n",
      "train loss:0.037156862311209245\n",
      "train loss:0.057084175685104786\n",
      "train loss:0.003374468077655513\n",
      "train loss:0.005508077162277986\n",
      "train loss:0.009623004801205046\n",
      "train loss:0.003805843488510713\n",
      "train loss:0.015196769362536661\n",
      "train loss:0.030281875718654868\n",
      "train loss:0.014759606473449496\n",
      "train loss:0.006609652866016457\n",
      "train loss:0.0021993367489716482\n",
      "train loss:0.018082987110136863\n",
      "train loss:0.01745106271535257\n",
      "train loss:0.02969101848715126\n",
      "train loss:0.02585800880741744\n",
      "train loss:0.0034000915581213114\n",
      "train loss:0.01811650930282878\n",
      "train loss:0.02849783929590985\n",
      "train loss:0.004903870841099362\n",
      "train loss:0.006824661522311266\n",
      "train loss:0.004817430834833364\n",
      "train loss:0.008654199722854637\n",
      "train loss:0.019127406118895338\n",
      "train loss:0.009214566373948636\n",
      "train loss:0.009811406556624526\n",
      "train loss:0.011461908052918572\n",
      "train loss:0.01730068515240253\n",
      "train loss:0.028300584472078935\n",
      "train loss:0.009252725829419736\n",
      "train loss:0.010739904435780852\n",
      "train loss:0.007639863900453785\n",
      "train loss:0.021323315757320212\n",
      "train loss:0.013775805032219845\n",
      "train loss:0.011925033408984907\n",
      "train loss:0.00968590242110885\n",
      "train loss:0.005501107751104394\n",
      "train loss:0.038982032965841865\n",
      "train loss:0.009605367676520628\n",
      "train loss:0.005750420284993601\n",
      "train loss:0.006186519487665888\n",
      "train loss:0.0029051212175741524\n",
      "train loss:0.007438366614236805\n",
      "train loss:0.034742802596344796\n",
      "train loss:0.012107236669162419\n",
      "train loss:0.04109556013264164\n",
      "train loss:0.008584941027358434\n",
      "train loss:0.004339105862338747\n",
      "train loss:0.015232737727726889\n",
      "train loss:0.010172661572731515\n",
      "train loss:0.00821764849366935\n",
      "train loss:0.003915740830983083\n",
      "train loss:0.013961453593522107\n",
      "train loss:0.009977718825401733\n",
      "train loss:0.005785538286460883\n",
      "train loss:0.006247770874289647\n",
      "train loss:0.04916581959024478\n",
      "train loss:0.011098017013733611\n",
      "train loss:0.0026820156976650545\n",
      "train loss:0.0010426689460353372\n",
      "train loss:0.004251966815013329\n",
      "train loss:0.0163101604660729\n",
      "train loss:0.004546448900840324\n",
      "train loss:0.027582298965434408\n",
      "train loss:0.00535457827211216\n",
      "train loss:0.00588849975785361\n",
      "train loss:0.0017154730143721594\n",
      "train loss:0.015007650245223537\n",
      "train loss:0.04258390628582445\n",
      "train loss:0.003503093314775563\n",
      "train loss:0.011854290889657879\n",
      "train loss:0.01822952494252478\n",
      "train loss:0.0022923391446408835\n",
      "train loss:0.031615794435085255\n",
      "train loss:0.0021567894522877776\n",
      "train loss:0.003589447800146655\n",
      "train loss:0.010721393345422438\n",
      "train loss:0.00987117509912783\n",
      "train loss:0.013152129540451562\n",
      "train loss:0.0020639486262251138\n",
      "train loss:0.027161413673695206\n",
      "train loss:0.015591147032662582\n",
      "train loss:0.004419636709168543\n",
      "train loss:0.005506617849343826\n",
      "train loss:0.014644267591445641\n",
      "train loss:0.006263271794796914\n",
      "train loss:0.057701925568102094\n",
      "train loss:0.0015136204313892661\n",
      "train loss:0.0040816715542181\n",
      "train loss:0.03554905331744967\n",
      "train loss:0.005122911840666567\n",
      "train loss:0.02569036025413456\n",
      "train loss:0.09192239312073144\n",
      "train loss:0.032743433550821065\n",
      "train loss:0.004294764967465974\n",
      "train loss:0.015638889471749524\n",
      "train loss:0.005418933271077627\n",
      "train loss:0.013461170512466902\n",
      "train loss:0.007287379296159469\n",
      "train loss:0.020688701003258654\n",
      "train loss:0.03441558423502509\n",
      "train loss:0.03602470207308703\n",
      "train loss:0.008496788214385325\n",
      "train loss:0.004918252411459502\n",
      "train loss:0.007143225313892336\n",
      "train loss:0.020846619472622896\n",
      "train loss:0.008243080528741599\n",
      "train loss:0.03893049881877227\n",
      "train loss:0.01595262821562825\n",
      "train loss:0.006179819483051169\n",
      "train loss:0.013425301282744344\n",
      "train loss:0.003913924204781773\n",
      "train loss:0.0027326174743950494\n",
      "train loss:0.020775912161051506\n",
      "train loss:0.01618523330089884\n",
      "train loss:0.006597225581326282\n",
      "train loss:0.015840878044952142\n",
      "train loss:0.012672862740169055\n",
      "train loss:0.00822333532265102\n",
      "train loss:0.012016756457075723\n",
      "train loss:0.014843804901414731\n",
      "train loss:0.0015984021826752873\n",
      "train loss:0.012116903971139834\n",
      "train loss:0.007043954793087691\n",
      "train loss:0.045059823228240266\n",
      "train loss:0.02085585601966904\n",
      "train loss:0.038491112682570175\n",
      "train loss:0.007922304257950359\n",
      "train loss:0.005633532435927526\n",
      "train loss:0.0013883741101509306\n",
      "train loss:0.02113651045916599\n",
      "train loss:0.004698168423577678\n",
      "train loss:0.010923295465834395\n",
      "train loss:0.0008087012085280751\n",
      "train loss:0.0065051383844502856\n",
      "train loss:0.006484110969109924\n",
      "train loss:0.02305572311340983\n",
      "train loss:0.00807347372520056\n",
      "train loss:0.01707360931660795\n",
      "train loss:0.03262065998874741\n",
      "train loss:0.0020151590641632675\n",
      "train loss:0.029688005041034\n",
      "train loss:0.0045734510020294696\n",
      "train loss:0.0033457726001016493\n",
      "train loss:0.0037571483903246798\n",
      "train loss:0.008335453320415924\n",
      "train loss:0.0027582762226680737\n",
      "train loss:0.003439755938717959\n",
      "train loss:0.016646731994033416\n",
      "train loss:0.029276962394509075\n",
      "train loss:0.07242772679955752\n",
      "train loss:0.02036768903497259\n",
      "train loss:0.005775488946848597\n",
      "train loss:0.011636343901893522\n",
      "train loss:0.02009561925393223\n",
      "train loss:0.00154343381419747\n",
      "train loss:0.005053564076833933\n",
      "train loss:0.006919137502874415\n",
      "train loss:0.0029726165932193634\n",
      "train loss:0.012123695629450095\n",
      "train loss:0.010055573521445182\n",
      "train loss:0.01342455326207498\n",
      "train loss:0.009442401460862298\n",
      "train loss:0.02093371983393943\n",
      "train loss:0.002383854667955966\n",
      "train loss:0.01160323203522231\n",
      "train loss:0.002891730758143841\n",
      "train loss:0.01321977910367909\n",
      "train loss:0.016589657945740906\n",
      "train loss:0.010415221663991567\n",
      "train loss:0.0017397052005519267\n",
      "train loss:0.016545837583376168\n",
      "train loss:0.004940503275068628\n",
      "train loss:0.002556109422930912\n",
      "train loss:0.008069334216651937\n",
      "train loss:0.009842985288543337\n",
      "train loss:0.0075601265800307035\n",
      "train loss:0.03162986108429669\n",
      "train loss:0.004225398271950266\n",
      "train loss:0.022197928108310186\n",
      "train loss:0.0045697314882445364\n",
      "train loss:0.00751349602247267\n",
      "train loss:0.009039181501531636\n",
      "train loss:0.010091091937955212\n",
      "train loss:0.0019391351817813715\n",
      "train loss:0.017688683162632154\n",
      "train loss:0.01344667223613636\n",
      "train loss:0.01874013705624225\n",
      "train loss:0.017150602120177105\n",
      "train loss:0.0008093473403555424\n",
      "train loss:0.008274196027383971\n",
      "train loss:0.05266548557532133\n",
      "train loss:0.0025242907899758753\n",
      "train loss:0.001785696204858676\n",
      "train loss:0.008639824518868484\n",
      "train loss:0.030215012787167074\n",
      "train loss:0.005625111526359496\n",
      "train loss:0.011077696489106508\n",
      "train loss:0.002340168892748098\n",
      "train loss:0.0076472635990463686\n",
      "train loss:0.027387497988237256\n",
      "train loss:0.013742472227741385\n",
      "train loss:0.001854482378425259\n",
      "train loss:0.01611886234530246\n",
      "train loss:0.026539560948506416\n",
      "train loss:0.006744608770231869\n",
      "train loss:0.002661399645102601\n",
      "train loss:0.006142102530609982\n",
      "train loss:0.008414465521892395\n",
      "train loss:0.024926515426447415\n",
      "train loss:0.06366063729211757\n",
      "train loss:0.07321479662597269\n",
      "train loss:0.05709863724616997\n",
      "train loss:0.02834894816504113\n",
      "train loss:0.005122204112822751\n",
      "train loss:0.01837248676273872\n",
      "train loss:0.028344422494082967\n",
      "train loss:0.027510971775794427\n",
      "train loss:0.010709886663782874\n",
      "train loss:0.024455826300970426\n",
      "train loss:0.0029161359874442434\n",
      "train loss:0.010536820399167052\n",
      "train loss:0.011259431526736485\n",
      "train loss:0.04717501622699271\n",
      "train loss:0.012911615567530113\n",
      "train loss:0.012880845558648844\n",
      "train loss:0.012737001371305887\n",
      "train loss:0.0026268732825690034\n",
      "train loss:0.009544504611083329\n",
      "train loss:0.017428481508822098\n",
      "train loss:0.05046722910869242\n",
      "train loss:0.0033659039835249698\n",
      "train loss:0.04949766321877877\n",
      "train loss:0.0063287765801779295\n",
      "train loss:0.013685738309173787\n",
      "train loss:0.008220386549664971\n",
      "train loss:0.02343045515939474\n",
      "train loss:0.01136597033667863\n",
      "train loss:0.029326743423352303\n",
      "train loss:0.005565389562800938\n",
      "train loss:0.011669548229136986\n",
      "train loss:0.0029618840620880106\n",
      "train loss:0.023782344505146123\n",
      "train loss:0.011311535484441488\n",
      "train loss:0.004967793995913019\n",
      "train loss:0.013590856150384287\n",
      "train loss:0.013672731009952397\n",
      "train loss:0.004205200796966115\n",
      "train loss:0.007388087949426758\n",
      "train loss:0.0188362437607118\n",
      "train loss:0.0032604830980055917\n",
      "train loss:0.0071733602861943566\n",
      "train loss:0.022247763574276585\n",
      "train loss:0.018373764884302514\n",
      "train loss:0.006531186943354802\n",
      "train loss:0.0050820145716280385\n",
      "train loss:0.07350166970437465\n",
      "train loss:0.006893806619862008\n",
      "train loss:0.0049663295934780465\n",
      "train loss:0.0071073318612452484\n",
      "train loss:0.0032346464978034355\n",
      "train loss:0.016085087635892253\n",
      "train loss:0.005339886182894387\n",
      "train loss:0.01440168544045794\n",
      "train loss:0.007697090861088468\n",
      "train loss:0.004045705021953406\n",
      "train loss:0.05766568772946039\n",
      "train loss:0.005092443289560506\n",
      "train loss:0.01737645069068068\n",
      "train loss:0.008602107202043748\n",
      "train loss:0.009147575534734451\n",
      "train loss:0.020338864042602475\n",
      "train loss:0.052620763566156775\n",
      "train loss:0.0023134036735757563\n",
      "train loss:0.03869116862146302\n",
      "train loss:0.003250240745765952\n",
      "train loss:0.004018533122083603\n",
      "train loss:0.035356052470656846\n",
      "train loss:0.025166112196229017\n",
      "train loss:0.0053327345937878605\n",
      "train loss:0.0040756679862631465\n",
      "train loss:0.006858018085944127\n",
      "train loss:0.020666380313730158\n",
      "train loss:0.007791354227170112\n",
      "train loss:0.04371321992657025\n",
      "train loss:0.03397119896512617\n",
      "train loss:0.02785244673176388\n",
      "train loss:0.028138225358335097\n",
      "train loss:0.029616878080414768\n",
      "train loss:0.0067756830330810616\n",
      "train loss:0.005100121930946003\n",
      "train loss:0.005791957832837301\n",
      "train loss:0.0024279586690447324\n",
      "train loss:0.05058872097817101\n",
      "train loss:0.00552049490494338\n",
      "train loss:0.005241031047814636\n",
      "train loss:0.004068282734536155\n",
      "train loss:0.019311700123745393\n",
      "train loss:0.010973323725543403\n",
      "train loss:0.007104129680561221\n",
      "train loss:0.010067625141648323\n",
      "train loss:0.0014491166214252748\n",
      "train loss:0.019075752801148302\n",
      "train loss:0.007121592404103103\n",
      "train loss:0.011189452655561951\n",
      "train loss:0.023243935143399487\n",
      "train loss:0.007096116412014518\n",
      "train loss:0.002678947185330436\n",
      "train loss:0.017770802344824515\n",
      "train loss:0.003564203262636518\n",
      "train loss:0.029775207200803337\n",
      "train loss:0.002771703081246442\n",
      "train loss:0.04225597225581952\n",
      "train loss:0.006193674355612438\n",
      "train loss:0.0014467752729912726\n",
      "train loss:0.016386245337854276\n",
      "train loss:0.0032969417534486245\n",
      "train loss:0.008874684919515418\n",
      "train loss:0.008305754103085185\n",
      "train loss:0.004237206717500001\n",
      "train loss:0.005240049488330953\n",
      "train loss:0.0020643797516502905\n",
      "train loss:0.013585403451381867\n",
      "train loss:0.007374641290470287\n",
      "train loss:0.0031335960658720914\n",
      "train loss:0.004938322232937927\n",
      "train loss:0.005352595978096983\n",
      "train loss:0.004259310186982789\n",
      "train loss:0.0011156257806034474\n",
      "train loss:0.005939908067071509\n",
      "train loss:0.01634526459029319\n",
      "train loss:0.013521712256104067\n",
      "train loss:0.018601690162322253\n",
      "train loss:0.03911403417738187\n",
      "train loss:0.08329139291938305\n",
      "train loss:0.011172137892475075\n",
      "train loss:0.029580008068316965\n",
      "train loss:0.011377233193802336\n",
      "train loss:0.007706389952667881\n",
      "train loss:0.010317293921397772\n",
      "train loss:0.03423364997508559\n",
      "train loss:0.02886631359236417\n",
      "train loss:0.0011946985844226241\n",
      "train loss:0.0029384604422725952\n",
      "train loss:0.005432120629417883\n",
      "train loss:0.018213881219049\n",
      "train loss:0.0043967091243027724\n",
      "train loss:0.018239952025054712\n",
      "train loss:0.07897211933627452\n",
      "train loss:0.026190316161456097\n",
      "train loss:0.009780025364553946\n",
      "train loss:0.012104894374318394\n",
      "train loss:0.036277505277716074\n",
      "train loss:0.00614779324076433\n",
      "train loss:0.006092913562429316\n",
      "train loss:0.0076807042372119\n",
      "train loss:0.004391855938404787\n",
      "train loss:0.016739186599771045\n",
      "train loss:0.004074565408844857\n",
      "train loss:0.013428742959277993\n",
      "train loss:0.00941684500651279\n",
      "train loss:0.0035806426653180777\n",
      "train loss:0.019692188435162426\n",
      "train loss:0.005926037542561668\n",
      "train loss:0.008223589903452568\n",
      "train loss:0.027296404331613205\n",
      "train loss:0.003014662118587082\n",
      "=== epoch:8, train acc:0.986, test acc:0.987 ===\n",
      "train loss:0.0028647009899431574\n",
      "train loss:0.005226863453878045\n",
      "train loss:0.005941083041407078\n",
      "train loss:0.01252888320365428\n",
      "train loss:0.08343881513308414\n",
      "train loss:0.0037387469806502227\n",
      "train loss:0.02087635265497858\n",
      "train loss:0.05595200462916775\n",
      "train loss:0.02250693696700006\n",
      "train loss:0.012098919032456199\n",
      "train loss:0.002778812838203579\n",
      "train loss:0.0136117077427443\n",
      "train loss:0.038216924207671685\n",
      "train loss:0.006181272524369388\n",
      "train loss:0.0030408663841646217\n",
      "train loss:0.013468851043119552\n",
      "train loss:0.049496554488224834\n",
      "train loss:0.01032617711175401\n",
      "train loss:0.03083873109549115\n",
      "train loss:0.0029646034937016665\n",
      "train loss:0.0344262110238355\n",
      "train loss:0.005083965434680184\n",
      "train loss:0.004628866080950347\n",
      "train loss:0.023880056932021842\n",
      "train loss:0.0011867868938563381\n",
      "train loss:0.04525248390569675\n",
      "train loss:0.036839314385294614\n",
      "train loss:0.04862542060396031\n",
      "train loss:0.03342188384526074\n",
      "train loss:0.037323484637173304\n",
      "train loss:0.01703800211299053\n",
      "train loss:0.024269372292286703\n",
      "train loss:0.0045934429585259085\n",
      "train loss:0.02658175383597461\n",
      "train loss:0.05255739294146031\n",
      "train loss:0.021502737928361465\n",
      "train loss:0.026483425199027306\n",
      "train loss:0.006887375747565624\n",
      "train loss:0.005279077636506235\n",
      "train loss:0.0034983919763609435\n",
      "train loss:0.004389292784159277\n",
      "train loss:0.003216479660057951\n",
      "train loss:0.00661310330773758\n",
      "train loss:0.00477051297198462\n",
      "train loss:0.009468379455639303\n",
      "train loss:0.0030718635731393773\n",
      "train loss:0.004897171969723734\n",
      "train loss:0.0073561314494172405\n",
      "train loss:0.009244235097486798\n",
      "train loss:0.015692825502360133\n",
      "train loss:0.004987060141738763\n",
      "train loss:0.010323597060420488\n",
      "train loss:0.05161782740147945\n",
      "train loss:0.009497420421761802\n",
      "train loss:0.013193918425988329\n",
      "train loss:0.01402150583132932\n",
      "train loss:0.013583421910532007\n",
      "train loss:0.022090342932593533\n",
      "train loss:0.0035521640739077263\n",
      "train loss:0.013589250629880163\n",
      "train loss:0.019561345165662485\n",
      "train loss:0.004396842771205307\n",
      "train loss:0.024958573693410292\n",
      "train loss:0.010032554731992249\n",
      "train loss:0.005313877648289106\n",
      "train loss:0.013862222883291858\n",
      "train loss:0.11308054214990554\n",
      "train loss:0.041583012485128315\n",
      "train loss:0.016948303448708\n",
      "train loss:0.015262642194195954\n",
      "train loss:0.0077458857562828975\n",
      "train loss:0.019820340332018935\n",
      "train loss:0.004375096421845736\n",
      "train loss:0.0023863791935334524\n",
      "train loss:0.032643533840110414\n",
      "train loss:0.07010878335185998\n",
      "train loss:0.0026680615914570567\n",
      "train loss:0.001334686268849956\n",
      "train loss:0.001556644974937993\n",
      "train loss:0.012254347785434307\n",
      "train loss:0.0013981978845739814\n",
      "train loss:0.0580086377845996\n",
      "train loss:0.0034944750276299005\n",
      "train loss:0.0030280298774983954\n",
      "train loss:0.016800637115299413\n",
      "train loss:0.007380917914743617\n",
      "train loss:0.009469807221852587\n",
      "train loss:0.0012314304278926208\n",
      "train loss:0.012961981612181251\n",
      "train loss:0.02373421776178622\n",
      "train loss:0.008053190225755118\n",
      "train loss:0.028916188075834372\n",
      "train loss:0.008353597027143687\n",
      "train loss:0.015024936699118658\n",
      "train loss:0.0205580942842459\n",
      "train loss:0.011230063002047187\n",
      "train loss:0.049962833480619494\n",
      "train loss:0.061230430748189256\n",
      "train loss:0.058061719622373505\n",
      "train loss:0.03282160505423536\n",
      "train loss:0.015386909510931222\n",
      "train loss:0.02255495645205904\n",
      "train loss:0.028754862834034386\n",
      "train loss:0.004879552627877653\n",
      "train loss:0.0009733506289358009\n",
      "train loss:0.009615677222373813\n",
      "train loss:0.0024273955195274533\n",
      "train loss:0.04110893119147496\n",
      "train loss:0.003310042995537944\n",
      "train loss:0.018796026916831403\n",
      "train loss:0.007754359204916942\n",
      "train loss:0.0068501841332548495\n",
      "train loss:0.08484873558527366\n",
      "train loss:0.0029036470252156747\n",
      "train loss:0.021532030680731354\n",
      "train loss:0.00928603528583768\n",
      "train loss:0.0033151200981851457\n",
      "train loss:0.009438394367344243\n",
      "train loss:0.005204826465971373\n",
      "train loss:0.006208329974198041\n",
      "train loss:0.015747458123370993\n",
      "train loss:0.013689499098633106\n",
      "train loss:0.031582098212221875\n",
      "train loss:0.02582350236415854\n",
      "train loss:0.010572908886341728\n",
      "train loss:0.0175771186399601\n",
      "train loss:0.004052428562283819\n",
      "train loss:0.0035990356883246932\n",
      "train loss:0.057099198742235326\n",
      "train loss:0.0014167716034439858\n",
      "train loss:0.10268681861086795\n",
      "train loss:0.0025243581007890962\n",
      "train loss:0.010203110806855478\n",
      "train loss:0.04957933026456858\n",
      "train loss:0.009352549531600139\n",
      "train loss:0.005500271446326694\n",
      "train loss:0.005977200496424535\n",
      "train loss:0.0032966242814593755\n",
      "train loss:0.018737793885614876\n",
      "train loss:0.04648552830031762\n",
      "train loss:0.004453325237073246\n",
      "train loss:0.009707079837305262\n",
      "train loss:0.006520177572965991\n",
      "train loss:0.004129912887272319\n",
      "train loss:0.05513483217876234\n",
      "train loss:0.015289954150678848\n",
      "train loss:0.0015520694787053842\n",
      "train loss:0.00214080067073255\n",
      "train loss:0.014774324405410042\n",
      "train loss:0.0035541590307452036\n",
      "train loss:0.0348730658501658\n",
      "train loss:0.01854282805908258\n",
      "train loss:0.004555847982823839\n",
      "train loss:0.009033823450133429\n",
      "train loss:0.018056897799755195\n",
      "train loss:0.014046496424841072\n",
      "train loss:0.0035441731789972457\n",
      "train loss:0.0047925831886843255\n",
      "train loss:0.044441416454830955\n",
      "train loss:0.005926783918133946\n",
      "train loss:0.0046712895819099815\n",
      "train loss:0.004003702875900363\n",
      "train loss:0.003934473952406804\n",
      "train loss:0.0043615279990570615\n",
      "train loss:0.07543128960197028\n",
      "train loss:0.007414507484079552\n",
      "train loss:0.026875638079154288\n",
      "train loss:0.02364039989072523\n",
      "train loss:0.009399779564626471\n",
      "train loss:0.005219700030959105\n",
      "train loss:0.012736292530053261\n",
      "train loss:0.0068314923436983265\n",
      "train loss:0.049925215974277314\n",
      "train loss:0.01702075296443037\n",
      "train loss:0.018122025883718976\n",
      "train loss:0.0023248126305343343\n",
      "train loss:0.005590046327904092\n",
      "train loss:0.003987691902999224\n",
      "train loss:0.004895972773672802\n",
      "train loss:0.007023862559788797\n",
      "train loss:0.0022355250398444575\n",
      "train loss:0.0351729104653427\n",
      "train loss:0.01375452886962559\n",
      "train loss:0.005254915904330249\n",
      "train loss:0.0026881361943857252\n",
      "train loss:0.006966069644663322\n",
      "train loss:0.019434221306906457\n",
      "train loss:0.00645566910382351\n",
      "train loss:0.014210217725282233\n",
      "train loss:0.018086828086348376\n",
      "train loss:0.05235831043799812\n",
      "train loss:0.007833102212178332\n",
      "train loss:0.010438429921801516\n",
      "train loss:0.0030760028927691286\n",
      "train loss:0.009254135514969338\n",
      "train loss:0.011829326988087504\n",
      "train loss:0.007748585724001231\n",
      "train loss:0.06165050899622004\n",
      "train loss:0.018622699601800262\n",
      "train loss:0.05698163039660855\n",
      "train loss:0.003710208004766265\n",
      "train loss:0.0065843669236347845\n",
      "train loss:0.051095725284165124\n",
      "train loss:0.0029371591501375794\n",
      "train loss:0.030417349309207826\n",
      "train loss:0.004459018517051414\n",
      "train loss:0.0073701744088590085\n",
      "train loss:0.02744712552083853\n",
      "train loss:0.018698667809468616\n",
      "train loss:0.0023751770081801714\n",
      "train loss:0.004679457140313708\n",
      "train loss:0.002861546918527512\n",
      "train loss:0.004723519218570286\n",
      "train loss:0.005076459368611781\n",
      "train loss:0.0017594033102747602\n",
      "train loss:0.00427007644808318\n",
      "train loss:0.015838711894674576\n",
      "train loss:0.0008641540267759813\n",
      "train loss:0.010559584447663034\n",
      "train loss:0.007491473300201117\n",
      "train loss:0.022385825400186934\n",
      "train loss:0.0028508149791152465\n",
      "train loss:0.009297707835835872\n",
      "train loss:0.0013833251048196377\n",
      "train loss:0.005744102023439306\n",
      "train loss:0.005746139151974258\n",
      "train loss:0.005736536663355884\n",
      "train loss:0.004372819823289862\n",
      "train loss:0.013929179663044395\n",
      "train loss:0.0044802663444507675\n",
      "train loss:0.00209050716008306\n",
      "train loss:0.003995725887544993\n",
      "train loss:0.002074705593662314\n",
      "train loss:0.006755248914869222\n",
      "train loss:0.008140041346449113\n",
      "train loss:0.04021697880410215\n",
      "train loss:0.0027292469900395216\n",
      "train loss:0.009822744678798779\n",
      "train loss:0.0067771212711448155\n",
      "train loss:0.013697652458294301\n",
      "train loss:0.002234164414513738\n",
      "train loss:0.007874364162734425\n",
      "train loss:0.02037669288993839\n",
      "train loss:0.004571969466635127\n",
      "train loss:0.015293172120485712\n",
      "train loss:0.019158945162820837\n",
      "train loss:0.17341496869121642\n",
      "train loss:0.014229395137528253\n",
      "train loss:0.0024124362074063035\n",
      "train loss:0.0161765345644831\n",
      "train loss:0.005930859446122098\n",
      "train loss:0.00967395710680809\n",
      "train loss:0.0032633574102424066\n",
      "train loss:0.006333483169153629\n",
      "train loss:0.022170044261165884\n",
      "train loss:0.001323788258094062\n",
      "train loss:0.006741156261167187\n",
      "train loss:0.023702529605322372\n",
      "train loss:0.0023191193262763568\n",
      "train loss:0.0007327225992725074\n",
      "train loss:0.008263295553315899\n",
      "train loss:0.0035759812305409273\n",
      "train loss:0.005596699458232266\n",
      "train loss:0.06779246974001843\n",
      "train loss:0.0030529759925168177\n",
      "train loss:0.004214807977280735\n",
      "train loss:0.0019316475388063074\n",
      "train loss:0.04495219121154721\n",
      "train loss:0.02199887726293217\n",
      "train loss:0.002914358315799033\n",
      "train loss:0.023137487596901676\n",
      "train loss:0.003415394019279435\n",
      "train loss:0.004973125304468663\n",
      "train loss:0.009845406673295483\n",
      "train loss:0.05042766287488683\n",
      "train loss:0.001471090746345875\n",
      "train loss:0.007646214098939254\n",
      "train loss:0.02131263343084637\n",
      "train loss:0.022142056033028767\n",
      "train loss:0.005846655723659282\n",
      "train loss:0.022581817012262414\n",
      "train loss:0.011382845575360527\n",
      "train loss:0.004782280199211306\n",
      "train loss:0.017058627690619464\n",
      "train loss:0.027825317466211377\n",
      "train loss:0.041070850873340475\n",
      "train loss:0.011322763887413411\n",
      "train loss:0.013399432330443148\n",
      "train loss:0.005557627710089\n",
      "train loss:0.0038397194396318445\n",
      "train loss:0.0205273368315862\n",
      "train loss:0.006027973509124972\n",
      "train loss:0.009039047127427018\n",
      "train loss:0.010206715722347959\n",
      "train loss:0.025663180166940407\n",
      "train loss:0.004292121578007853\n",
      "train loss:0.02387895948383041\n",
      "train loss:0.003731817810192879\n",
      "train loss:0.004191358836276103\n",
      "train loss:0.004379802180985085\n",
      "train loss:0.022898762318041666\n",
      "train loss:0.011300207999283276\n",
      "train loss:0.1456571808587781\n",
      "train loss:0.002933284171885731\n",
      "train loss:0.005935145383395967\n",
      "train loss:0.010445031076041927\n",
      "train loss:0.012898690782884668\n",
      "train loss:0.014418681593889836\n",
      "train loss:0.0032000889375945495\n",
      "train loss:0.01227667881799793\n",
      "train loss:0.04140492058997202\n",
      "train loss:0.009131169701014958\n",
      "train loss:0.0127670794927677\n",
      "train loss:0.008651593990711545\n",
      "train loss:0.015868090347305866\n",
      "train loss:0.0036507764877238545\n",
      "train loss:0.005029630409783364\n",
      "train loss:0.004835934871991743\n",
      "train loss:0.007669801019921319\n",
      "train loss:0.0053203340246518105\n",
      "train loss:0.022792114423249642\n",
      "train loss:0.0039985755423969874\n",
      "train loss:0.04591465466183322\n",
      "train loss:0.00566221117606238\n",
      "train loss:0.011469528521856297\n",
      "train loss:0.01505623273053392\n",
      "train loss:0.001282317288354712\n",
      "train loss:0.010457615841857771\n",
      "train loss:0.010250850311230216\n",
      "train loss:0.0052819195065690085\n",
      "train loss:0.026434875433612275\n",
      "train loss:0.023354617637819784\n",
      "train loss:0.0028222481433943934\n",
      "train loss:0.003698072792909351\n",
      "train loss:0.013242312165596095\n",
      "train loss:0.0026091505676701502\n",
      "train loss:0.007556402424321515\n",
      "train loss:0.01712688226113483\n",
      "train loss:0.004680534327636018\n",
      "train loss:0.0021931804626845438\n",
      "train loss:0.0218434137388387\n",
      "train loss:0.003950951654568477\n",
      "train loss:0.030187836289821815\n",
      "train loss:0.007950516467279227\n",
      "train loss:0.004835653725069835\n",
      "train loss:0.003979054666702438\n",
      "train loss:0.006624309042902893\n",
      "train loss:0.01208410105085348\n",
      "train loss:0.016667311811578416\n",
      "train loss:0.003331496952434762\n",
      "train loss:0.029349731136041352\n",
      "train loss:0.005923834605798948\n",
      "train loss:0.012553266928969598\n",
      "train loss:0.0035563026547746172\n",
      "train loss:0.004882303847472801\n",
      "train loss:0.01782886295811073\n",
      "train loss:0.0009211545821352853\n",
      "train loss:0.0028884924478620204\n",
      "train loss:0.004203532611964382\n",
      "train loss:0.0025912968130458198\n",
      "train loss:0.0010674343634345241\n",
      "train loss:0.00946061409407847\n",
      "train loss:0.002315898289091808\n",
      "train loss:0.0021086625038336977\n",
      "train loss:0.010840181930393506\n",
      "train loss:0.0028353370785953384\n",
      "train loss:0.0018506764759342329\n",
      "train loss:0.025238829603583278\n",
      "train loss:0.010546916904175873\n",
      "train loss:0.01335742156284307\n",
      "train loss:0.004880481540432977\n",
      "train loss:0.0020114043354120836\n",
      "train loss:0.0032164364248133703\n",
      "train loss:0.0025010854780139254\n",
      "train loss:0.005456398019050641\n",
      "train loss:0.02165382056686257\n",
      "train loss:0.006709772183351963\n",
      "train loss:0.00419036498403887\n",
      "train loss:0.004219966528453786\n",
      "train loss:0.014450620956463512\n",
      "train loss:0.019825081099745862\n",
      "train loss:0.004154920720925987\n",
      "train loss:0.0033650439461364646\n",
      "train loss:0.014880531621108554\n",
      "train loss:0.011023759957300339\n",
      "train loss:0.002641701919154615\n",
      "train loss:0.011714090580896157\n",
      "train loss:0.008740934216407658\n",
      "train loss:0.0016612464161050266\n",
      "train loss:0.0019901444160676813\n",
      "train loss:0.0023629154220057447\n",
      "train loss:0.0016009938578934616\n",
      "train loss:0.00595741881558521\n",
      "train loss:0.00638372343375374\n",
      "train loss:0.004806516425526399\n",
      "train loss:0.0010360985088222528\n",
      "train loss:0.004230604115785679\n",
      "train loss:0.00607996258456288\n",
      "train loss:0.019444054666053326\n",
      "train loss:0.01255772835649587\n",
      "train loss:0.0025160998158388053\n",
      "train loss:0.0006978127822190327\n",
      "train loss:0.02859991849701108\n",
      "train loss:0.0031433441796471806\n",
      "train loss:0.013753003023087178\n",
      "train loss:0.01667456352719592\n",
      "train loss:0.0034025025968514454\n",
      "train loss:0.013356353257068123\n",
      "train loss:0.015592867032782365\n",
      "train loss:0.02016264471488932\n",
      "train loss:0.009590271610851865\n",
      "train loss:0.008620113638468313\n",
      "train loss:0.00567067066099772\n",
      "train loss:0.003832482906851149\n",
      "train loss:0.0037725640677703227\n",
      "train loss:0.0038106436441718273\n",
      "train loss:0.026746466642488143\n",
      "train loss:0.0034159832067227136\n",
      "train loss:0.008505787840650003\n",
      "train loss:0.022648511089947143\n",
      "train loss:0.01571148144398228\n",
      "train loss:0.05511482626386499\n",
      "train loss:0.004695705330566852\n",
      "train loss:0.010795935216248135\n",
      "train loss:0.06467611787223898\n",
      "train loss:0.008149884978894871\n",
      "train loss:0.0024130654962055114\n",
      "train loss:0.07039039385707607\n",
      "train loss:0.07193180058608373\n",
      "train loss:0.010218126974835715\n",
      "train loss:0.0019846974509406734\n",
      "train loss:0.007436530919323048\n",
      "train loss:0.007018381603843422\n",
      "train loss:0.010943578416264801\n",
      "train loss:0.05258461676068592\n",
      "train loss:0.051430006346791755\n",
      "train loss:0.02447279522683781\n",
      "train loss:0.005568167561399886\n",
      "train loss:0.010267567834905303\n",
      "train loss:0.004751742472979055\n",
      "train loss:0.006877144214785297\n",
      "train loss:0.012104028314902099\n",
      "train loss:0.015107183919979707\n",
      "train loss:0.010019346114446279\n",
      "train loss:0.006320322233136885\n",
      "train loss:0.014488315827624398\n",
      "train loss:0.003173829632064472\n",
      "train loss:0.09101659921369752\n",
      "train loss:0.0020742668596886384\n",
      "train loss:0.010757024679142106\n",
      "train loss:0.005184290303353601\n",
      "train loss:0.02783286047739071\n",
      "train loss:0.009726234829339951\n",
      "train loss:0.010832298358039972\n",
      "train loss:0.003253852393184382\n",
      "train loss:0.0393779740556198\n",
      "train loss:0.0031908888734068623\n",
      "train loss:0.0010134596135819003\n",
      "train loss:0.012729539489320381\n",
      "train loss:0.013073691039964861\n",
      "train loss:0.0008373685697596324\n",
      "train loss:0.017138703729931433\n",
      "train loss:0.0029876461563198052\n",
      "train loss:0.015224675585234288\n",
      "train loss:0.007424790258626715\n",
      "train loss:0.0013081153088239242\n",
      "train loss:0.008657494499086591\n",
      "train loss:0.013332394048543856\n",
      "train loss:0.023878188557736598\n",
      "train loss:0.0076754319723135005\n",
      "train loss:0.02896080899399247\n",
      "train loss:0.002843925902039916\n",
      "train loss:0.002934282155184827\n",
      "train loss:0.005427810426014378\n",
      "train loss:0.008498260993030794\n",
      "train loss:0.015762062241834268\n",
      "train loss:0.0075687734074449155\n",
      "train loss:0.0058292406540616385\n",
      "train loss:0.003235733992020648\n",
      "train loss:0.004471855051259903\n",
      "train loss:0.004018281597890805\n",
      "train loss:0.00840090643952499\n",
      "train loss:0.0023123118967344667\n",
      "train loss:0.009574668834022707\n",
      "train loss:0.009727516376947753\n",
      "train loss:0.05192554651140854\n",
      "train loss:0.006348377707597228\n",
      "train loss:0.009626663579702481\n",
      "train loss:0.06115916516959771\n",
      "train loss:0.0017586960979780338\n",
      "train loss:0.00108451114674132\n",
      "train loss:0.0068317315142203796\n",
      "train loss:0.0042992150729390735\n",
      "train loss:0.013164712914740329\n",
      "train loss:0.008629038227100311\n",
      "train loss:0.01043219533098912\n",
      "train loss:0.009541074473333718\n",
      "train loss:0.022615615837576448\n",
      "train loss:0.03115825991432617\n",
      "train loss:0.036243580621623556\n",
      "train loss:0.036924020308179206\n",
      "train loss:0.011608944334728201\n",
      "train loss:0.005307748466939798\n",
      "train loss:0.014089492929136516\n",
      "train loss:0.003988063021883179\n",
      "train loss:0.012305614868585713\n",
      "train loss:0.0021981005164164184\n",
      "train loss:0.00960840701300961\n",
      "train loss:0.004601744158376921\n",
      "train loss:0.0019232337406724918\n",
      "train loss:0.01756486133315074\n",
      "train loss:0.0160654896357152\n",
      "train loss:0.007718608308981881\n",
      "train loss:0.010930606941477062\n",
      "train loss:0.0026562398673744413\n",
      "train loss:0.009372304981616791\n",
      "train loss:0.03474458833257932\n",
      "train loss:0.01860518290011475\n",
      "train loss:0.015470889233808752\n",
      "train loss:0.0013880590816629187\n",
      "train loss:0.0017858224651149729\n",
      "train loss:0.0005115569646603324\n",
      "train loss:0.0029758393201561473\n",
      "train loss:0.014467710591355664\n",
      "train loss:0.005612001084330877\n",
      "train loss:0.007755680370286848\n",
      "train loss:0.007673369160945368\n",
      "train loss:0.003777038553441527\n",
      "train loss:0.006372924305343855\n",
      "train loss:0.0034258413068574585\n",
      "train loss:0.0036701027705691182\n",
      "train loss:0.02152485406202445\n",
      "train loss:0.022323947233077\n",
      "train loss:0.00930533513785982\n",
      "train loss:0.009259881646838601\n",
      "train loss:0.003691512870188568\n",
      "train loss:0.005128216827498466\n",
      "train loss:0.018996509228710518\n",
      "train loss:0.009142714577532856\n",
      "train loss:0.006625286936464299\n",
      "train loss:0.010175414910097498\n",
      "train loss:0.03560528191935461\n",
      "train loss:0.011607730933782765\n",
      "train loss:0.00753926025695159\n",
      "train loss:0.0011163324008756788\n",
      "train loss:0.0009206330433147458\n",
      "train loss:0.003921848628649546\n",
      "train loss:0.001400325927620672\n",
      "train loss:0.0027795449657476135\n",
      "train loss:0.01703446066891612\n",
      "train loss:0.027135893820678412\n",
      "train loss:0.0034743587123897586\n",
      "train loss:0.11046333020165029\n",
      "train loss:0.005664123442013602\n",
      "train loss:0.011891318205567818\n",
      "train loss:0.0013245778043193082\n",
      "train loss:0.008964223981358155\n",
      "train loss:0.008014726965477982\n",
      "train loss:0.024089689429210102\n",
      "train loss:0.04867033782558405\n",
      "train loss:0.0010291831833400572\n",
      "train loss:0.008635335653533749\n",
      "train loss:0.013306576242238513\n",
      "train loss:0.004736632901547616\n",
      "train loss:0.02924441049832204\n",
      "train loss:0.011569403991436012\n",
      "train loss:0.0038882928256952663\n",
      "train loss:0.006434565738684836\n",
      "train loss:0.014766339054755011\n",
      "train loss:0.0014748995174313365\n",
      "train loss:0.010030824174286652\n",
      "train loss:0.03863005467509374\n",
      "train loss:0.009020479059404207\n",
      "train loss:0.00610864918062573\n",
      "train loss:0.022151188735466735\n",
      "train loss:0.012605719054217805\n",
      "train loss:0.00969930681088273\n",
      "train loss:0.01047786059819239\n",
      "train loss:0.035520808026858794\n",
      "train loss:0.018814866364141033\n",
      "train loss:0.023362220303872753\n",
      "train loss:0.006809706423644998\n",
      "train loss:0.020373454867704366\n",
      "train loss:0.010831065225229315\n",
      "train loss:0.09732542849064435\n",
      "train loss:0.0005910257860424656\n",
      "train loss:0.10065521820770915\n",
      "train loss:0.008163329011441395\n",
      "train loss:0.0019068770935563803\n",
      "train loss:0.02062896521745175\n",
      "train loss:0.0035424302919550726\n",
      "train loss:0.0057135516836975256\n",
      "train loss:0.010289328516039442\n",
      "train loss:0.0035552367061654176\n",
      "train loss:0.025632911789118876\n",
      "train loss:0.005033203029502691\n",
      "train loss:0.021490753208149308\n",
      "train loss:0.03178888301384195\n",
      "train loss:0.0025051486263444806\n",
      "train loss:0.008141061642633417\n",
      "=== epoch:9, train acc:0.992, test acc:0.991 ===\n",
      "train loss:0.016807875837746525\n",
      "train loss:0.007725387281099797\n",
      "train loss:0.03441896644613859\n",
      "train loss:0.004362667691336653\n",
      "train loss:0.0033164251608180416\n",
      "train loss:0.019743440661478824\n",
      "train loss:0.012507057219366092\n",
      "train loss:0.009598172780951333\n",
      "train loss:0.004471317972139998\n",
      "train loss:0.024928224230495025\n",
      "train loss:0.0035510179612802547\n",
      "train loss:0.005296827324537432\n",
      "train loss:0.0063194365640074305\n",
      "train loss:0.008762870309480923\n",
      "train loss:0.006795630906710288\n",
      "train loss:0.008073872113420415\n",
      "train loss:0.004450000467057297\n",
      "train loss:0.010094466329003285\n",
      "train loss:0.029130203259846024\n",
      "train loss:0.008422745530209946\n",
      "train loss:0.012236680099173667\n",
      "train loss:0.02325659227739457\n",
      "train loss:0.0023331135370308247\n",
      "train loss:0.030333180054037685\n",
      "train loss:0.013707193642244576\n",
      "train loss:0.013879095429267288\n",
      "train loss:0.002663599684403395\n",
      "train loss:0.006896050075921886\n",
      "train loss:0.013737140660739573\n",
      "train loss:0.02171023042517114\n",
      "train loss:0.004832689279961192\n",
      "train loss:0.014559869146137968\n",
      "train loss:0.0013806665725247397\n",
      "train loss:0.02272957269603987\n",
      "train loss:0.001450958062423853\n",
      "train loss:0.006591321493639245\n",
      "train loss:0.004106028687460786\n",
      "train loss:0.0010194464970926216\n",
      "train loss:0.006490305598304087\n",
      "train loss:0.013533604237833783\n",
      "train loss:0.00654335076159271\n",
      "train loss:0.0007858694847916682\n",
      "train loss:0.003049936288648971\n",
      "train loss:0.00962961850214221\n",
      "train loss:0.017351553560870835\n",
      "train loss:0.002745180525294263\n",
      "train loss:0.021437933173940497\n",
      "train loss:0.04943479718416855\n",
      "train loss:0.020012710364438843\n",
      "train loss:0.012679694970503\n",
      "train loss:0.031081048322494115\n",
      "train loss:0.004701289875805738\n",
      "train loss:0.006164578583696432\n",
      "train loss:0.002677282535145064\n",
      "train loss:0.004342494446984653\n",
      "train loss:0.02753845781018387\n",
      "train loss:0.003428188908428403\n",
      "train loss:0.009973834083340532\n",
      "train loss:0.002271235813221733\n",
      "train loss:0.0176141836212397\n",
      "train loss:0.010502684073513482\n",
      "train loss:0.022640605428354554\n",
      "train loss:0.026767322405415864\n",
      "train loss:0.003791350649917301\n",
      "train loss:0.006418821963458079\n",
      "train loss:0.008325418856176277\n",
      "train loss:0.008037459043498127\n",
      "train loss:0.03293061290129958\n",
      "train loss:0.028587761248045736\n",
      "train loss:0.014864974635008677\n",
      "train loss:0.010779747666801058\n",
      "train loss:0.007299561348342056\n",
      "train loss:0.028245271984979742\n",
      "train loss:0.005783431437585418\n",
      "train loss:0.010025089099008486\n",
      "train loss:0.060412236147283964\n",
      "train loss:0.0008593160068933558\n",
      "train loss:0.009880150905771804\n",
      "train loss:0.013947723120099217\n",
      "train loss:0.025372252157576367\n",
      "train loss:0.002482072057810965\n",
      "train loss:0.007969925706922952\n",
      "train loss:0.07064221226174704\n",
      "train loss:0.010011749810489065\n",
      "train loss:0.004999492813268228\n",
      "train loss:0.0027745875581439883\n",
      "train loss:0.002886474551573456\n",
      "train loss:0.02265358600824381\n",
      "train loss:0.003971447433046577\n",
      "train loss:0.0011646208802127001\n",
      "train loss:0.0028309774766668862\n",
      "train loss:0.004448520838651631\n",
      "train loss:0.007537054299791191\n",
      "train loss:0.008292704232789598\n",
      "train loss:0.004021743759197113\n",
      "train loss:0.002280345541267467\n",
      "train loss:0.0016751210858129803\n",
      "train loss:0.003294327993534803\n",
      "train loss:0.004245656112678254\n",
      "train loss:0.03758861901963201\n",
      "train loss:0.002240730424661679\n",
      "train loss:0.007915963988068462\n",
      "train loss:0.005834822991706106\n",
      "train loss:0.0028862974212019187\n",
      "train loss:0.00844603409394017\n",
      "train loss:0.012816669435942098\n",
      "train loss:0.004324217285510837\n",
      "train loss:0.06637286373341662\n",
      "train loss:0.007869734330393134\n",
      "train loss:0.012322746252207544\n",
      "train loss:0.0013296163444546628\n",
      "train loss:0.005599577063512262\n",
      "train loss:0.008186437071492239\n",
      "train loss:0.0065956400415725655\n",
      "train loss:0.007866768625139785\n",
      "train loss:0.00481648255807705\n",
      "train loss:0.029736437832984044\n",
      "train loss:0.0005777996793028005\n",
      "train loss:0.005136414938411402\n",
      "train loss:0.0016922393904025815\n",
      "train loss:0.020203875915225534\n",
      "train loss:0.016598132338827926\n",
      "train loss:0.03377394105154431\n",
      "train loss:0.013492587176937331\n",
      "train loss:0.011109242222172975\n",
      "train loss:0.010608029510487836\n",
      "train loss:0.0006068854074091761\n",
      "train loss:0.02761802706825248\n",
      "train loss:0.0026522749644322103\n",
      "train loss:0.0043870954029047145\n",
      "train loss:0.002098613673199368\n",
      "train loss:0.0016512810771425219\n",
      "train loss:0.002692710044256714\n",
      "train loss:0.0117568561437365\n",
      "train loss:0.0035031636850875857\n",
      "train loss:0.003645631311278068\n",
      "train loss:0.0023063357105844616\n",
      "train loss:0.008592950159340055\n",
      "train loss:0.0038499651610855766\n",
      "train loss:0.004798473659342044\n",
      "train loss:0.007508351150093231\n",
      "train loss:0.0007782464346100723\n",
      "train loss:0.007244103748855625\n",
      "train loss:0.0016864770873721644\n",
      "train loss:0.002090767885222824\n",
      "train loss:0.012242456444474263\n",
      "train loss:0.004953104310319687\n",
      "train loss:0.0039883386162980206\n",
      "train loss:0.002361502437090136\n",
      "train loss:0.005789844061037091\n",
      "train loss:0.01314067427395988\n",
      "train loss:0.00575181647734854\n",
      "train loss:0.05803590986790883\n",
      "train loss:0.0011583571987794517\n",
      "train loss:0.0011786637111895995\n",
      "train loss:0.010627559063993675\n",
      "train loss:0.005526676977318473\n",
      "train loss:0.006441293747372262\n",
      "train loss:0.0032370440375962452\n",
      "train loss:0.006688412582001091\n",
      "train loss:0.0013925207592117817\n",
      "train loss:0.016499677380987947\n",
      "train loss:0.0029259352867808995\n",
      "train loss:0.01998503686880732\n",
      "train loss:0.00573823933756478\n",
      "train loss:0.04454825072753626\n",
      "train loss:0.058213608802900614\n",
      "train loss:0.013449499485842646\n",
      "train loss:0.001994006073518122\n",
      "train loss:0.02205218061873368\n",
      "train loss:0.006168638387266271\n",
      "train loss:0.001506171830202132\n",
      "train loss:0.011076038632220618\n",
      "train loss:0.004054581412487419\n",
      "train loss:0.012372361844815516\n",
      "train loss:0.007917790778812191\n",
      "train loss:0.005404801283540542\n",
      "train loss:0.012728303676611354\n",
      "train loss:0.0008521266883062158\n",
      "train loss:0.005813731063694183\n",
      "train loss:0.03910087242211869\n",
      "train loss:0.012553411337470021\n",
      "train loss:0.004335649019767456\n",
      "train loss:0.011404730167873998\n",
      "train loss:0.0034259019395056827\n",
      "train loss:0.011640367306767221\n",
      "train loss:0.005395002457455817\n",
      "train loss:0.001459572138299649\n",
      "train loss:0.010664212993703508\n",
      "train loss:0.005125480884770217\n",
      "train loss:0.009936720844542352\n",
      "train loss:0.016462205469515243\n",
      "train loss:0.002706725065595238\n",
      "train loss:0.01217022995535268\n",
      "train loss:0.018537943161237025\n",
      "train loss:0.0195436115959798\n",
      "train loss:0.015746686824779296\n",
      "train loss:0.003459011933984813\n",
      "train loss:0.020003277550404288\n",
      "train loss:0.008298228881656522\n",
      "train loss:0.001765534017032827\n",
      "train loss:0.005243039746614085\n",
      "train loss:0.014325954151945037\n",
      "train loss:0.0030704915550868973\n",
      "train loss:0.04164321755040505\n",
      "train loss:0.008778114114009578\n",
      "train loss:0.01025732296870762\n",
      "train loss:0.014427307240615899\n",
      "train loss:0.012802109649770015\n",
      "train loss:0.0006862052314638097\n",
      "train loss:0.0041375724768661255\n",
      "train loss:0.004208169707602515\n",
      "train loss:0.0015299469912221553\n",
      "train loss:0.0034472341861256405\n",
      "train loss:0.002044653446850943\n",
      "train loss:0.004709831676492231\n",
      "train loss:0.008750177389659122\n",
      "train loss:0.0008451349385630398\n",
      "train loss:0.004086840372024627\n",
      "train loss:0.00662089555991628\n",
      "train loss:0.008900650587147783\n",
      "train loss:0.003131979033615139\n",
      "train loss:0.011033530236532876\n",
      "train loss:0.011223878002008907\n",
      "train loss:0.004709623861587718\n",
      "train loss:0.0062021536601094\n",
      "train loss:0.0018290995695753726\n",
      "train loss:0.0031168832045572405\n",
      "train loss:0.002047887999165391\n",
      "train loss:0.0043678744102921075\n",
      "train loss:0.0033516010551763726\n",
      "train loss:0.008417446711951425\n",
      "train loss:0.006081822009605061\n",
      "train loss:0.01679377194560857\n",
      "train loss:0.003382941324521645\n",
      "train loss:0.003567040247141472\n",
      "train loss:0.00804796124379857\n",
      "train loss:0.0294140080384512\n",
      "train loss:0.004718874663644\n",
      "train loss:0.0026699927358316473\n",
      "train loss:0.0609056986419706\n",
      "train loss:0.01606853227700592\n",
      "train loss:0.0017717104131515049\n",
      "train loss:0.0015483160239966832\n",
      "train loss:0.012735046772995131\n",
      "train loss:0.011036732104420468\n",
      "train loss:0.011044594571026111\n",
      "train loss:0.0028091761648437407\n",
      "train loss:0.035525299660023844\n",
      "train loss:0.0023806015445993773\n",
      "train loss:0.0023011576860979288\n",
      "train loss:0.01774741886561929\n",
      "train loss:0.01618125542307549\n",
      "train loss:0.015133362320609307\n",
      "train loss:0.004431009560460734\n",
      "train loss:0.0026835628818162025\n",
      "train loss:0.0008156165223961343\n",
      "train loss:0.000857473096883527\n",
      "train loss:0.0031975021864163126\n",
      "train loss:0.005220171728678148\n",
      "train loss:0.0028161387972708975\n",
      "train loss:0.02147941016842159\n",
      "train loss:0.024958991230415103\n",
      "train loss:0.0030096818574764555\n",
      "train loss:0.002676758500942588\n",
      "train loss:0.00888572940140523\n",
      "train loss:0.004121118749929478\n",
      "train loss:0.0024834286108383506\n",
      "train loss:0.0033028431414626504\n",
      "train loss:0.008097275527015066\n",
      "train loss:0.008285294850862506\n",
      "train loss:0.05150730314627963\n",
      "train loss:0.010164424787036812\n",
      "train loss:0.0010014549072276352\n",
      "train loss:0.0037484278863706057\n",
      "train loss:0.0031116054471413508\n",
      "train loss:0.006861180510293472\n",
      "train loss:0.004451200748487083\n",
      "train loss:0.00787693374207027\n",
      "train loss:0.017322539926620955\n",
      "train loss:0.002023512623501111\n",
      "train loss:0.039176708164953285\n",
      "train loss:0.000516676611019703\n",
      "train loss:0.007931803883195355\n",
      "train loss:0.011199830674878359\n",
      "train loss:0.0008620090049009095\n",
      "train loss:0.0015375598690169161\n",
      "train loss:0.007170159793410101\n",
      "train loss:0.006363515327255742\n",
      "train loss:0.003911324403095266\n",
      "train loss:0.005299734981761249\n",
      "train loss:0.004569201215925696\n",
      "train loss:0.002106432610024238\n",
      "train loss:0.01240477308981152\n",
      "train loss:0.008220129599097131\n",
      "train loss:0.0073913802313965\n",
      "train loss:0.007957232754443743\n",
      "train loss:0.0021056573244627283\n",
      "train loss:0.0021999532559174384\n",
      "train loss:0.008946666772165735\n",
      "train loss:0.002863760196369558\n",
      "train loss:0.013299178828341134\n",
      "train loss:0.0008930663781409816\n",
      "train loss:0.0016386422945666077\n",
      "train loss:0.0003761885940283925\n",
      "train loss:0.008484808185669572\n",
      "train loss:0.005750546859985839\n",
      "train loss:0.0010212040063094139\n",
      "train loss:0.020899020106878097\n",
      "train loss:0.006129420816594402\n",
      "train loss:0.007496555598031911\n",
      "train loss:0.007875430331756604\n",
      "train loss:0.03167287708253258\n",
      "train loss:0.019702603920757848\n",
      "train loss:0.0023875131687686162\n",
      "train loss:0.015459937240302963\n",
      "train loss:0.004330938471297704\n",
      "train loss:0.0051835845260207606\n",
      "train loss:0.0018470909219523094\n",
      "train loss:0.008007573296186364\n",
      "train loss:0.01121116792995522\n",
      "train loss:0.03365574262361392\n",
      "train loss:0.005511772054859674\n",
      "train loss:0.009350250388758955\n",
      "train loss:0.011305951216813461\n",
      "train loss:0.004121211616285124\n",
      "train loss:0.007267056026886677\n",
      "train loss:0.009446294582337625\n",
      "train loss:0.012051110787691745\n",
      "train loss:0.006417018894726742\n",
      "train loss:0.004413836208042651\n",
      "train loss:0.0011066066787058168\n",
      "train loss:0.01664188789857053\n",
      "train loss:0.011827106302948467\n",
      "train loss:0.006581768497405089\n",
      "train loss:0.002938963911331503\n",
      "train loss:0.019708486048522014\n",
      "train loss:0.0006209011156760297\n",
      "train loss:0.01379250863338743\n",
      "train loss:0.003930205455853295\n",
      "train loss:0.013851424041306425\n",
      "train loss:0.012099095899332384\n",
      "train loss:0.004170439301616039\n",
      "train loss:0.005235528153902524\n",
      "train loss:0.005441731470004353\n",
      "train loss:0.0016108933523037204\n",
      "train loss:0.0012394021533115016\n",
      "train loss:0.013461109293656863\n",
      "train loss:0.002757070263266265\n",
      "train loss:0.006142179494514951\n",
      "train loss:0.003441716018144042\n",
      "train loss:0.00881156784341038\n",
      "train loss:0.01933894836936771\n",
      "train loss:0.004338336968456783\n",
      "train loss:0.008835496827589958\n",
      "train loss:0.0017758221150826765\n",
      "train loss:0.00634145490864698\n",
      "train loss:0.018994001495157623\n",
      "train loss:0.057968203856630554\n",
      "train loss:0.0007896517181064051\n",
      "train loss:0.0012243485449991711\n",
      "train loss:0.011079808610134743\n",
      "train loss:0.004473540162793198\n",
      "train loss:0.0017375762087667235\n",
      "train loss:0.003484431449394433\n",
      "train loss:0.00354616262522155\n",
      "train loss:0.023118590778208895\n",
      "train loss:0.007217191458472394\n",
      "train loss:0.005389044009256136\n",
      "train loss:0.01405362612194131\n",
      "train loss:0.02545320648500771\n",
      "train loss:0.005690697478000966\n",
      "train loss:0.012322152851228438\n",
      "train loss:0.008689591564428481\n",
      "train loss:0.0019279311350634525\n",
      "train loss:0.020514208808498635\n",
      "train loss:0.004229638854552865\n",
      "train loss:0.004676868229403302\n",
      "train loss:0.005141014300948626\n",
      "train loss:0.03164090368044135\n",
      "train loss:0.01173948404876022\n",
      "train loss:0.007714684616168065\n",
      "train loss:0.02941770996164406\n",
      "train loss:0.0018444771587677947\n",
      "train loss:0.004224465298509146\n",
      "train loss:0.004203369415223711\n",
      "train loss:0.006859757657601924\n",
      "train loss:0.06556575164174812\n",
      "train loss:0.00159932515615353\n",
      "train loss:0.0221642118560466\n",
      "train loss:0.0066782757220140545\n",
      "train loss:0.018963766659092777\n",
      "train loss:0.001561474004951939\n",
      "train loss:0.01998658218819548\n",
      "train loss:0.029824868841466744\n",
      "train loss:0.016337245959709278\n",
      "train loss:0.0004598721010338703\n",
      "train loss:0.0037787093127949773\n",
      "train loss:0.00607869219043403\n",
      "train loss:0.00904438427996745\n",
      "train loss:0.0056680107550867035\n",
      "train loss:0.017356048017667203\n",
      "train loss:0.015207781423646293\n",
      "train loss:0.011184552882297485\n",
      "train loss:0.0010109802091307649\n",
      "train loss:0.010630448391024718\n",
      "train loss:0.004796703911879112\n",
      "train loss:0.0003369327121897469\n",
      "train loss:0.0033235626457006166\n",
      "train loss:0.0036453733996968034\n",
      "train loss:0.0007745051615084936\n",
      "train loss:0.0032596795144432893\n",
      "train loss:0.004695143265936573\n",
      "train loss:0.0031359498255126043\n",
      "train loss:0.003160587918884695\n",
      "train loss:0.0021831851787088813\n",
      "train loss:0.001076069226269436\n",
      "train loss:0.01411308477526022\n",
      "train loss:0.01370820287904847\n",
      "train loss:0.005722950824215275\n",
      "train loss:0.0037823032594572893\n",
      "train loss:0.0029471103496145957\n",
      "train loss:0.01124780304046931\n",
      "train loss:0.005860352595434695\n",
      "train loss:0.004285625648283192\n",
      "train loss:0.0036580719884880693\n",
      "train loss:0.00293400201518829\n",
      "train loss:0.021935090690867184\n",
      "train loss:0.07018050424073255\n",
      "train loss:0.008197278066427553\n",
      "train loss:0.009976640607814698\n",
      "train loss:0.004846975121224758\n",
      "train loss:0.0002670892243848198\n",
      "train loss:0.0014713659140644225\n",
      "train loss:0.015919732175212198\n",
      "train loss:0.0050495509387409035\n",
      "train loss:0.009100066870269024\n",
      "train loss:0.003067835190209468\n",
      "train loss:0.012471229778621569\n",
      "train loss:0.029887533462356505\n",
      "train loss:0.001975427115416814\n",
      "train loss:0.009516280916900407\n",
      "train loss:0.005992400832058794\n",
      "train loss:0.004738508507901488\n",
      "train loss:0.01166232631331493\n",
      "train loss:0.012782463407445634\n",
      "train loss:0.021210922055884374\n",
      "train loss:0.0026697353024586674\n",
      "train loss:0.0027104947041541876\n",
      "train loss:0.002452965645214614\n",
      "train loss:0.010384885007300995\n",
      "train loss:0.021561968740722883\n",
      "train loss:0.0015456082341898422\n",
      "train loss:0.003007314751851134\n",
      "train loss:0.0018770774740931844\n",
      "train loss:0.0069338136541917\n",
      "train loss:0.07256983641369046\n",
      "train loss:0.0028770436371533935\n",
      "train loss:0.02189897669929203\n",
      "train loss:0.005634616174834768\n",
      "train loss:0.005937854441503145\n",
      "train loss:0.004307838327590123\n",
      "train loss:0.009541998031359852\n",
      "train loss:0.04616447658780335\n",
      "train loss:0.0009491521872461939\n",
      "train loss:0.006313233667319754\n",
      "train loss:0.013792323011760026\n",
      "train loss:0.005106379686440059\n",
      "train loss:0.007568053443081389\n",
      "train loss:0.007152258810746619\n",
      "train loss:0.013238971865812637\n",
      "train loss:0.007600646428191942\n",
      "train loss:0.025602950413183237\n",
      "train loss:0.0021609462464860043\n",
      "train loss:0.006411816089206744\n",
      "train loss:0.0034366470185633875\n",
      "train loss:0.026581105651574562\n",
      "train loss:0.010544980558949434\n",
      "train loss:0.001989093396245634\n",
      "train loss:0.02088477483834279\n",
      "train loss:0.003794783370737709\n",
      "train loss:0.007363552815687834\n",
      "train loss:0.004136784206195768\n",
      "train loss:0.0007652704233948831\n",
      "train loss:0.00838717899763148\n",
      "train loss:0.012130725652747844\n",
      "train loss:0.02686687840957198\n",
      "train loss:0.0006630736537906072\n",
      "train loss:0.0008261301430301105\n",
      "train loss:0.00459778385559484\n",
      "train loss:0.005646830974142913\n",
      "train loss:0.0030555531418182784\n",
      "train loss:0.007324249726104078\n",
      "train loss:0.002434913095323642\n",
      "train loss:0.002727560864874832\n",
      "train loss:0.002461911562933412\n",
      "train loss:0.003956259708706549\n",
      "train loss:0.00469418192986468\n",
      "train loss:0.02545434679050008\n",
      "train loss:0.005429220458896426\n",
      "train loss:0.008188692264431157\n",
      "train loss:0.024107667550059574\n",
      "train loss:0.013222080344652163\n",
      "train loss:0.0025470152571525984\n",
      "train loss:0.004556171147481569\n",
      "train loss:0.0032676455235549724\n",
      "train loss:0.022131502272117597\n",
      "train loss:0.0008859088726358761\n",
      "train loss:0.013412715380856675\n",
      "train loss:0.009753634182014345\n",
      "train loss:0.004866547004853767\n",
      "train loss:0.018712811993095487\n",
      "train loss:0.001102104964119878\n",
      "train loss:0.004721250423370541\n",
      "train loss:0.008011851902982304\n",
      "train loss:0.0022347894520525855\n",
      "train loss:0.00450612844236328\n",
      "train loss:0.13054299111455778\n",
      "train loss:0.007400759241253068\n",
      "train loss:0.029816145536869364\n",
      "train loss:0.005788919218503822\n",
      "train loss:0.0032160261178819784\n",
      "train loss:0.0025257003494830754\n",
      "train loss:0.011611516484071221\n",
      "train loss:0.0028649766031135686\n",
      "train loss:0.004300796679593512\n",
      "train loss:0.0032027113869994867\n",
      "train loss:0.06062291443606491\n",
      "train loss:0.03119455550177568\n",
      "train loss:0.00502251308304405\n",
      "train loss:0.016837435915462808\n",
      "train loss:0.022752103661457565\n",
      "train loss:0.0194915491870221\n",
      "train loss:0.00274589211454724\n",
      "train loss:0.012361673330395413\n",
      "train loss:0.01640821227904421\n",
      "train loss:0.0028819740765663637\n",
      "train loss:0.011639966499231462\n",
      "train loss:0.0008978862895369366\n",
      "train loss:0.009915446266244674\n",
      "train loss:0.002531742798062146\n",
      "train loss:0.006978827278015704\n",
      "train loss:0.011103168697132026\n",
      "train loss:0.012961078829885049\n",
      "train loss:0.003359377660378415\n",
      "train loss:0.004653206470234875\n",
      "train loss:0.009186633842483168\n",
      "train loss:0.02059159655127023\n",
      "train loss:0.01250369174404795\n",
      "train loss:0.011367274520904335\n",
      "train loss:0.006245806439073802\n",
      "train loss:0.0021264841689829584\n",
      "train loss:0.002809563527724593\n",
      "train loss:0.0011660430708824126\n",
      "train loss:0.0488155576501528\n",
      "train loss:0.01240013880848763\n",
      "train loss:0.021988330753519213\n",
      "train loss:0.027212711190127043\n",
      "train loss:0.0008877807696128832\n",
      "train loss:0.003040580815753754\n",
      "train loss:0.06790549800181753\n",
      "train loss:0.013133885959684384\n",
      "train loss:0.019384821085184033\n",
      "train loss:0.0036024535305041634\n",
      "train loss:0.0033703792130312066\n",
      "train loss:0.0008328281623808302\n",
      "train loss:0.011715401211334901\n",
      "train loss:0.006042466594714957\n",
      "train loss:0.0013260462936146614\n",
      "train loss:0.018353972320218757\n",
      "train loss:0.034365675994502604\n",
      "train loss:0.018977741591576804\n",
      "train loss:0.006272910980250731\n",
      "train loss:0.005302990952667935\n",
      "train loss:0.002418428523971152\n",
      "train loss:0.000994234697533521\n",
      "train loss:0.0051277696980548395\n",
      "train loss:0.007028439621811707\n",
      "train loss:0.002040966326161017\n",
      "train loss:0.0068233831540606095\n",
      "train loss:0.008515470010108672\n",
      "train loss:0.02203290395784932\n",
      "train loss:0.00398116225915325\n",
      "train loss:0.016239444696662136\n",
      "train loss:0.04418124451908035\n",
      "train loss:0.0038761967483845255\n",
      "train loss:0.038563585872261406\n",
      "train loss:0.010882577127806208\n",
      "train loss:0.0076264453499294595\n",
      "train loss:0.003966461377703824\n",
      "train loss:0.002974166390819535\n",
      "train loss:0.010203112255286252\n",
      "train loss:0.010676591638577789\n",
      "train loss:0.0032873083555278407\n",
      "train loss:0.0009051301856552889\n",
      "train loss:0.008994535351697776\n",
      "train loss:0.010206149178228228\n",
      "train loss:0.027244152012073652\n",
      "train loss:0.0044472389928089376\n",
      "train loss:0.027603307948232066\n",
      "=== epoch:10, train acc:0.989, test acc:0.989 ===\n",
      "train loss:0.059764275838188274\n",
      "train loss:0.011181134393112269\n",
      "train loss:0.06125724128266419\n",
      "train loss:0.0005783087405371506\n",
      "train loss:0.000357562702993268\n",
      "train loss:0.0014568798727566995\n",
      "train loss:0.006545336863962556\n",
      "train loss:0.0024032555996214167\n",
      "train loss:0.006574397094918178\n",
      "train loss:0.0013855228521111797\n",
      "train loss:0.01996358883944696\n",
      "train loss:0.027087932112429637\n",
      "train loss:0.006185225912351353\n",
      "train loss:0.004832437845422332\n",
      "train loss:0.0024491510542765933\n",
      "train loss:0.004376591661587901\n",
      "train loss:0.0012244968026797064\n",
      "train loss:0.00837250941414973\n",
      "train loss:0.014433831836164117\n",
      "train loss:0.01398534617646466\n",
      "train loss:0.015656311777084958\n",
      "train loss:0.01054404253101322\n",
      "train loss:0.009819854709528054\n",
      "train loss:0.03421974721770705\n",
      "train loss:0.009650276310869212\n",
      "train loss:0.008062487244636192\n",
      "train loss:0.02019531013580698\n",
      "train loss:0.016858180430928075\n",
      "train loss:0.011288852616429226\n",
      "train loss:0.010798729114416306\n",
      "train loss:0.003435503031050664\n",
      "train loss:0.00666895176614911\n",
      "train loss:0.006152926451914842\n",
      "train loss:0.028600555666792062\n",
      "train loss:0.0016191942318662495\n",
      "train loss:0.002309521322521669\n",
      "train loss:0.003516715265178079\n",
      "train loss:0.004698876472674485\n",
      "train loss:0.001591409993036711\n",
      "train loss:0.005128363615606281\n",
      "train loss:0.026350705077133302\n",
      "train loss:0.023631765830936863\n",
      "train loss:0.002622168056308625\n",
      "train loss:0.004031011622825822\n",
      "train loss:0.0019842909556630085\n",
      "train loss:0.030400585182868353\n",
      "train loss:0.006596446532839809\n",
      "train loss:0.00048001155545148675\n",
      "train loss:0.060602484401503356\n",
      "train loss:0.006261049168075084\n",
      "train loss:0.00253868051994032\n",
      "train loss:0.008095074015903932\n",
      "train loss:0.002856677957966292\n",
      "train loss:0.005662198847412365\n",
      "train loss:0.015432033849386795\n",
      "train loss:0.0010228464965811239\n",
      "train loss:0.01909834719980356\n",
      "train loss:0.026856161717820414\n",
      "train loss:0.008667018009026927\n",
      "train loss:0.002419396323155598\n",
      "train loss:0.012795905682948416\n",
      "train loss:0.0053028576942407545\n",
      "train loss:0.006512628272813379\n",
      "train loss:0.007568218633046995\n",
      "train loss:0.002282944654377073\n",
      "train loss:0.0018414213233733023\n",
      "train loss:0.0016491381910304947\n",
      "train loss:0.028706037875741556\n",
      "train loss:0.0019230056391161326\n",
      "train loss:0.027400183661739165\n",
      "train loss:0.007060145459394103\n",
      "train loss:0.004298212266226657\n",
      "train loss:0.0031216186987386655\n",
      "train loss:0.002917170148979491\n",
      "train loss:0.013422115759137116\n",
      "train loss:0.002290811557793704\n",
      "train loss:0.0027492465539375914\n",
      "train loss:0.0033905250975805653\n",
      "train loss:0.0040146882275780525\n",
      "train loss:0.025566392811930596\n",
      "train loss:0.0030373755461097383\n",
      "train loss:0.006430115010143336\n",
      "train loss:0.007542670898612438\n",
      "train loss:0.0001919324294722629\n",
      "train loss:0.004511768323707482\n",
      "train loss:0.01573681408675629\n",
      "train loss:0.004522213757089337\n",
      "train loss:0.006838401933544287\n",
      "train loss:0.0020750359774771043\n",
      "train loss:0.0008395784484555583\n",
      "train loss:0.01068818612566702\n",
      "train loss:0.0023510003973610193\n",
      "train loss:0.006333637409371171\n",
      "train loss:0.02652734263066954\n",
      "train loss:0.006348168589638892\n",
      "train loss:0.001504792167428351\n",
      "train loss:0.006242443682292585\n",
      "train loss:0.009060226720411431\n",
      "train loss:0.0059916030567063105\n",
      "train loss:0.005008909073035293\n",
      "train loss:0.001958183156541709\n",
      "train loss:0.005845870671995102\n",
      "train loss:0.0021622132243891328\n",
      "train loss:0.003852772598083214\n",
      "train loss:0.002683132218736432\n",
      "train loss:0.010438748128537435\n",
      "train loss:0.002108777937754697\n",
      "train loss:0.005382825345741601\n",
      "train loss:0.002251889478441197\n",
      "train loss:0.0005966100494758512\n",
      "train loss:0.014100092015132723\n",
      "train loss:0.005050413339351484\n",
      "train loss:0.004508758460902539\n",
      "train loss:0.0006281388067853944\n",
      "train loss:0.0031270741298207966\n",
      "train loss:0.0025391850357269503\n",
      "train loss:0.0019397622510239504\n",
      "train loss:0.0053490467179084485\n",
      "train loss:0.005270010002101861\n",
      "train loss:0.030388590833307038\n",
      "train loss:0.03542404947263582\n",
      "train loss:0.003255979655341024\n",
      "train loss:0.024567558459712847\n",
      "train loss:0.0027035746177820614\n",
      "train loss:0.0012180152638688103\n",
      "train loss:0.0013656746576381938\n",
      "train loss:0.0056153969101926\n",
      "train loss:0.06285179099601836\n",
      "train loss:0.05955753933476832\n",
      "train loss:0.0017525298515141177\n",
      "train loss:0.002832587563314049\n",
      "train loss:0.0006830027945932093\n",
      "train loss:0.006083196057982743\n",
      "train loss:0.003077574495901471\n",
      "train loss:0.0003780508297970042\n",
      "train loss:0.002773681880829958\n",
      "train loss:0.020546231418750515\n",
      "train loss:0.00219334901564219\n",
      "train loss:0.0009606246123819882\n",
      "train loss:0.0204988604348242\n",
      "train loss:0.00589606656767283\n",
      "train loss:0.001234805452664192\n",
      "train loss:0.001054915194295226\n",
      "train loss:0.0033360350407472027\n",
      "train loss:0.019612399209643805\n",
      "train loss:0.00400640779436228\n",
      "train loss:0.003033229884187012\n",
      "train loss:0.002817198667918347\n",
      "train loss:0.025136206210590154\n",
      "train loss:0.011148814152394392\n",
      "train loss:0.0032052728535305296\n",
      "train loss:0.007741905643024242\n",
      "train loss:0.007442301459309998\n",
      "train loss:0.004256099743723677\n",
      "train loss:0.0011494764214672647\n",
      "train loss:0.0018764210871081905\n",
      "train loss:0.006443202717857918\n",
      "train loss:0.005523103288576224\n",
      "train loss:0.002036602201442895\n",
      "train loss:0.0072757343362597005\n",
      "train loss:0.0018809069487132415\n",
      "train loss:0.0013816703256596227\n",
      "train loss:0.006013331529885719\n",
      "train loss:0.00416629557995558\n",
      "train loss:0.004577955226170955\n",
      "train loss:0.0036659535126968494\n",
      "train loss:0.002756263241922017\n",
      "train loss:0.007647959141181309\n",
      "train loss:0.01645458283178596\n",
      "train loss:0.012231642123893476\n",
      "train loss:0.014887715382978341\n",
      "train loss:0.0011984559175055999\n",
      "train loss:0.004661808556126163\n",
      "train loss:0.0022127789905407504\n",
      "train loss:0.004690137645917159\n",
      "train loss:0.005763613270985163\n",
      "train loss:0.0132947915752665\n",
      "train loss:0.05132954926237356\n",
      "train loss:0.04163536522265028\n",
      "train loss:0.022887044121107508\n",
      "train loss:0.002328336642291093\n",
      "train loss:0.00641622347697591\n",
      "train loss:0.004002007715680853\n",
      "train loss:0.005255172746735529\n",
      "train loss:0.00568387257571629\n",
      "train loss:0.0014267006424352378\n",
      "train loss:0.005460532719794227\n",
      "train loss:0.002697703818339893\n",
      "train loss:0.1271015207310389\n",
      "train loss:0.004227283016880456\n",
      "train loss:0.008189005782253813\n",
      "train loss:0.004582964409391017\n",
      "train loss:0.027989084272101717\n",
      "train loss:0.0043141870346143744\n",
      "train loss:0.0010525845192793496\n",
      "train loss:0.0020782713326382317\n",
      "train loss:0.0013017936266423538\n",
      "train loss:0.0019106378796316156\n",
      "train loss:0.012456918403404429\n",
      "train loss:0.012135544050673828\n",
      "train loss:0.005513830085677531\n",
      "train loss:0.02397443522804945\n",
      "train loss:0.024407396967592355\n",
      "train loss:0.0005397933560778225\n",
      "train loss:0.0022561765641000413\n",
      "train loss:0.0021128784019576407\n",
      "train loss:0.003306760370711493\n",
      "train loss:0.00522414100003225\n",
      "train loss:0.001001090618057491\n",
      "train loss:0.012183926559900965\n",
      "train loss:0.004357334279170039\n",
      "train loss:0.001801145261851053\n",
      "train loss:0.0037674564017646504\n",
      "train loss:0.004951068019213261\n",
      "train loss:0.004656064549786712\n",
      "train loss:0.004423690277961658\n",
      "train loss:0.0030105409025762324\n",
      "train loss:0.0019606232818968903\n",
      "train loss:0.0030490724527072926\n",
      "train loss:0.006761823321543362\n",
      "train loss:0.005917356679118095\n",
      "train loss:0.005167161739231239\n",
      "train loss:0.008588563614928013\n",
      "train loss:0.001382414366454416\n",
      "train loss:0.004462530853216655\n",
      "train loss:0.0011980384126952916\n",
      "train loss:0.004210852569274898\n",
      "train loss:0.010686123400110922\n",
      "train loss:0.005061306716698017\n",
      "train loss:0.012176864355473202\n",
      "train loss:0.0032727672875702296\n",
      "train loss:0.006145618856418209\n",
      "train loss:0.006846196443280323\n",
      "train loss:0.00331719333970659\n",
      "train loss:0.00509444456055806\n",
      "train loss:0.015280920593961068\n",
      "train loss:0.00477639955140547\n",
      "train loss:0.006741319624039316\n",
      "train loss:0.0035715701755290774\n",
      "train loss:0.00046606342743844294\n",
      "train loss:0.010441912101777376\n",
      "train loss:0.004678939952230453\n",
      "train loss:0.0029808778283855575\n",
      "train loss:0.018726845175634076\n",
      "train loss:0.01243626178417079\n",
      "train loss:0.0059752250558667485\n",
      "train loss:0.0012946051085360013\n",
      "train loss:0.0026324699782603843\n",
      "train loss:0.009742447860168727\n",
      "train loss:0.001577550684271495\n",
      "train loss:0.002559486988756734\n",
      "train loss:0.010789418070441297\n",
      "train loss:0.0041025378514840324\n",
      "train loss:0.0011475801646713356\n",
      "train loss:0.0010488221868550616\n",
      "train loss:0.012571888657633978\n",
      "train loss:0.0025699341105232427\n",
      "train loss:0.004418153841127606\n",
      "train loss:0.02133746351528206\n",
      "train loss:0.003905485073588302\n",
      "train loss:0.002056249575856754\n",
      "train loss:0.0020087328654377927\n",
      "train loss:0.0024086624875348885\n",
      "train loss:0.008769221269150473\n",
      "train loss:0.005702742168839211\n",
      "train loss:0.006463700653588806\n",
      "train loss:0.006429250107397454\n",
      "train loss:0.006491468804482022\n",
      "train loss:0.005004576611894221\n",
      "train loss:0.01920918281519219\n",
      "train loss:0.0419401242908648\n",
      "train loss:0.002577609550040044\n",
      "train loss:0.003744960831416826\n",
      "train loss:0.0055476752487936196\n",
      "train loss:0.0028604783489277652\n",
      "train loss:0.009989085883931196\n",
      "train loss:0.004125563608213416\n",
      "train loss:0.002439207450070178\n",
      "train loss:0.010477880345997675\n",
      "train loss:0.007504434210110921\n",
      "train loss:0.014879860064992421\n",
      "train loss:0.02827218931933286\n",
      "train loss:0.012288977738411484\n",
      "train loss:0.009817321213133622\n",
      "train loss:0.006042956823964746\n",
      "train loss:0.003745333255606795\n",
      "train loss:0.0010004863999540704\n",
      "train loss:0.0010982509577058446\n",
      "train loss:0.024964144646652794\n",
      "train loss:0.003929651191823074\n",
      "train loss:0.041956972228155545\n",
      "train loss:0.003993143948600162\n",
      "train loss:0.0007316921793383988\n",
      "train loss:0.014423405975110866\n",
      "train loss:0.007156560792494817\n",
      "train loss:0.008432754832940764\n",
      "train loss:0.0019390789339984052\n",
      "train loss:0.013979635142345664\n",
      "train loss:0.02808362711720209\n",
      "train loss:0.0005756203401425892\n",
      "train loss:0.015570426228845748\n",
      "train loss:0.010307654176409508\n",
      "train loss:0.0024611996514358\n",
      "train loss:0.0012378362931924688\n",
      "train loss:0.08402244843760188\n",
      "train loss:0.0006485755894781425\n",
      "train loss:0.009164469135634224\n",
      "train loss:0.016440482283151148\n",
      "train loss:0.005073049389918906\n",
      "train loss:0.0013645583438679071\n",
      "train loss:0.043890268547897154\n",
      "train loss:0.010535474215597515\n",
      "train loss:0.008235271599894513\n",
      "train loss:0.019780293865612225\n",
      "train loss:0.006985003957141713\n",
      "train loss:0.0034897789669010777\n",
      "train loss:0.007141413419475563\n",
      "train loss:0.000653721311764724\n",
      "train loss:0.0011141930836315761\n",
      "train loss:0.014844780856179263\n",
      "train loss:0.005678664590148624\n",
      "train loss:0.0033231396206641517\n",
      "train loss:0.0004007055760987951\n",
      "train loss:0.011625230182913466\n",
      "train loss:0.00690868631895164\n",
      "train loss:0.004296137289776588\n",
      "train loss:0.006817942056514512\n",
      "train loss:0.0024122728595653018\n",
      "train loss:0.0034067822766347916\n",
      "train loss:0.006923016530103771\n",
      "train loss:0.0030186418684618353\n",
      "train loss:0.014150766510003918\n",
      "train loss:0.0026535760830732297\n",
      "train loss:0.004353930074852065\n",
      "train loss:0.0037896115197031304\n",
      "train loss:0.016294782654681077\n",
      "train loss:0.008938905697665887\n",
      "train loss:0.005292409038045911\n",
      "train loss:0.0012074203760720928\n",
      "train loss:0.02506604664352411\n",
      "train loss:0.004638181090687149\n",
      "train loss:0.018897451548319233\n",
      "train loss:0.007436811524492235\n",
      "train loss:0.015655951943831573\n",
      "train loss:0.0013334739735137392\n",
      "train loss:0.005240251149572059\n",
      "train loss:0.006487485734384331\n",
      "train loss:0.0026743144524616898\n",
      "train loss:0.0021884558186391033\n",
      "train loss:0.0060700041687126345\n",
      "train loss:0.003118999844417026\n",
      "train loss:0.031055903700183966\n",
      "train loss:0.00798074878994562\n",
      "train loss:0.02780066000306655\n",
      "train loss:0.044166218094693316\n",
      "train loss:0.022349685801085727\n",
      "train loss:0.012576344510201851\n",
      "train loss:0.004866685053835698\n",
      "train loss:0.004237682155438517\n",
      "train loss:0.0072111011699793745\n",
      "train loss:0.010476267175500629\n",
      "train loss:0.0009649293928622295\n",
      "train loss:0.06368973978287668\n",
      "train loss:0.02023823313096075\n",
      "train loss:0.007921913269035512\n",
      "train loss:0.009059148951084898\n",
      "train loss:0.004189374340388373\n",
      "train loss:0.006299935806548504\n",
      "train loss:0.0236113780243553\n",
      "train loss:0.0032546008382834586\n",
      "train loss:0.03767953531762488\n",
      "train loss:0.013804882641828444\n",
      "train loss:0.03987004427531346\n",
      "train loss:0.016276522990844377\n",
      "train loss:0.001612997254493085\n",
      "train loss:0.0015207085431178755\n",
      "train loss:0.015324081347122447\n",
      "train loss:0.008882739692368618\n",
      "train loss:0.003686181159662767\n",
      "train loss:0.008978949799874913\n",
      "train loss:0.0037291743413940324\n",
      "train loss:0.0021381390069215157\n",
      "train loss:0.01856010246631169\n",
      "train loss:0.0027987766042326984\n",
      "train loss:0.0014639815849077456\n",
      "train loss:0.0008334715536954669\n",
      "train loss:0.005034547529155514\n",
      "train loss:0.005123406167190652\n",
      "train loss:0.005153485776297178\n",
      "train loss:0.01985922086771197\n",
      "train loss:0.009828441731058514\n",
      "train loss:0.006352305487021664\n",
      "train loss:0.0017339989004862822\n",
      "train loss:0.00308300140194421\n",
      "train loss:0.09605471088128781\n",
      "train loss:0.00698562043823311\n",
      "train loss:0.005973111164855504\n",
      "train loss:0.003896884913473489\n",
      "train loss:0.023907076829344325\n",
      "train loss:0.0011996224359805087\n",
      "train loss:0.0037022885193707415\n",
      "train loss:0.003983524329023502\n",
      "train loss:0.003614273308231949\n",
      "train loss:0.002156301237092073\n",
      "train loss:0.012395215632762127\n",
      "train loss:0.0016765645208770153\n",
      "train loss:0.0006354884728974464\n",
      "train loss:0.0072690703939326876\n",
      "train loss:0.0023853419424096165\n",
      "train loss:0.007444691430954129\n",
      "train loss:0.007815899477850365\n",
      "train loss:0.009194742765254078\n",
      "train loss:0.001439168206115226\n",
      "train loss:0.009625769175306881\n",
      "train loss:0.0156393737339347\n",
      "train loss:0.0076841027087450565\n",
      "train loss:0.0017373859864112929\n",
      "train loss:0.0016272775926753787\n",
      "train loss:0.003168102879375022\n",
      "train loss:0.045873329011736075\n",
      "train loss:0.0009470836120757735\n",
      "train loss:0.02361640137412575\n",
      "train loss:0.002980633571226846\n",
      "train loss:0.01156893097345433\n",
      "train loss:0.005318299558248552\n",
      "train loss:0.001305893709071165\n",
      "train loss:0.0015239685811060141\n",
      "train loss:0.0008678904243853022\n",
      "train loss:0.08018635217149037\n",
      "train loss:0.0011469426118090923\n",
      "train loss:0.017477169948889662\n",
      "train loss:0.0007786421115582866\n",
      "train loss:0.005952980494224411\n",
      "train loss:0.027635310919061778\n",
      "train loss:0.0009395284678262235\n",
      "train loss:0.003765745299496192\n",
      "train loss:0.002030110111469329\n",
      "train loss:0.036022853258097884\n",
      "train loss:0.015545307346745377\n",
      "train loss:0.014987020632093253\n",
      "train loss:0.005697629476801805\n",
      "train loss:0.004777346456169716\n",
      "train loss:0.03139068844874129\n",
      "train loss:0.003552907422792263\n",
      "train loss:0.0020191171830240117\n",
      "train loss:0.004466519136115914\n",
      "train loss:0.041219222889707315\n",
      "train loss:0.004254806660593203\n",
      "train loss:0.004428904061882718\n",
      "train loss:0.003670061371870661\n",
      "train loss:0.0018756854688331728\n",
      "train loss:0.0037743921720022815\n",
      "train loss:0.005285478532866011\n",
      "train loss:0.008219650270967412\n",
      "train loss:0.007384173500065245\n",
      "train loss:0.004243151213314554\n",
      "train loss:0.003840602427185587\n",
      "train loss:0.0023082005521187885\n",
      "train loss:0.013280775067168168\n",
      "train loss:0.011939882589646922\n",
      "train loss:0.0020466359084542873\n",
      "train loss:0.007233532160260907\n",
      "train loss:0.002021466371020105\n",
      "train loss:0.0028453545209640558\n",
      "train loss:0.002640354785239545\n",
      "train loss:0.00741976992660691\n",
      "train loss:0.017566138533006953\n",
      "train loss:0.01638942162575477\n",
      "train loss:0.005854990195418953\n",
      "train loss:0.0013375885748392099\n",
      "train loss:0.0023581052035917334\n",
      "train loss:0.0282163195292103\n",
      "train loss:0.020055211519878137\n",
      "train loss:0.01700963196630235\n",
      "train loss:0.00341000153265891\n",
      "train loss:0.00333486974077586\n",
      "train loss:0.0010498252065450659\n",
      "train loss:0.002708757233611989\n",
      "train loss:0.012868683245727486\n",
      "train loss:0.0011192821103054433\n",
      "train loss:0.012016995609921938\n",
      "train loss:0.007673259582128877\n",
      "train loss:0.0013471471113954685\n",
      "train loss:0.016015458645472953\n",
      "train loss:0.0008258874151390038\n",
      "train loss:0.020149032712791864\n",
      "train loss:0.007482737056485175\n",
      "train loss:0.0310022866034846\n",
      "train loss:0.007098537050266624\n",
      "train loss:0.01770530101493896\n",
      "train loss:0.005259390134339325\n",
      "train loss:0.013496361221012805\n",
      "train loss:0.0030418798844374932\n",
      "train loss:0.01699751054116176\n",
      "train loss:0.0013666706137054122\n",
      "train loss:0.009598761559878136\n",
      "train loss:0.0015817741602807075\n",
      "train loss:0.0018459613672390646\n",
      "train loss:0.005953792422453871\n",
      "train loss:0.004816777706324485\n",
      "train loss:0.003907223359610194\n",
      "train loss:0.0016687220795535674\n",
      "train loss:0.0021009771543256963\n",
      "train loss:0.0025249895570934903\n",
      "train loss:0.008242134021777023\n",
      "train loss:0.00470955894041199\n",
      "train loss:0.003106637909442706\n",
      "train loss:0.0010852303161027555\n",
      "train loss:0.02813809063546013\n",
      "train loss:0.011350529773272429\n",
      "train loss:0.009643072526366392\n",
      "train loss:0.008502160427859267\n",
      "train loss:0.038697664994161815\n",
      "train loss:0.007229306384295407\n",
      "train loss:0.0027425601124242897\n",
      "train loss:0.0038890391671956943\n",
      "train loss:0.0011870425590877645\n",
      "train loss:0.003288318127430796\n",
      "train loss:0.014875621120254949\n",
      "train loss:0.016374547354874022\n",
      "train loss:0.004968092227280497\n",
      "train loss:0.0009903768331710559\n",
      "train loss:0.0023230003558270818\n",
      "train loss:0.001489395678225427\n",
      "train loss:0.013935254675974972\n",
      "train loss:0.001188199620229465\n",
      "train loss:0.016117335690231913\n",
      "train loss:0.0045766107107889096\n",
      "train loss:0.005835374356454426\n",
      "train loss:0.015266498628894103\n",
      "train loss:0.007849008244546964\n",
      "train loss:0.0071949044056253695\n",
      "train loss:0.033304705023327205\n",
      "train loss:0.004946120720574982\n",
      "train loss:0.027137478015183958\n",
      "train loss:0.0012945727422191246\n",
      "train loss:0.0016801000462725142\n",
      "train loss:0.008551707304264532\n",
      "train loss:0.005381326037357558\n",
      "train loss:0.001288678027153756\n",
      "train loss:0.0007499706630879835\n",
      "train loss:0.0005877246884661244\n",
      "train loss:0.006759432299931383\n",
      "train loss:0.005868969463552048\n",
      "train loss:0.015225385734634788\n",
      "train loss:0.003792251438962127\n",
      "train loss:0.00809248481433556\n",
      "train loss:0.015786682266089966\n",
      "train loss:0.004435948412348328\n",
      "train loss:0.0030058461704483303\n",
      "train loss:0.006408474574081754\n",
      "train loss:0.014335912901914362\n",
      "train loss:0.01951723095914395\n",
      "train loss:0.00412774037634278\n",
      "train loss:0.0003546565759341234\n",
      "train loss:0.012880498376444872\n",
      "train loss:0.003581832279905425\n",
      "train loss:0.009913368643402998\n",
      "train loss:0.007195577270895926\n",
      "train loss:0.003987591674658531\n",
      "train loss:0.004408846137220688\n",
      "train loss:0.005950718236006023\n",
      "train loss:0.017896825562628907\n",
      "train loss:0.0013507813304643834\n",
      "train loss:0.006748136636892791\n",
      "train loss:0.0006646125106033556\n",
      "train loss:0.005497636179731179\n",
      "train loss:0.0015170964432612624\n",
      "train loss:0.0025187615997642704\n",
      "train loss:0.003853487315387286\n",
      "train loss:0.002266879227378187\n",
      "train loss:0.006846461615925583\n",
      "train loss:0.026905517167355387\n",
      "train loss:0.005394390994718615\n",
      "train loss:0.005367595554456689\n",
      "train loss:0.03118781814097649\n",
      "train loss:0.005114549203085993\n",
      "train loss:0.0034864939163976295\n",
      "train loss:0.011125949444700734\n",
      "train loss:0.0011615640525108203\n",
      "train loss:0.015858380047893857\n",
      "train loss:0.004827897454379507\n",
      "train loss:0.002858977480305902\n",
      "train loss:0.014248585513086862\n",
      "train loss:0.0012907528757644777\n",
      "train loss:0.0010116337073047522\n",
      "train loss:0.021339260910312085\n",
      "train loss:0.02951380744380675\n",
      "train loss:0.0135164405075817\n",
      "train loss:0.0024844127213588117\n",
      "train loss:0.0054838606527894814\n",
      "train loss:0.0032651881300600257\n",
      "train loss:0.004617088043329391\n",
      "train loss:0.019229967376236085\n",
      "train loss:0.0019494402557934504\n",
      "train loss:0.00548635198100337\n",
      "train loss:0.00782876027891113\n",
      "train loss:0.010264653643659584\n",
      "train loss:0.008131097740363196\n",
      "train loss:0.004007561182638194\n",
      "=== epoch:11, train acc:0.994, test acc:0.988 ===\n",
      "train loss:0.02096488818825843\n",
      "train loss:0.0011371708935164252\n",
      "train loss:0.022197956288166423\n",
      "train loss:0.04273036801409348\n",
      "train loss:0.0020404955305995147\n",
      "train loss:0.0015634513511455614\n",
      "train loss:0.004203227837063442\n",
      "train loss:0.013654665173600547\n",
      "train loss:0.001212914046980266\n",
      "train loss:0.015019960990537672\n",
      "train loss:0.003388320199790643\n",
      "train loss:0.001977005501656614\n",
      "train loss:0.003798354431806444\n",
      "train loss:0.00036418439850042275\n",
      "train loss:0.030505016032707784\n",
      "train loss:0.011649327531279237\n",
      "train loss:0.010000369721283528\n",
      "train loss:0.0016495162569950558\n",
      "train loss:0.00085823032337521\n",
      "train loss:0.001732962841593948\n",
      "train loss:0.00858555838178073\n",
      "train loss:0.003695640932533521\n",
      "train loss:0.004230487613529477\n",
      "train loss:0.0008122999292087183\n",
      "train loss:0.011705111666525719\n",
      "train loss:0.011304028944559697\n",
      "train loss:0.0005368059966938273\n",
      "train loss:0.01445832793827646\n",
      "train loss:0.00380989051730787\n",
      "train loss:0.0008740789830929594\n",
      "train loss:0.0011076095325209658\n",
      "train loss:0.005981583911466212\n",
      "train loss:0.018736424465099568\n",
      "train loss:0.015336666901268827\n",
      "train loss:0.007128765953314939\n",
      "train loss:0.0027691041186391242\n",
      "train loss:0.0007955481682983908\n",
      "train loss:0.038341088710003295\n",
      "train loss:0.009436515617305512\n",
      "train loss:0.01082019776517019\n",
      "train loss:0.010917287523828628\n",
      "train loss:0.0022659984984794257\n",
      "train loss:0.008272909113419767\n",
      "train loss:0.014327132536508469\n",
      "train loss:0.005906358991931437\n",
      "train loss:0.006418146550054639\n",
      "train loss:0.007791916726830962\n",
      "train loss:0.000752452575805184\n",
      "train loss:0.014773995617198516\n",
      "train loss:0.009480138818814415\n",
      "train loss:0.008897852662842555\n",
      "train loss:0.00196483379861207\n",
      "train loss:0.0016732519107977401\n",
      "train loss:0.02205645490279093\n",
      "train loss:0.002719553365947539\n",
      "train loss:0.0012248110601684953\n",
      "train loss:0.0037835402504309682\n",
      "train loss:0.004318696875228786\n",
      "train loss:0.0038317170751794305\n",
      "train loss:0.004302263743328829\n",
      "train loss:0.003346784353415707\n",
      "train loss:0.002805817916637106\n",
      "train loss:0.008412219690668958\n",
      "train loss:0.0009949480000536555\n",
      "train loss:0.01177594242814587\n",
      "train loss:0.005134775470230768\n",
      "train loss:0.004966509449282755\n",
      "train loss:0.0012738315761725932\n",
      "train loss:0.007867377047644777\n",
      "train loss:0.001292569938999671\n",
      "train loss:0.0035602110474017372\n",
      "train loss:0.005683366919924914\n",
      "train loss:0.000478550311409113\n",
      "train loss:0.0012970650021209699\n",
      "train loss:0.0013003969984744506\n",
      "train loss:0.0042218984396092275\n",
      "train loss:0.005585542854383697\n",
      "train loss:0.0018329715335533717\n",
      "train loss:0.00423737796384686\n",
      "train loss:0.018191625498141493\n",
      "train loss:0.0036257988674508225\n",
      "train loss:0.007040411319185171\n",
      "train loss:0.001493601641341839\n",
      "train loss:0.0029337461441970125\n",
      "train loss:0.0070597085775733134\n",
      "train loss:0.017944980871268723\n",
      "train loss:0.0026543233083925395\n",
      "train loss:0.0017925039227973771\n",
      "train loss:0.008041541404461299\n",
      "train loss:0.0006196054735429906\n",
      "train loss:0.0056911564136975425\n",
      "train loss:0.0056557378876933295\n",
      "train loss:0.003394484245468877\n",
      "train loss:0.0026357860944151413\n",
      "train loss:0.0007860031299413677\n",
      "train loss:0.014347139996705074\n",
      "train loss:0.006004675134382891\n",
      "train loss:0.011039688333972151\n",
      "train loss:0.00274793781405217\n",
      "train loss:0.0006588311546399424\n",
      "train loss:0.0011324277130060401\n",
      "train loss:0.0005046759243983057\n",
      "train loss:0.0021521394127213575\n",
      "train loss:0.0006876629336638225\n",
      "train loss:0.0059283059376129\n",
      "train loss:0.004432835785496164\n",
      "train loss:0.001210374098171696\n",
      "train loss:0.005216566885168643\n",
      "train loss:0.0018370091538551432\n",
      "train loss:0.001601329774181416\n",
      "train loss:0.0009782298565040432\n",
      "train loss:0.0014478136194496624\n",
      "train loss:0.017869242984595697\n",
      "train loss:0.0012798750794252784\n",
      "train loss:0.007432262541038858\n",
      "train loss:0.0037393248747948915\n",
      "train loss:0.0015532838485517017\n",
      "train loss:0.0014828753378937907\n",
      "train loss:0.001880749854755255\n",
      "train loss:0.003927143018953143\n",
      "train loss:0.007671616428721121\n",
      "train loss:0.00040668314029110303\n",
      "train loss:0.006958835384635712\n",
      "train loss:0.0063058860958108654\n",
      "train loss:0.011452898742708684\n",
      "train loss:0.0028127708650335283\n",
      "train loss:0.0013851702168220438\n",
      "train loss:0.0019801363013633405\n",
      "train loss:0.0008204150568600385\n",
      "train loss:0.0029062521357995892\n",
      "train loss:0.05166731322415597\n",
      "train loss:0.007082089752356323\n",
      "train loss:0.0024840209125568157\n",
      "train loss:0.015963513979046547\n",
      "train loss:0.0015362889550700062\n",
      "train loss:0.0034951681630373244\n",
      "train loss:0.0016948877162499235\n",
      "train loss:0.004546484356439595\n",
      "train loss:0.004820786044591545\n",
      "train loss:0.003301095557135457\n",
      "train loss:0.01290556709630706\n",
      "train loss:0.0010880161941438544\n",
      "train loss:0.0029851770250280876\n",
      "train loss:0.0020867430086909788\n",
      "train loss:0.018698495458078782\n",
      "train loss:0.005945617308366586\n",
      "train loss:0.009169739652637541\n",
      "train loss:0.005303897845210959\n",
      "train loss:0.003215058729700351\n",
      "train loss:0.005338143269671187\n",
      "train loss:0.002405394839138137\n",
      "train loss:0.0024524648413246433\n",
      "train loss:0.0028568342124525984\n",
      "train loss:0.002252542171718047\n",
      "train loss:0.007405172037228482\n",
      "train loss:0.036438694403271486\n",
      "train loss:0.0033501698201395896\n",
      "train loss:0.0005518873239038203\n",
      "train loss:0.024863082164232206\n",
      "train loss:0.002578320458447687\n",
      "train loss:0.0016232034635666024\n",
      "train loss:0.005238101285335151\n",
      "train loss:0.0012277602771479572\n",
      "train loss:0.003205222503706213\n",
      "train loss:0.0004614040025438218\n",
      "train loss:0.01421205296417282\n",
      "train loss:0.0020648375409783744\n",
      "train loss:0.0003672464926551678\n",
      "train loss:0.0030186326511679852\n",
      "train loss:0.0006644319754901783\n",
      "train loss:0.0028738178849236524\n",
      "train loss:0.004920139819660196\n",
      "train loss:0.004550259023311234\n",
      "train loss:0.004522858389300839\n",
      "train loss:0.012059841273881758\n",
      "train loss:0.0011160237074833556\n",
      "train loss:0.002538441809294878\n",
      "train loss:0.0013854734278482383\n",
      "train loss:0.004544825960695826\n",
      "train loss:0.04909036715500785\n",
      "train loss:0.005931153907973349\n",
      "train loss:0.0036840102398667616\n",
      "train loss:0.001368837758731403\n",
      "train loss:0.0057367345146725505\n",
      "train loss:0.0007522049129786445\n",
      "train loss:0.003507361688989529\n",
      "train loss:0.004817265878945416\n",
      "train loss:0.0012511972541008338\n",
      "train loss:0.0005361221144632434\n",
      "train loss:0.0016942906968250016\n",
      "train loss:0.003950654238255117\n",
      "train loss:0.0011467839268965822\n",
      "train loss:0.0062660720113579815\n",
      "train loss:0.009827188108770042\n",
      "train loss:0.002793340769328706\n",
      "train loss:0.010767824593165854\n",
      "train loss:0.0020934115389419413\n",
      "train loss:0.007190860322308432\n",
      "train loss:0.014033891444959559\n",
      "train loss:0.005242630787920637\n",
      "train loss:0.0009666846765891954\n",
      "train loss:0.019866689462418412\n",
      "train loss:0.0005365776814348734\n",
      "train loss:0.03375768593329009\n",
      "train loss:0.0002287701267570481\n",
      "train loss:0.0069904375699151935\n",
      "train loss:0.012107178630577657\n",
      "train loss:0.0024228040752341546\n",
      "train loss:0.0031188848469223375\n",
      "train loss:0.0020887527003551416\n",
      "train loss:0.00098114087961845\n",
      "train loss:0.0003991883323465105\n",
      "train loss:0.0022972852344557803\n",
      "train loss:0.0025061213631165768\n",
      "train loss:0.0052823720457229415\n",
      "train loss:0.0017070540515721827\n",
      "train loss:0.015030540510399386\n",
      "train loss:0.007542371674452431\n",
      "train loss:0.0004880406414691115\n",
      "train loss:0.001578679124284702\n",
      "train loss:0.0029030647117420667\n",
      "train loss:0.013733188330872108\n",
      "train loss:0.002751228879135664\n",
      "train loss:0.0010573634664395217\n",
      "train loss:0.001683809906388954\n",
      "train loss:0.0012961433758049248\n",
      "train loss:0.0019543630515980064\n",
      "train loss:0.0012580382947797411\n",
      "train loss:0.0005117762821638982\n",
      "train loss:0.0015004379311454776\n",
      "train loss:0.0019351872883136252\n",
      "train loss:0.01396711363945093\n",
      "train loss:0.0022345251017960336\n",
      "train loss:0.0032064554465143875\n",
      "train loss:0.0016748229555565135\n",
      "train loss:0.0036719476273449434\n",
      "train loss:0.002618861371041385\n",
      "train loss:0.0007095745773760945\n",
      "train loss:0.004394710140928543\n",
      "train loss:0.010685240356520099\n",
      "train loss:0.002505795506139089\n",
      "train loss:0.0045264210731065235\n",
      "train loss:0.002939141435842024\n",
      "train loss:0.0235600987006674\n",
      "train loss:0.0019866622166513645\n",
      "train loss:0.018710792990791834\n",
      "train loss:0.0006844467750254701\n",
      "train loss:0.063027930464327\n",
      "train loss:0.003931521483403899\n",
      "train loss:0.0014710854460756736\n",
      "train loss:0.006218770104876797\n",
      "train loss:0.0017723439364492994\n",
      "train loss:0.00860238224992236\n",
      "train loss:0.0156784735945228\n",
      "train loss:0.006994347348074392\n",
      "train loss:0.0016166879143096953\n",
      "train loss:0.0006329951387861291\n",
      "train loss:0.027277771127774894\n",
      "train loss:0.01076240018875267\n",
      "train loss:0.0056091278618378175\n",
      "train loss:0.01028308769001272\n",
      "train loss:0.007517974214865431\n",
      "train loss:0.005691576134618035\n",
      "train loss:0.004804789829069325\n",
      "train loss:0.008946063774603785\n",
      "train loss:0.0036264920775764906\n",
      "train loss:0.015413970955649243\n",
      "train loss:0.0034973226903323444\n",
      "train loss:0.007793725653187656\n",
      "train loss:0.001923192266462356\n",
      "train loss:0.005005524209703059\n",
      "train loss:0.0426243478168765\n",
      "train loss:0.001403026681192352\n",
      "train loss:0.012488326769448362\n",
      "train loss:0.006342234998310194\n",
      "train loss:0.002020442881751309\n",
      "train loss:0.0019946374641348435\n",
      "train loss:0.0034319597053798397\n",
      "train loss:0.0008965041397248699\n",
      "train loss:0.014918446693154855\n",
      "train loss:0.00372397457250936\n",
      "train loss:0.006717683230939202\n",
      "train loss:0.0036212987311395584\n",
      "train loss:0.004471109216595973\n",
      "train loss:0.001115334145296949\n",
      "train loss:0.004207532547950639\n",
      "train loss:0.00801502589951431\n",
      "train loss:0.00865534165438025\n",
      "train loss:0.0018070579101698004\n",
      "train loss:0.006850969735085623\n",
      "train loss:0.023948447122951067\n",
      "train loss:0.0013054188473032966\n",
      "train loss:0.0023961664143980553\n",
      "train loss:0.005476005625978315\n",
      "train loss:0.0027392246194320614\n",
      "train loss:0.0076284256847736496\n",
      "train loss:0.0030472522413872265\n",
      "train loss:0.007045238652917884\n",
      "train loss:0.02144404614192437\n",
      "train loss:0.0028339375308607463\n",
      "train loss:0.0031154855962793825\n",
      "train loss:0.00629385111719464\n",
      "train loss:0.00431425959423616\n",
      "train loss:0.001840320853747506\n",
      "train loss:0.0004264639130102651\n",
      "train loss:0.0012415924053706597\n",
      "train loss:0.003945858714255677\n",
      "train loss:0.005989727673621482\n",
      "train loss:0.005928822632046472\n",
      "train loss:0.004951159848392336\n",
      "train loss:0.0017659641285860872\n",
      "train loss:0.00297423387973519\n",
      "train loss:0.007966772838829198\n",
      "train loss:0.003694605288162126\n",
      "train loss:0.004563355578072095\n",
      "train loss:0.0018343308519795471\n",
      "train loss:0.005114395699131587\n",
      "train loss:0.005422772773930361\n",
      "train loss:0.005914836104477632\n",
      "train loss:0.0006900994237143842\n",
      "train loss:0.001506230979892223\n",
      "train loss:0.0023422529009859906\n",
      "train loss:0.006797392601119262\n",
      "train loss:0.004952828601328118\n",
      "train loss:0.0015849862225273724\n",
      "train loss:0.005307303755841808\n",
      "train loss:0.014146739006253914\n",
      "train loss:0.0066720411770294944\n",
      "train loss:0.005105109881531169\n",
      "train loss:0.061352670160164394\n",
      "train loss:0.001412991105670458\n",
      "train loss:0.010616278161435842\n",
      "train loss:0.0006407152140428901\n",
      "train loss:0.03830085695141292\n",
      "train loss:0.0023036390253563482\n",
      "train loss:0.0011896123349573633\n",
      "train loss:0.0007865586912497011\n",
      "train loss:0.010924138548010538\n",
      "train loss:0.005853814388817812\n",
      "train loss:0.003420314352201145\n",
      "train loss:0.00047163119755428995\n",
      "train loss:0.0010483619130671488\n",
      "train loss:0.009513848739219044\n",
      "train loss:0.009276709686513132\n",
      "train loss:0.0012863381572595222\n",
      "train loss:0.01121572420164481\n",
      "train loss:0.0019924144715064195\n",
      "train loss:0.001201282236710779\n",
      "train loss:0.0015224990966955431\n",
      "train loss:0.004074550487161947\n",
      "train loss:0.005623458759042677\n",
      "train loss:0.0012624373838370374\n",
      "train loss:0.001608406470469644\n",
      "train loss:0.0008034625497750562\n",
      "train loss:0.0025253716049442416\n",
      "train loss:0.0031074164692608316\n",
      "train loss:0.030623502133366995\n",
      "train loss:0.0038026884160651943\n",
      "train loss:0.002801650575890469\n",
      "train loss:0.004723289486183156\n",
      "train loss:0.0013603518143238027\n",
      "train loss:0.0050384805840785266\n",
      "train loss:0.021084226213839742\n",
      "train loss:0.009963978440391109\n",
      "train loss:0.008040384721486753\n",
      "train loss:0.0009684131554654174\n",
      "train loss:0.004271556306153407\n",
      "train loss:0.003120239029765812\n",
      "train loss:0.0023900114689015153\n",
      "train loss:0.0013107226547235437\n",
      "train loss:0.0014681107919887956\n",
      "train loss:0.0013905605364679385\n",
      "train loss:0.003286681510693122\n",
      "train loss:0.0021081940699182074\n",
      "train loss:0.028542154290713273\n",
      "train loss:0.00345829161950494\n",
      "train loss:0.005283864707115409\n",
      "train loss:0.008645642001526288\n",
      "train loss:0.0018621235912501318\n",
      "train loss:0.0011491061608607917\n",
      "train loss:0.004780075058330919\n",
      "train loss:0.043040581476636364\n",
      "train loss:0.002240656743751471\n",
      "train loss:0.0005068600549147617\n",
      "train loss:0.058569533002923994\n",
      "train loss:0.004862018542352164\n",
      "train loss:0.0025099482605653984\n",
      "train loss:0.002128498388912081\n",
      "train loss:0.0025038102849220924\n",
      "train loss:0.008031265140838136\n",
      "train loss:0.004812753732139472\n",
      "train loss:0.005066195870477391\n",
      "train loss:0.0068263358501748535\n",
      "train loss:0.006599614697293136\n",
      "train loss:0.0018581719501155542\n",
      "train loss:0.0026178936389464574\n",
      "train loss:0.002315206262767966\n",
      "train loss:0.010107776031160165\n",
      "train loss:0.07229851263400094\n",
      "train loss:0.0035715810710281047\n",
      "train loss:0.0037977409347392595\n",
      "train loss:0.006505778230731162\n",
      "train loss:0.005558232574056857\n",
      "train loss:0.010109623269433866\n",
      "train loss:0.0023911223219992782\n",
      "train loss:0.00169131606805785\n",
      "train loss:0.0036716559247018388\n",
      "train loss:0.0011452620982928278\n",
      "train loss:0.012536030163744352\n",
      "train loss:0.013536615871510576\n",
      "train loss:0.0011516426435828522\n",
      "train loss:0.006607158708364737\n",
      "train loss:0.001656785461018038\n",
      "train loss:0.0014583056594483076\n",
      "train loss:0.019562778623346697\n",
      "train loss:0.01198914466635884\n",
      "train loss:0.002960393652249903\n",
      "train loss:0.0005127004594457187\n",
      "train loss:0.0035190735619807963\n",
      "train loss:0.0023115411853917188\n",
      "train loss:0.0035979440704464534\n",
      "train loss:0.03291585499835613\n",
      "train loss:0.0029180390765172494\n",
      "train loss:0.00589050665687767\n",
      "train loss:0.006102921228477633\n",
      "train loss:0.002294935543834807\n",
      "train loss:0.003834224867257774\n",
      "train loss:0.0004110942431323466\n",
      "train loss:0.0022358070345587645\n",
      "train loss:0.0007947270038888099\n",
      "train loss:0.01467401116503197\n",
      "train loss:0.007436563602647908\n",
      "train loss:0.003337673577843418\n",
      "train loss:0.002250981001718796\n",
      "train loss:0.0011890464410299769\n",
      "train loss:0.004606948293256957\n",
      "train loss:0.00027274906721659907\n",
      "train loss:0.0008303915259420306\n",
      "train loss:0.0005259667289707127\n",
      "train loss:0.0031650520655689546\n",
      "train loss:0.0038303592118698626\n",
      "train loss:0.0010211503680799174\n",
      "train loss:0.003954815983095233\n",
      "train loss:0.01147088652760288\n",
      "train loss:0.0032586281461575843\n",
      "train loss:0.0016232751051146151\n",
      "train loss:0.0006338787798687412\n",
      "train loss:0.0019884719067030905\n",
      "train loss:0.019669935370981603\n",
      "train loss:0.009579309799825101\n",
      "train loss:0.0015652531323938892\n",
      "train loss:0.004586046076982765\n",
      "train loss:0.004944076567428739\n",
      "train loss:0.005644448404552352\n",
      "train loss:0.005047571550411904\n",
      "train loss:0.00023863952094797268\n",
      "train loss:0.0018672149666502796\n",
      "train loss:0.003547358256711155\n",
      "train loss:0.0007991469228562691\n",
      "train loss:0.004265557453036523\n",
      "train loss:0.002813261998317628\n",
      "train loss:0.004881017827609774\n",
      "train loss:0.001182917224748824\n",
      "train loss:0.004886961900501252\n",
      "train loss:0.0005505166714618487\n",
      "train loss:0.014023524509876093\n",
      "train loss:0.009549757373711184\n",
      "train loss:0.008634627020229638\n",
      "train loss:0.0055954995286707065\n",
      "train loss:0.0007471930115217117\n",
      "train loss:0.004178425436297174\n",
      "train loss:0.0010537109636386797\n",
      "train loss:0.005874051550686928\n",
      "train loss:0.0016303924181150981\n",
      "train loss:0.018210544574507558\n",
      "train loss:0.0014532560316837231\n",
      "train loss:0.02927742233042621\n",
      "train loss:0.004158701425203761\n",
      "train loss:0.004971639987185594\n",
      "train loss:0.00036607219646036577\n",
      "train loss:0.0004497693247863448\n",
      "train loss:0.005751889733052503\n",
      "train loss:0.005993913788292805\n",
      "train loss:0.0030899423844571415\n",
      "train loss:0.0015054727916389904\n",
      "train loss:0.04752575370145852\n",
      "train loss:0.00020106375422490757\n",
      "train loss:0.0022920354000156304\n",
      "train loss:0.007853221694325698\n",
      "train loss:0.03678068004797142\n",
      "train loss:0.0004270250149015644\n",
      "train loss:0.0012473799714731218\n",
      "train loss:0.028774004117741208\n",
      "train loss:0.0038669802146379805\n",
      "train loss:0.007978617820773231\n",
      "train loss:0.006443328395114351\n",
      "train loss:0.0041518861616215525\n",
      "train loss:0.016131857711082193\n",
      "train loss:0.012561103971946526\n",
      "train loss:0.02077514370869156\n",
      "train loss:0.005711010322546427\n",
      "train loss:0.007114321046535897\n",
      "train loss:0.01592224334864141\n",
      "train loss:0.0010487133433145237\n",
      "train loss:0.00843281811101506\n",
      "train loss:0.000660953658154603\n",
      "train loss:0.016523268409959154\n",
      "train loss:0.006559386583009232\n",
      "train loss:0.01126111307377547\n",
      "train loss:0.00891919937794149\n",
      "train loss:0.0015413888108072368\n",
      "train loss:0.005242004788168896\n",
      "train loss:0.004187104661381922\n",
      "train loss:0.0011412759912928885\n",
      "train loss:0.005762005662103677\n",
      "train loss:0.004640104028033585\n",
      "train loss:0.003718998475000037\n",
      "train loss:0.0028911604171554133\n",
      "train loss:0.005899521661896054\n",
      "train loss:0.002308934717912948\n",
      "train loss:0.002392482392546523\n",
      "train loss:0.00775848469531041\n",
      "train loss:0.011368838017151928\n",
      "train loss:0.004460396501682989\n",
      "train loss:0.005044227450891253\n",
      "train loss:0.004229106206448908\n",
      "train loss:0.035671619528605925\n",
      "train loss:0.0038507863421906913\n",
      "train loss:0.013584951428909286\n",
      "train loss:0.002028734224239588\n",
      "train loss:0.03519247777139618\n",
      "train loss:0.0027172139845024553\n",
      "train loss:0.02747338198728382\n",
      "train loss:0.004478069966564385\n",
      "train loss:0.0005898218160477367\n",
      "train loss:0.004352609056589126\n",
      "train loss:0.005019766269886043\n",
      "train loss:0.019250365494904137\n",
      "train loss:0.003441365890725979\n",
      "train loss:0.0033925564364716033\n",
      "train loss:0.0023568678362393385\n",
      "train loss:0.039590046316726225\n",
      "train loss:0.01981789631035057\n",
      "train loss:0.0076149849062379475\n",
      "train loss:0.0008309206257843711\n",
      "train loss:0.006002407718282392\n",
      "train loss:0.0009969227095205531\n",
      "train loss:0.003600430585176585\n",
      "train loss:0.0002534405500163032\n",
      "train loss:0.0020860446767854836\n",
      "train loss:0.006993584309805662\n",
      "train loss:0.004188965484199572\n",
      "train loss:0.0031054316108342197\n",
      "train loss:0.0016002183770270422\n",
      "train loss:0.001983667823998885\n",
      "train loss:0.014986180474423703\n",
      "train loss:0.003701569832902186\n",
      "train loss:0.009468699708525433\n",
      "train loss:0.011644346974275892\n",
      "train loss:0.0043033587474489154\n",
      "train loss:0.0004123444141114835\n",
      "train loss:0.0017033407689792293\n",
      "train loss:0.003537507663169081\n",
      "train loss:0.003058235998585673\n",
      "train loss:0.0012619812545150016\n",
      "train loss:0.0015747504103064995\n",
      "train loss:0.022507793214525767\n",
      "train loss:0.015388617957987733\n",
      "train loss:0.0011955462532894365\n",
      "train loss:0.0007025061728231091\n",
      "train loss:0.055357428123258966\n",
      "train loss:0.0020597111045503654\n",
      "train loss:0.018181452836244633\n",
      "train loss:0.008171175794586961\n",
      "train loss:0.0005782758282263572\n",
      "train loss:0.0017054197399011617\n",
      "train loss:0.004710567746132811\n",
      "train loss:0.007737481623841449\n",
      "train loss:0.002338165000463824\n",
      "train loss:0.006093889475823155\n",
      "train loss:0.005911176380228164\n",
      "train loss:0.0031967515414761697\n",
      "train loss:0.0008450048487370445\n",
      "train loss:0.0006358038583207893\n",
      "train loss:0.0023179476605779447\n",
      "train loss:0.0036591056348967144\n",
      "train loss:0.005165541256469143\n",
      "train loss:0.005789737949887928\n",
      "train loss:0.0005902563160402379\n",
      "train loss:0.0005011655667459106\n",
      "train loss:0.004827789706305623\n",
      "train loss:0.0022307068384545816\n",
      "train loss:0.0013098464157792471\n",
      "train loss:0.0038186984119283466\n",
      "train loss:0.0017490919547035553\n",
      "train loss:0.002262851700724263\n",
      "train loss:0.009761589075923621\n",
      "train loss:0.0020488543460837182\n",
      "train loss:0.0014281986621618792\n",
      "train loss:0.0016390450467736889\n",
      "=== epoch:12, train acc:0.996, test acc:0.985 ===\n",
      "train loss:0.00126769810779217\n",
      "train loss:0.007153026246282866\n",
      "train loss:0.009628700570339158\n",
      "train loss:0.007481412285375519\n",
      "train loss:0.008004604171357337\n",
      "train loss:0.018877097219664924\n",
      "train loss:0.003514765162269032\n",
      "train loss:0.002777265852918544\n",
      "train loss:0.002289365924611995\n",
      "train loss:0.002431086519444538\n",
      "train loss:0.003636050433566115\n",
      "train loss:0.007515391365480231\n",
      "train loss:0.0038586974159234943\n",
      "train loss:0.0010494506317260273\n",
      "train loss:0.009564358362101028\n",
      "train loss:0.008868563490039135\n",
      "train loss:0.0007696291664620608\n",
      "train loss:0.0018719551695988393\n",
      "train loss:0.030143081614321495\n",
      "train loss:0.0011814200463926277\n",
      "train loss:0.003315441884072412\n",
      "train loss:0.01609356534842296\n",
      "train loss:0.010842113493089308\n",
      "train loss:0.0025882562989800705\n",
      "train loss:0.004431287009004815\n",
      "train loss:0.0015951684329052365\n",
      "train loss:0.00034602445634945557\n",
      "train loss:0.0009104080815989533\n",
      "train loss:0.0016021644298970226\n",
      "train loss:0.0009355269635700224\n",
      "train loss:0.006706682750295432\n",
      "train loss:0.0008262446556031023\n",
      "train loss:0.006964851370770111\n",
      "train loss:0.0004158446902030419\n",
      "train loss:0.0034041242968865845\n",
      "train loss:0.00319317146233045\n",
      "train loss:0.007305731411849814\n",
      "train loss:0.02174513475262038\n",
      "train loss:0.0013035584473322054\n",
      "train loss:0.006385683165743407\n",
      "train loss:0.0011941840038814998\n",
      "train loss:0.0023585530475909093\n",
      "train loss:0.0008734705170035588\n",
      "train loss:0.002497554439302514\n",
      "train loss:0.003512807070090168\n",
      "train loss:0.007610888947644929\n",
      "train loss:0.004821930730669091\n",
      "train loss:0.0011488691157288302\n",
      "train loss:0.0006389474411873453\n",
      "train loss:0.0017652644312688378\n",
      "train loss:0.005325542910812629\n",
      "train loss:0.0011743114230518814\n",
      "train loss:0.013071908327942361\n",
      "train loss:0.012578542641432471\n",
      "train loss:0.0026943830118169114\n",
      "train loss:0.006739994430137694\n",
      "train loss:0.0007060725386980759\n",
      "train loss:0.0011556345979893176\n",
      "train loss:0.003513931311294234\n",
      "train loss:0.006174682721049301\n",
      "train loss:0.004427204137973342\n",
      "train loss:0.0006357383361937905\n",
      "train loss:0.0008028872386037281\n",
      "train loss:0.0011262768691509854\n",
      "train loss:0.0015990696830290464\n",
      "train loss:0.00027563955942491063\n",
      "train loss:0.00526254241001474\n",
      "train loss:0.004082533559387227\n",
      "train loss:0.004154517260208576\n",
      "train loss:0.01016037499485145\n",
      "train loss:0.0012675653611031931\n",
      "train loss:0.0006466113701945104\n",
      "train loss:0.0013452625615100265\n",
      "train loss:0.0027910547748288966\n",
      "train loss:0.002096578291726792\n",
      "train loss:0.000634709263923441\n",
      "train loss:0.0020752945002589594\n",
      "train loss:0.0025394435757484057\n",
      "train loss:0.006700530694719615\n",
      "train loss:0.0024212266157910244\n",
      "train loss:0.01022965467681057\n",
      "train loss:0.0027115823997149544\n",
      "train loss:0.006590982903391152\n",
      "train loss:0.0038923574895122436\n",
      "train loss:0.002563934320647824\n",
      "train loss:0.004417402397429341\n",
      "train loss:0.0029232517075053668\n",
      "train loss:0.0015939952246122613\n",
      "train loss:0.017977825514822666\n",
      "train loss:0.0017605494961125364\n",
      "train loss:0.0007801119613125117\n",
      "train loss:0.011924208658420312\n",
      "train loss:0.0036150467945872855\n",
      "train loss:0.0051423977776963925\n",
      "train loss:0.00044354611076662874\n",
      "train loss:0.005269966323786759\n",
      "train loss:0.009122319515100485\n",
      "train loss:0.0018716687294120474\n",
      "train loss:0.00308881971666482\n",
      "train loss:0.0015466597441641833\n",
      "train loss:0.0035586014138134603\n",
      "train loss:0.001720439832038366\n",
      "train loss:0.000958840929287737\n",
      "train loss:0.02647534258655472\n",
      "train loss:0.006928743124238646\n",
      "train loss:0.005101528446448821\n",
      "train loss:0.0026437861194034203\n",
      "train loss:0.019233333803535216\n",
      "train loss:0.001047250423702835\n",
      "train loss:0.005830905103671401\n",
      "train loss:0.0052598806910857734\n",
      "train loss:0.0013337216568428442\n",
      "train loss:0.0020591994845872647\n",
      "train loss:0.0012852499465965386\n",
      "train loss:0.0054690008242164155\n",
      "train loss:0.003268669784749876\n",
      "train loss:0.006142534647054839\n",
      "train loss:0.002257217229632593\n",
      "train loss:0.0005070354812122082\n",
      "train loss:0.0017497429846653157\n",
      "train loss:0.0002678521070624515\n",
      "train loss:0.0005750786650517322\n",
      "train loss:0.0002977218050367253\n",
      "train loss:0.003389081805075734\n",
      "train loss:0.0006710257448508916\n",
      "train loss:0.003519076051079674\n",
      "train loss:0.0026133270491663168\n",
      "train loss:0.0027821120161989387\n",
      "train loss:0.00014116353457636273\n",
      "train loss:0.0036156183084474687\n",
      "train loss:0.00016594079333355052\n",
      "train loss:0.002511576044280287\n",
      "train loss:0.0002905992811144628\n",
      "train loss:0.0022587821950896055\n",
      "train loss:0.002571489160388109\n",
      "train loss:0.0008565842916925015\n",
      "train loss:0.0004194896104147167\n",
      "train loss:0.003428594983790289\n",
      "train loss:0.02105126585195656\n",
      "train loss:0.005500180171868259\n",
      "train loss:0.001460458976842439\n",
      "train loss:0.0002859991379658511\n",
      "train loss:0.001163123856998083\n",
      "train loss:0.0012131999426269263\n",
      "train loss:0.002266558133414517\n",
      "train loss:0.0051690137982967534\n",
      "train loss:0.0036278754557307795\n",
      "train loss:0.002236505253949603\n",
      "train loss:0.002970318804190412\n",
      "train loss:0.00048556259721278924\n",
      "train loss:0.000789873599908254\n",
      "train loss:0.000563450232164843\n",
      "train loss:0.0008105509715255127\n",
      "train loss:0.0009833213195897768\n",
      "train loss:0.0015332102193316836\n",
      "train loss:0.004019334085223079\n",
      "train loss:0.00035633071385684183\n",
      "train loss:0.002328374402998479\n",
      "train loss:0.0020948595166521405\n",
      "train loss:0.0007483678284354338\n",
      "train loss:0.0024057123735002216\n",
      "train loss:0.0013082987521283518\n",
      "train loss:0.009754451042903643\n",
      "train loss:0.0015793994708836038\n",
      "train loss:0.003395677531929794\n",
      "train loss:0.00019367292378124327\n",
      "train loss:0.0018965251468674208\n",
      "train loss:0.002999753348696968\n",
      "train loss:0.00400694942993678\n",
      "train loss:0.00130486046766456\n",
      "train loss:0.000837598894634347\n",
      "train loss:0.0018447827570501436\n",
      "train loss:0.006162813710613838\n",
      "train loss:0.007423775802526507\n",
      "train loss:0.013659447966898703\n",
      "train loss:0.033739841714814874\n",
      "train loss:0.004802669660717153\n",
      "train loss:0.0002696567702805949\n",
      "train loss:0.0025815965366593925\n",
      "train loss:0.007527630397929054\n",
      "train loss:0.0025014043284410812\n",
      "train loss:0.00874925703271529\n",
      "train loss:0.001150836099100181\n",
      "train loss:0.011049687291226778\n",
      "train loss:0.008074772967802684\n",
      "train loss:0.002418885235767369\n",
      "train loss:0.009388192919920994\n",
      "train loss:0.007495846125305406\n",
      "train loss:0.008998416469509685\n",
      "train loss:0.01631588452427788\n",
      "train loss:0.04802833355339789\n",
      "train loss:0.008068045270330296\n",
      "train loss:0.0022996756979345896\n",
      "train loss:0.0009246704646199847\n",
      "train loss:0.0015203931202469525\n",
      "train loss:0.0018066611256602264\n",
      "train loss:0.009874438759032836\n",
      "train loss:0.005159749507684219\n",
      "train loss:0.00039035180876094834\n",
      "train loss:0.004223538587345229\n",
      "train loss:0.00549257816876234\n",
      "train loss:0.00026792368415073757\n",
      "train loss:0.006175889402245208\n",
      "train loss:0.0022476741135455548\n",
      "train loss:0.0028320413741657496\n",
      "train loss:0.010541481496693317\n",
      "train loss:0.002435362901763728\n",
      "train loss:0.0013045746007394384\n",
      "train loss:0.009481638908850988\n",
      "train loss:0.003920907679969041\n",
      "train loss:0.00037739916042572717\n",
      "train loss:0.006024686497168888\n",
      "train loss:0.006578285099537317\n",
      "train loss:6.77581471216533e-05\n",
      "train loss:0.014678416404905888\n",
      "train loss:0.004371263715294556\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mセル7 を /home/yuki/clone/deep-learning-from-scratch/7.ipynb\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=3'>4</a>\u001b[0m network \u001b[39m=\u001b[39m SimpleConvNet(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=4'>5</a>\u001b[0m     input_dim\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=5'>6</a>\u001b[0m     conv_param\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mfilter_num\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m30\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfilter_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m5\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpad\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstride\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=8'>9</a>\u001b[0m     weight_init_std\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=9'>10</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=11'>12</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=12'>13</a>\u001b[0m     network,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=13'>14</a>\u001b[0m     x_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=21'>22</a>\u001b[0m     evaluate_sample_num_per_epoch\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=22'>23</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=24'>25</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=26'>27</a>\u001b[0m \u001b[39m# パラメータ保存\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/yuki/clone/deep-learning-from-scratch/7.ipynb#ch0000006vscode-remote?line=27'>28</a>\u001b[0m network\u001b[39m.\u001b[39msave_params(\u001b[39m\"\u001b[39m\u001b[39mparams.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/clone/deep-learning-from-scratch/common/trainer.py:71\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     70\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter):\n\u001b[0;32m---> 71\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step()\n\u001b[1;32m     73\u001b[0m     test_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39maccuracy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_test)\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/clone/deep-learning-from-scratch/common/trainer.py:44\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m x_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_train[batch_mask]\n\u001b[1;32m     42\u001b[0m t_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_train[batch_mask]\n\u001b[0;32m---> 44\u001b[0m grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork\u001b[39m.\u001b[39;49mgradient(x_batch, t_batch)\n\u001b[1;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mparams, grads)\n\u001b[1;32m     47\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mloss(x_batch, t_batch)\n",
      "File \u001b[0;32m~/clone/deep-learning-from-scratch/ch07/simple_convnet.py:126\u001b[0m, in \u001b[0;36mSimpleConvNet.gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m\"\"\"勾配を求める（誤差逆伝搬法）\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m    grads['b1']、grads['b2']、...は各層のバイアス\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m# forward\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(x, t)\n\u001b[1;32m    128\u001b[0m \u001b[39m# backward\u001b[39;00m\n\u001b[1;32m    129\u001b[0m dout \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/clone/deep-learning-from-scratch/ch07/simple_convnet.py:71\u001b[0m, in \u001b[0;36mSimpleConvNet.loss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, x, t):\n\u001b[1;32m     68\u001b[0m     \u001b[39m\"\"\"損失関数を求める\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m    引数のxは入力データ、tは教師ラベル\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x)\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_layer\u001b[39m.\u001b[39mforward(y, t)\n",
      "File \u001b[0;32m~/clone/deep-learning-from-scratch/ch07/simple_convnet.py:63\u001b[0m, in \u001b[0;36mSimpleConvNet.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     62\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m---> 63\u001b[0m         x \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mforward(x)\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/clone/deep-learning-from-scratch/common/layers.py:223\u001b[0m, in \u001b[0;36mConvolution.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    220\u001b[0m col \u001b[39m=\u001b[39m im2col(x, FH, FW, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad)\n\u001b[1;32m    221\u001b[0m col_W \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW\u001b[39m.\u001b[39mreshape(FN, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mT\n\u001b[0;32m--> 223\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(col, col_W) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb\n\u001b[1;32m    224\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mreshape(N, out_h, out_w, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    226\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m x\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "max_epochs = 20\n",
    "network = SimpleConvNet(\n",
    "    input_dim=(1, 28, 28),\n",
    "    conv_param={\"filter_num\": 30, \"filter_size\": 5, \"pad\": 0, \"stride\": 1},\n",
    "    hidden_size=100,\n",
    "    output_size=10,\n",
    "    weight_init_std=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    network,\n",
    "    x_train,\n",
    "    t_train,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    epochs=max_epochs,\n",
    "    mini_batch_size=100,\n",
    "    optimizer=\"Adam\",\n",
    "    optimizer_param={\"lr\": 0.001},\n",
    "    evaluate_sample_num_per_epoch=1000,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# パラメータ保存\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# ランダム初期化後の重み\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 学習後の重み\n",
    "network.load_params(\"ch07/params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
